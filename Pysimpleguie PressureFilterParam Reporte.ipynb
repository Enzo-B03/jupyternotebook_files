{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\v.t.flores\\\\Documents\\\\Pressure Filter Inv_2020_PF_stagecheck.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-7c54b81d60ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m#Sheet From Pi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m#Step1: Load the Data for the month\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mdf_Pi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'C:\\Users\\v.t.flores\\Documents\\Pressure Filter Inv_2020_PF_stagecheck.xlsx'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msheet_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'PiData_PressureFilter'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m#Drop the row[1]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, **kwds)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 304\u001b[1;33m         \u001b[0mio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    305\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m         raise ValueError(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, io, engine)\u001b[0m\n\u001b[0;32m    819\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstringify_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 821\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    822\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    823\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_xlrd.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0merr_msg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Install xlrd >= 1.0.0 for Excel support\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mimport_optional_dependency\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"xlrd\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[0;32m    351\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    354\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_xlrd.py\u001b[0m in \u001b[0;36mload_workbook\u001b[1;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xlrd\\__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[1;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m             \u001b[0mpeek\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpeek\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34mb\"PK\\x03\\x04\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# a ZIP file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\v.t.flores\\\\Documents\\\\Pressure Filter Inv_2020_PF_stagecheck.xlsx'"
     ]
    }
   ],
   "source": [
    "#exc1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from dateutil.parser import parse\n",
    "\n",
    "from datetime import date\n",
    "import datetime\n",
    "\n",
    "\n",
    "\n",
    "#Sheet From Pi\n",
    "#Step1: Load the Data for the month\n",
    "df_Pi = pd.read_excel(r'C:\\Users\\v.t.flores\\Documents\\Pressure Filter Inv_2020_PF_stagecheck.xlsx', sheet_name='PiData_PressureFilter', index_col=False)\n",
    "\n",
    "#Drop the row[1]\n",
    "df_Pi = df_Pi.drop(df_Pi.index[0])\n",
    "\n",
    "#Step2: Parse the DATETIME column\n",
    "df_Pi['DATETIME'] = df_Pi['DATETIME'].apply(lambda x: parse(str(x)))\n",
    "\n",
    "df_Pi.set_index('DATETIME', inplace=True)\n",
    "df_comb = df_Pi\n",
    "\n",
    "\n",
    "def getTheLocalMinMaxRev(df_col1, df_col2):\n",
    "    df_col1 = pd.to_numeric(df_col1, errors='coerce')\n",
    "    b = (np.diff(np.sign(np.diff(df_col1))) > 0).nonzero()[0] + 1         # local min\n",
    "    #Variable b contains the list of indices for where there are minimum values detected from the rows\n",
    "    \n",
    "    df_col2 = pd.to_numeric(df_col2, errors='coerce')\n",
    "    f = (np.diff(np.sign(np.diff(df_col2))) < 0).nonzero()[0] + 1         # local max\n",
    "    \n",
    "    #Variable f contains the list of indices for where there are maximum values detected from the rows\n",
    "    \n",
    "    try:\n",
    "        ft_cyc_lim = {}\n",
    "        for i in range(0, len(b)):\n",
    "            for j in range(0, len(f)):\n",
    "                if b[i] < f[j]:\n",
    "                    cyc_start = b[i]\n",
    "                    cyc_end = f[j]\n",
    "                    ft_cyc_lim.setdefault(cyc_start,cyc_end) #The ft_cyc_lim is the dictionary of the local min, max pair\n",
    "                    pass\n",
    "    except IndexError:\n",
    "        print('IndexError')\n",
    "    return ft_cyc_lim\n",
    "\n",
    "\n",
    "def generate_DF(df, str_colname, dictParameter):\n",
    "    # Prepare the df_coltitle as df_comb['filtration']\n",
    "    #-------------str_colname as 'A_t_feed'\n",
    "    #-------------dict_FT as the dictionary containing the local min and local max filtration time indices\n",
    "    #---the key is the local mininmum filtration time\n",
    "    #---the key element is the local maximum filtration time which signifies the end of the filtration time\n",
    "    \n",
    "    A_Filt_MaxList= list()\n",
    "    A_Filt_MaxList[:] = []\n",
    "    A_feedt_Val_List = list()\n",
    "    A_feedt_Val_List[:] = []\n",
    "    A_feedt_index_List = list()\n",
    "    A_feedt_index_List[:] = []\n",
    "    A_Pair_Filt_List = list()\n",
    "    A_Pair_Filt_List[:] = []\n",
    "    try:\n",
    "        for i in dictParameter.keys():\n",
    "            A_feedt = df[str_colname][dictParameter[i]]\n",
    "            A_feedt_Val_List.append(A_feedt)\n",
    "            A_feedt_index_List.append(df.index[dictParameter[i]])\n",
    "        A_Pair_Filt_List = list(zip(A_feedt_Val_List, A_feedt_index_List[0:]))\n",
    "    except:\n",
    "        pass\n",
    "    df_A_Pair_Filt_t = pd.DataFrame(A_Pair_Filt_List)\n",
    "    \n",
    "    df_A_Pair_Filt_t.columns = [str_colname, 'DATETIME']\n",
    "    df_A_Pair_Filt_t.set_index('DATETIME', inplace=True)  \n",
    "    return df_A_Pair_Filt_t\n",
    "#--------------------------------------------\n",
    "\n",
    "#create a dictionary of the local minimum and local maximum values for each parameter\n",
    "#Use the function getTheLocalMinMaxRev()\n",
    "\n",
    "dict_AT =  getTheLocalMinMaxRev(df_comb['A_t_FEED'], df_comb['A_t_FEED'])\n",
    "dict_N2_AT = getTheLocalMinMaxRev(df_comb['A_t_DRY'], df_comb['A_t_DRY'])\n",
    "dict_CWSH1_AT = getTheLocalMinMaxRev(df_comb['A_t_CWSH1'], df_comb['A_t_CWSH1'])\n",
    "dict_CWSH2_AT = getTheLocalMinMaxRev(df_comb['A_t_CWSH2'], df_comb['A_t_CWSH2'])\n",
    "dict_P1_AT = getTheLocalMinMaxRev(df_comb['A_t_PRESS1'], df_comb['A_t_PRESS1'])\n",
    "dict_P2_AT = getTheLocalMinMaxRev(df_comb['A_t_PRESS2'], df_comb['A_t_PRESS2'])\n",
    "\n",
    "\n",
    "dict_BT =  getTheLocalMinMaxRev(df_comb['B_t_FEED'], df_comb['B_t_FEED'])\n",
    "dict_N2_BT = getTheLocalMinMaxRev(df_comb['B_t_DRY'], df_comb['B_t_DRY'])\n",
    "dict_CWSH1_BT = getTheLocalMinMaxRev(df_comb['B_t_CWSH1'], df_comb['B_t_CWSH1'])\n",
    "dict_CWSH2_BT = getTheLocalMinMaxRev(df_comb['B_t_CWSH2'], df_comb['B_t_CWSH2'])\n",
    "dict_P1_BT = getTheLocalMinMaxRev(df_comb['B_t_PRESS1'], df_comb['B_t_PRESS1'])\n",
    "dict_P2_BT = getTheLocalMinMaxRev(df_comb['B_t_PRESS2'], df_comb['B_t_PRESS2'])\n",
    "\n",
    "#Create a dataframe from the actual parameter values using the dictionary created previously\n",
    "\n",
    "df_FT_feed_t =  generate_DF(df_comb, 'A_t_FEED', dict_AT)\n",
    "df_FT_N2_t =  generate_DF(df_comb, 'A_t_DRY', dict_N2_AT)\n",
    "df_FT_CWSH1_t =  generate_DF(df_comb, 'A_t_CWSH1', dict_CWSH1_AT)\n",
    "df_FT_CWSH2_t =  generate_DF(df_comb, 'A_t_CWSH2', dict_CWSH2_AT)\n",
    "df_FT_P1_t =  generate_DF(df_comb, 'A_t_PRESS1', dict_P1_AT)\n",
    "df_FT_P2_t =  generate_DF(df_comb, 'A_t_PRESS2', dict_P2_AT)\n",
    "\n",
    "#Generate the dataframes for A\n",
    "df_A_N2DRY = generate_DF(df_comb, 'A_t_DRY', dict_AT)\n",
    "df_A_t_FEED = generate_DF(df_comb, 'A_t_FEED', dict_N2_AT)\n",
    "df_A_t_CWSH1 = generate_DF(df_comb, 'A_t_CWSH1', dict_CWSH1_AT)\n",
    "df_A_t_CWSH2 = generate_DF(df_comb, 'A_t_CWSH2', dict_CWSH2_AT)\n",
    "df_A_t_PRESS1 = generate_DF(df_comb, 'A_t_PRESS1', dict_P1_AT)\n",
    "df_A_t_PRESS2 = generate_DF(df_comb, 'A_t_PRESS2', dict_P2_AT)\n",
    "\n",
    "#Generate the dataframes for B\n",
    "df_B_N2DRY = generate_DF(df_comb, 'B_t_DRY', dict_BT)\n",
    "df_B_t_FEED = generate_DF(df_comb, 'B_t_FEED', dict_N2_BT)\n",
    "df_B_t_CWSH1 = generate_DF(df_comb, 'B_t_CWSH1', dict_CWSH1_BT)\n",
    "df_B_t_CWSH2 = generate_DF(df_comb, 'B_t_CWSH2', dict_CWSH2_BT)\n",
    "df_B_t_PRESS1 = generate_DF(df_comb, 'B_t_PRESS1', dict_P1_BT)\n",
    "df_B_t_PRESS2 = generate_DF(df_comb, 'B_t_PRESS2', dict_P2_BT)\n",
    "\n",
    "\n",
    "df1A = df_A_N2DRY.join(df_A_t_FEED, how='outer')\n",
    "df2A = df_A_t_CWSH1.join(df_A_t_CWSH2, how='outer')\n",
    "df3A = df_A_t_PRESS1.join(df_A_t_PRESS2, how='outer')\n",
    "df4A = df1A.join(df2A, how='outer')\n",
    "df5A = df3A.join(df4A, how='outer')\n",
    "\n",
    "df1B = df_B_N2DRY.join(df_B_t_FEED, how='outer')\n",
    "df2B = df_B_t_CWSH1.join(df_B_t_CWSH2, how='outer')\n",
    "df3B = df_B_t_PRESS1.join(df_B_t_PRESS2, how='outer')\n",
    "df4B = df1B.join(df2B, how='outer')\n",
    "df5B = df3B.join(df4B, how='outer')\n",
    "\n",
    "import PySimpleGUI as sg\n",
    "import time\n",
    "\n",
    "def excecutetest(command):\n",
    "        for i in range(5):\n",
    "            print (command + str(i))\n",
    "\n",
    "layout = [      \n",
    "    [sg.T('Source Folder')],\n",
    "              [sg.In(key='input')],\n",
    "              [sg.FolderBrowse(target='input'), sg.OK()],\n",
    "    [sg.Submit(), sg.Cancel()]\n",
    "    [sg.Text('Select the Pressure Filter to report the Parameters:', size=(40, 1))],      \n",
    "    [sg.Output(size=(100, 20))],      \n",
    "    [sg.Text('Input:', size=(15, 1)), sg.Button('Report_Recent_A_Paramaters', bind_return_key=True), sg.Button('Report_Recent_B_Paramaters', bind_return_key=True)],\n",
    "    [sg.Button('EXIT')]      \n",
    "        ] \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "window = sg.Window('Pressure Filter Parameter Report', layout)      \n",
    "\n",
    "# ---===--- Loop taking in user input and using it to call scripts --- #      \n",
    "\n",
    "while True:      \n",
    "    (event, value) = window.Read()      \n",
    "    if event == 'EXIT'  or event is None:      \n",
    "        break # exit button clicked      \n",
    "    if event == 'Report_Recent_A_Paramaters':      \n",
    "        print(df5A)\n",
    "    elif event == 'Report_Recent_B_Paramaters':\n",
    "        print(df5B)\n",
    "window.Close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dateutil.parser import parse\n",
    "from datetime import date\n",
    "import datetime\n",
    "import PySimpleGUI as sg\n",
    "import time\n",
    "\n",
    "def excecutetest(command):\n",
    "        for i in range(5):\n",
    "            print (command + str(i))\n",
    "\n",
    "layout = [      \n",
    "    [sg.In() ,sg.FileBrowse('Browse', file_types=((\"Excel Files\", \"*.xlsx\"),))],\n",
    "    [sg.Submit(), sg.Cancel()],\n",
    "    [sg.Text('Pressure Filter Parameters:', size=(40, 1))],      \n",
    "    [sg.Output(size=(88, 20))],      \n",
    "    [sg.Text('Input:', size=(15, 1)), sg.Button('Report_Recent_A_Paramaters', bind_return_key=True), sg.Button('Report_Recent_B_Paramaters', bind_return_key=True)],\n",
    "    [sg.Button('EXIT')]      \n",
    "        ] \n",
    "\n",
    "\n",
    "window = sg.Window('testing', layout)      \n",
    "\n",
    "# ---===--- Loop taking in user input and using it to call scripts --- #      \n",
    "\n",
    "while True:      \n",
    "    (event, value) = window.Read()\n",
    "    if event == 'Submit':\n",
    "        #Sheet From Pi\n",
    "        #Step1: Load the Data for the month\n",
    "        df_Pi = pd.read_excel(raw(value[0]), index_col=False)\n",
    "\n",
    "        #Drop the row[1]\n",
    "        df_Pi = df_Pi.drop(df_Pi.index[0])\n",
    "\n",
    "        #Step2: Parse the DATETIME column\n",
    "        df_Pi['DATETIME'] = df_Pi['DATETIME'].apply(lambda x: parse(str(x)))\n",
    "\n",
    "        df_Pi.set_index('DATETIME', inplace=True)\n",
    "        df_comb = df_Pi\n",
    "\n",
    "\n",
    "        def getTheLocalMinMaxRev(df_col1, df_col2):\n",
    "            df_col1 = pd.to_numeric(df_col1, errors='coerce')\n",
    "            b = (np.diff(np.sign(np.diff(df_col1))) > 0).nonzero()[0] + 1         # local min\n",
    "            #Variable b contains the list of indices for where there are minimum values detected from the rows\n",
    "\n",
    "            df_col2 = pd.to_numeric(df_col2, errors='coerce')\n",
    "            f = (np.diff(np.sign(np.diff(df_col2))) < 0).nonzero()[0] + 1         # local max\n",
    "\n",
    "            #Variable f contains the list of indices for where there are maximum values detected from the rows\n",
    "\n",
    "            try:\n",
    "                ft_cyc_lim = {}\n",
    "                for i in range(0, len(b)):\n",
    "                    for j in range(0, len(f)):\n",
    "                        if b[i] < f[j]:\n",
    "                            cyc_start = b[i]\n",
    "                            cyc_end = f[j]\n",
    "                            ft_cyc_lim.setdefault(cyc_start,cyc_end) #The ft_cyc_lim is the dictionary of the local min, max pair\n",
    "                            pass\n",
    "            except IndexError:\n",
    "                print('IndexError')\n",
    "            return ft_cyc_lim\n",
    "\n",
    "\n",
    "        def generate_DF(df, str_colname, dictParameter):\n",
    "            # Prepare the df_coltitle as df_comb['filtration']\n",
    "            #-------------str_colname as 'A_t_feed'\n",
    "            #-------------dict_FT as the dictionary containing the local min and local max filtration time indices\n",
    "            #---the key is the local mininmum filtration time\n",
    "            #---the key element is the local maximum filtration time which signifies the end of the filtration time\n",
    "\n",
    "            A_Filt_MaxList= list()\n",
    "            A_Filt_MaxList[:] = []\n",
    "            A_feedt_Val_List = list()\n",
    "            A_feedt_Val_List[:] = []\n",
    "            A_feedt_index_List = list()\n",
    "            A_feedt_index_List[:] = []\n",
    "            A_Pair_Filt_List = list()\n",
    "            A_Pair_Filt_List[:] = []\n",
    "            try:\n",
    "                for i in dictParameter.keys():\n",
    "                    A_feedt = df[str_colname][dictParameter[i]]\n",
    "                    A_feedt_Val_List.append(A_feedt)\n",
    "                    A_feedt_index_List.append(df.index[dictParameter[i]])\n",
    "                A_Pair_Filt_List = list(zip(A_feedt_Val_List, A_feedt_index_List[0:]))\n",
    "            except:\n",
    "                pass\n",
    "            df_A_Pair_Filt_t = pd.DataFrame(A_Pair_Filt_List)\n",
    "\n",
    "            df_A_Pair_Filt_t.columns = [str_colname, 'DATETIME']\n",
    "            df_A_Pair_Filt_t.set_index('DATETIME', inplace=True)  \n",
    "            return df_A_Pair_Filt_t\n",
    "        #--------------------------------------------\n",
    "\n",
    "        #create a dictionary of the local minimum and local maximum values for each parameter\n",
    "        #Use the function getTheLocalMinMaxRev()\n",
    "\n",
    "        dict_AT =  getTheLocalMinMaxRev(df_comb['A_t_FEED'], df_comb['A_t_FEED'])\n",
    "        dict_N2_AT = getTheLocalMinMaxRev(df_comb['A_t_DRY'], df_comb['A_t_DRY'])\n",
    "        dict_CWSH1_AT = getTheLocalMinMaxRev(df_comb['A_t_CWSH1'], df_comb['A_t_CWSH1'])\n",
    "        dict_CWSH2_AT = getTheLocalMinMaxRev(df_comb['A_t_CWSH2'], df_comb['A_t_CWSH2'])\n",
    "        dict_P1_AT = getTheLocalMinMaxRev(df_comb['A_t_PRESS1'], df_comb['A_t_PRESS1'])\n",
    "        dict_P2_AT = getTheLocalMinMaxRev(df_comb['A_t_PRESS2'], df_comb['A_t_PRESS2'])\n",
    "\n",
    "\n",
    "        dict_BT =  getTheLocalMinMaxRev(df_comb['B_t_FEED'], df_comb['B_t_FEED'])\n",
    "        dict_N2_BT = getTheLocalMinMaxRev(df_comb['B_t_DRY'], df_comb['B_t_DRY'])\n",
    "        dict_CWSH1_BT = getTheLocalMinMaxRev(df_comb['B_t_CWSH1'], df_comb['B_t_CWSH1'])\n",
    "        dict_CWSH2_BT = getTheLocalMinMaxRev(df_comb['B_t_CWSH2'], df_comb['B_t_CWSH2'])\n",
    "        dict_P1_BT = getTheLocalMinMaxRev(df_comb['B_t_PRESS1'], df_comb['B_t_PRESS1'])\n",
    "        dict_P2_BT = getTheLocalMinMaxRev(df_comb['B_t_PRESS2'], df_comb['B_t_PRESS2'])\n",
    "\n",
    "        #Create a dataframe from the actual parameter values using the dictionary created previously\n",
    "\n",
    "        df_FT_feed_t =  generate_DF(df_comb, 'A_t_FEED', dict_AT)\n",
    "        df_FT_N2_t =  generate_DF(df_comb, 'A_t_DRY', dict_N2_AT)\n",
    "        df_FT_CWSH1_t =  generate_DF(df_comb, 'A_t_CWSH1', dict_CWSH1_AT)\n",
    "        df_FT_CWSH2_t =  generate_DF(df_comb, 'A_t_CWSH2', dict_CWSH2_AT)\n",
    "        df_FT_P1_t =  generate_DF(df_comb, 'A_t_PRESS1', dict_P1_AT)\n",
    "        df_FT_P2_t =  generate_DF(df_comb, 'A_t_PRESS2', dict_P2_AT)\n",
    "\n",
    "        #Generate the dataframes for A\n",
    "        df_A_N2DRY = generate_DF(df_comb, 'A_t_DRY', dict_AT)\n",
    "        df_A_t_FEED = generate_DF(df_comb, 'A_t_FEED', dict_N2_AT)\n",
    "        df_A_t_CWSH1 = generate_DF(df_comb, 'A_t_CWSH1', dict_CWSH1_AT)\n",
    "        df_A_t_CWSH2 = generate_DF(df_comb, 'A_t_CWSH2', dict_CWSH2_AT)\n",
    "        df_A_t_PRESS1 = generate_DF(df_comb, 'A_t_PRESS1', dict_P1_AT)\n",
    "        df_A_t_PRESS2 = generate_DF(df_comb, 'A_t_PRESS2', dict_P2_AT)\n",
    "\n",
    "        #Generate the dataframes for B\n",
    "        df_B_N2DRY = generate_DF(df_comb, 'B_t_DRY', dict_BT)\n",
    "        df_B_t_FEED = generate_DF(df_comb, 'B_t_FEED', dict_N2_BT)\n",
    "        df_B_t_CWSH1 = generate_DF(df_comb, 'B_t_CWSH1', dict_CWSH1_BT)\n",
    "        df_B_t_CWSH2 = generate_DF(df_comb, 'B_t_CWSH2', dict_CWSH2_BT)\n",
    "        df_B_t_PRESS1 = generate_DF(df_comb, 'B_t_PRESS1', dict_P1_BT)\n",
    "        df_B_t_PRESS2 = generate_DF(df_comb, 'B_t_PRESS2', dict_P2_BT)\n",
    "\n",
    "\n",
    "        df1A = df_A_N2DRY.join(df_A_t_FEED, how='outer')\n",
    "        df2A = df_A_t_CWSH1.join(df_A_t_CWSH2, how='outer')\n",
    "        df3A = df_A_t_PRESS1.join(df_A_t_PRESS2, how='outer')\n",
    "        df4A = df1A.join(df2A, how='outer')\n",
    "        df5A = df3A.join(df4A, how='outer')\n",
    "\n",
    "        df1B = df_B_N2DRY.join(df_B_t_FEED, how='outer')\n",
    "        df2B = df_B_t_CWSH1.join(df_B_t_CWSH2, how='outer')\n",
    "        df3B = df_B_t_PRESS1.join(df_B_t_PRESS2, how='outer')\n",
    "        df4B = df1B.join(df2B, how='outer')\n",
    "        df5B = df3B.join(df4B, how='outer')\n",
    "\n",
    "    if event == 'EXIT'  or event is None:      \n",
    "        break # exit button clicked      \n",
    "    if event == 'Report_Recent_A_Paramaters':      \n",
    "        print('df5A')\n",
    "    elif event == 'Report_Recent_B_Paramaters':\n",
    "        print('df5A')\n",
    "window.Close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = [[sg.In() ,sg.FileBrowse(file_types=((\"Text Files\", \"*.txt\"),))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PySimpleGUI as sg\n",
    "\n",
    "layout = [\n",
    "    [sg.Text('Name1', size=(15, 1), background_color=\"white\" ), sg.InputText()],\n",
    "    [sg.Text('Name2', size=(15, 1), background_color=\"white\" ), sg.InputText()],\n",
    "    [sg.Text('Name3', size=(15, 1), background_color=\"white\" ), sg.InputText()],\n",
    "\n",
    "    [sg.Submit(), sg.Cancel()]\n",
    "]\n",
    "\n",
    "window = sg.Window('Test', layout, background_color=\"white\")\n",
    "event, values = window.Read()\n",
    "window.Close()\n",
    "\n",
    "if event == 'Submit':\n",
    "    # create before next GUI because I want to use the same name for variable `values`\n",
    "    all_values = values.values() # values from dictionary\n",
    "    text = \"\\n\".join(all_values) # put values in separated lines\n",
    "\n",
    "    layout = [\n",
    "        [sg.Text('Filename', size=(15, 1), background_color=\"white\" ), sg.InputText()],\n",
    "\n",
    "        [sg.Submit(), sg.Cancel()]\n",
    "    ]\n",
    "\n",
    "    window = sg.Window('Test', layout, background_color=\"white\")\n",
    "    event, values = window.Read()\n",
    "    window.Close()\n",
    "\n",
    "    if event == 'Submit':\n",
    "        name_file = values[0]\n",
    "\n",
    "        try:\n",
    "            fh = open(name_file, 'r+')\n",
    "        except FileNotFoundError:\n",
    "            fh = open(name_file, 'w+')\n",
    "\n",
    "        fh.write(text) # write all as one string\n",
    "\n",
    "        fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
