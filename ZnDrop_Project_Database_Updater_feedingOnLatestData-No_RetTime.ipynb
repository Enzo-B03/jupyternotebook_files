{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This program computes the linear regression coefficients and intercept to predict the Zn Drop in  106TK01 from the following features:\n",
    "1. dezn flow\n",
    "2. dezn feed temp\n",
    "3. 105tk05 temp\n",
    "4. H2S flow\n",
    "5. ntrl pls condition\n",
    "Ridge regression is used.\n",
    "\n",
    "\n",
    "This is a continuation from the ZnDrop_Proj_Load_Data_Gathered_2017_to_2020Aug.ipynb file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from dateutil.parser import parse\n",
    "from itertools import compress\n",
    "from collections import OrderedDict\n",
    "from datetime import date\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "import re\n",
    "\n",
    "import openpyxl\n",
    "import random\n",
    "\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 10\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#used in the analysis results data. cleans up the sampling time entry\n",
    "def time_cleaner(x):\n",
    "    time_regex = re.compile(r'[0-8a-zA-Z:]', re.IGNORECASE| re.VERBOSE|re.DOTALL)\n",
    "    timeact = time_regex.findall(x)\n",
    "    newtime = ''.join(timeact)\n",
    "    t = parse(x)\n",
    "    new_str_time = str(t.hour)+':'+str(t.minute)+':'+str(t.second)\n",
    "    return new_str_time\n",
    "def ave_filler(dfname, colname):\n",
    "    dfcn = dfname[colname]\n",
    "    try:        \n",
    "        dfcn = pd.to_numeric(dfcn, errors='coerce')\n",
    "    except:\n",
    "        print('error found in' + str(colname))\n",
    "        pass\n",
    "    try:\n",
    "        dfname[colname] = dfcn.where(dfcn.notnull(), other=(dfcn.fillna(method='ffill') + dfcn.fillna(method='bfill'))/2)\n",
    "    except:\n",
    "        print('nan not fixed' + str(colname))   \n",
    "    return dfname\n",
    "def generate_df_from_analysis(workbookTab, col_sampleDate, col_sampleTime, col_analysis, col_title):\n",
    "    #get the start and end sample dates\n",
    "    Smpl_day_index = list()\n",
    "    Chem_Element_datelist = list()\n",
    "    Chem_Element_list = list()\n",
    "    Smpl_day_index = list()\n",
    "    Chem_Element_datelist = list()\n",
    "    Chem_Element_list = list()\n",
    "    plus_oneday_list = ['0:0:0', '1:0:0', '2:0:0', '3:0:0', '4:0:0', '5:0:0']\n",
    "    #gets the date day from the B column of the analysis file if there is value in the cell\n",
    "    for i in range(1, workbookTab.max_row):\n",
    "        if type(workbookTab[str(col_sampleDate) + str(i)].value) == int or type(workbookTab[str(col_sampleDate) + str(i)].value) == float:\n",
    "            Smpl_day_index.append(i)\n",
    "    #get the ending row that has date day\n",
    "    for j in range(1, workbookTab.max_row):\n",
    "        if type(workbookTab[str(col_sampleTime) + str(j)].value) == datetime.datetime:\n",
    "            smpl_end_index = j\n",
    "    for y in range(0, len(Smpl_day_index)):\n",
    "        if Smpl_day_index[y] != Smpl_day_index[-1]:      \n",
    "            for x in range(Smpl_day_index[y], Smpl_day_index[y+1]):\n",
    "                if workbookTab[str(col_analysis)+str(x)].value is None: \n",
    "                    pass\n",
    "                else:\n",
    "                    if time_cleaner(str(workbookTab[str(col_sampleTime)+str(x)].value)) in plus_oneday_list:\n",
    "                        date = str((currentmonthyr)+datetime.timedelta(workbookTab[str(col_sampleDate)+str(Smpl_day_index[y])].value))\\\n",
    "                        +' '+time_cleaner(str(workbookTab[str(col_sampleTime)+str(x)].value))\n",
    "                        Chem_Element_datelist.append(parse(date))  \n",
    "                        chem_element = workbookTab[str(col_analysis)+str(x)].value\n",
    "                        Chem_Element_list.append(chem_element)\n",
    "                    else:\n",
    "                        date = str((currentmonthyr)-datetime.timedelta(1)+datetime.timedelta(workbookTab[str(col_sampleDate)+str(Smpl_day_index[y])].value))\\\n",
    "                        +' '+time_cleaner(str(workbookTab[str(col_sampleTime)+str(x)].value))\n",
    "                        Chem_Element_datelist.append(parse(date))  \n",
    "                        chem_element = workbookTab[str(col_analysis)+str(x)].value\n",
    "                        Chem_Element_list.append(chem_element)\n",
    "\n",
    "        if Smpl_day_index[y] == Smpl_day_index[-1]:\n",
    "            for x in range(Smpl_day_index[y], smpl_end_index+1):\n",
    "                if workbookTab[str(col_analysis)+str(x)].value is None:   \n",
    "                    pass\n",
    "                else:\n",
    "                    if time_cleaner(str(workbookTab[str(col_sampleTime)+str(x)].value)) in plus_oneday_list:\n",
    "                        date = str((currentmonthyr)+datetime.timedelta(workbookTab[str(col_sampleDate)+str(Smpl_day_index[y])].value))\\\n",
    "                        +' '+time_cleaner(str(workbookTab[str(col_sampleTime)+str(x)].value))\n",
    "                        Chem_Element_datelist.append(parse(date))\n",
    "                        chem_element = workbookTab[str(col_analysis)+str(x)].value\n",
    "                        Chem_Element_list.append(chem_element)\n",
    "                    else:\n",
    "                        date = str((currentmonthyr)-datetime.timedelta(1)+datetime.timedelta(workbookTab[str(col_sampleDate)+str(Smpl_day_index[y])].value))\\\n",
    "                        +' '+time_cleaner(str(workbookTab[str(col_sampleTime)+str(x)].value))\n",
    "                        Chem_Element_datelist.append(parse(date))\n",
    "                        chem_element = workbookTab[str(col_analysis)+str(x)].value\n",
    "                        Chem_Element_list.append(chem_element)\n",
    "\n",
    "    Chem_Element_list_pair = list(zip(Chem_Element_list, Chem_Element_datelist[0:]))\n",
    "    Chem_Element_df = pd.DataFrame(Chem_Element_list_pair)\n",
    "    Chem_Element_df.columns = [col_title, 'DATETIME'] ##check if list title is updated\n",
    "    Chem_Element_df.set_index('DATETIME', inplace=True)\n",
    "\n",
    "    return Chem_Element_df\n",
    "\n",
    "def generate_add_trace(figname, df_elemental, axis_bool):\n",
    "    colname = df_elemental.columns[0]\n",
    "    figname.add_trace(go.Scatter(x=df_elemental.index, y=df_elemental[colname], name=colname), secondary_y=axis_bool,)\n",
    "#---------------------------------------\n",
    "\n",
    "class LabResults():\n",
    "    def __init__(self, monthyear, filePath):\n",
    "        #____monthyear format examle is datetime.date(2020,7,1)\n",
    "        #____filepath example is '\\\\thgobna001\\userdata\\THPAL\\...\\ANALYSIS RESULTS 2020\\7) July _2020.xlsx'\n",
    "        #____add r' at the start of the filepath to apply the regex that allows the use of the filepath as raw\n",
    "        #____sef.workbook is the uploaded excel workbook of the entire analysis files so it takes time to load\n",
    "        #____Create an instance of the workbook by giving it a varible name with the sample format: Jan_2020\n",
    "        \n",
    "        import openpyxl\n",
    "        import io\n",
    "        with open(filePath, \"rb\") as f:\n",
    "            in_mem_file = io.BytesIO(f.read())\n",
    "        \n",
    "        self.workbook = openpyxl.load_workbook(in_mem_file, data_only=True)\n",
    "        self.monthyear = monthyear   \n",
    "        \n",
    "    def generate_df_from_analysis(self, tabname, list_lab_index):\n",
    "        #____tabname is a string type name of the tab in the laboratory analysis excel file.\n",
    "        #____-------Example tabnames: '104PU01', '105TK03', '106TK01'\n",
    "        #____-------Inside these tabs are the specific analysis results done on the sample taken from the 'tabname' area .\n",
    "        #____list_lab_index is a list with the sample format is: ['B', 'C', 'E', '104_Pb']\n",
    "        #____-------the first letter 'B' is the column letter where the day of the month is written as integers 1,2,3..30\n",
    "        #____-------the second letter 'C' is the column letter where the sampling time is written; e.g. '7:00:00 AM'\n",
    "        #____-------the third letter 'E' is the column where the results of the specific analysis are listed\n",
    "        #____-------the last item in the list is the string you'll use as the new title; e.g. '104_Pb'\n",
    "        \n",
    "        workbookTab = self.workbook[tabname]\n",
    "        self.list_lab_index = list_lab_index\n",
    "        col_sampleDate = self.list_lab_index[0]\n",
    "        col_sampleTime = self.list_lab_index[1]\n",
    "        col_analysis = self.list_lab_index[2]\n",
    "        col_title = self.list_lab_index[3]\n",
    "        currentmonthyr = self.monthyear\n",
    "        \n",
    "        #get the start and end sample dates\n",
    "        Smpl_day_index = list()\n",
    "        Chem_Element_datelist = list()\n",
    "        Chem_Element_list = list()\n",
    "        Smpl_day_index = list()\n",
    "        Chem_Element_datelist = list()\n",
    "        Chem_Element_list = list()\n",
    "        plus_oneday_list = ['0:0:0', '1:0:0', '2:0:0', '3:0:0', '4:0:0', '5:0:0']\n",
    "        #gets the date day from the B column of the analysis file if there is value in the cell\n",
    "        for i in range(1, workbookTab.max_row):\n",
    "            if type(workbookTab[str(col_sampleDate) + str(i)].value) == int or type(workbookTab[str(col_sampleDate) + str(i)].value) == float:\n",
    "                Smpl_day_index.append(i)\n",
    "        #get the ending row that has date day\n",
    "        for j in range(1, workbookTab.max_row):\n",
    "            if type(workbookTab[str(col_sampleTime) + str(j)].value) == datetime.datetime:\n",
    "                smpl_end_index = j\n",
    "        for y in range(0, len(Smpl_day_index)):\n",
    "            if Smpl_day_index[y] != Smpl_day_index[-1]:      \n",
    "                for x in range(Smpl_day_index[y], Smpl_day_index[y+1]):\n",
    "                    if workbookTab[str(col_analysis)+str(x)].value is None: \n",
    "                        pass\n",
    "                    else:\n",
    "                        try:\n",
    "                            if time_cleaner(str(workbookTab[str(col_sampleTime)+str(x)].value)) in plus_oneday_list:\n",
    "                                date = str((currentmonthyr)+datetime.timedelta(workbookTab[str(col_sampleDate)+str(Smpl_day_index[y])].value))\\\n",
    "                                +' '+time_cleaner(str(workbookTab[str(col_sampleTime)+str(x)].value))\n",
    "                                Chem_Element_datelist.append(parse(date))  \n",
    "                                chem_element = workbookTab[str(col_analysis)+str(x)].value\n",
    "                                Chem_Element_list.append(chem_element)\n",
    "                            else:\n",
    "                                date = str((currentmonthyr)-datetime.timedelta(1)+datetime.timedelta(workbookTab[str(col_sampleDate)+str(Smpl_day_index[y])].value))\\\n",
    "                                +' '+time_cleaner(str(workbookTab[str(col_sampleTime)+str(x)].value))\n",
    "                                Chem_Element_datelist.append(parse(date))  \n",
    "                                chem_element = workbookTab[str(col_analysis)+str(x)].value\n",
    "                                Chem_Element_list.append(chem_element)\n",
    "                        except:\n",
    "                            pass\n",
    "\n",
    "            if Smpl_day_index[y] == Smpl_day_index[-1]:\n",
    "                for x in range(Smpl_day_index[y], smpl_end_index+1):\n",
    "                    if workbookTab[str(col_analysis)+str(x)].value is None:   \n",
    "                        pass\n",
    "                    else:\n",
    "                        try:\n",
    "                            if time_cleaner(str(workbookTab[str(col_sampleTime)+str(x)].value)) in plus_oneday_list:\n",
    "                                date = str((currentmonthyr)+datetime.timedelta(workbookTab[str(col_sampleDate)+str(Smpl_day_index[y])].value))\\\n",
    "                                +' '+time_cleaner(str(workbookTab[str(col_sampleTime)+str(x)].value))\n",
    "                                Chem_Element_datelist.append(parse(date))\n",
    "                                chem_element = workbookTab[str(col_analysis)+str(x)].value\n",
    "                                Chem_Element_list.append(chem_element)\n",
    "                            else:\n",
    "                                date = str((currentmonthyr)-datetime.timedelta(1)+datetime.timedelta(workbookTab[str(col_sampleDate)+str(Smpl_day_index[y])].value))\\\n",
    "                                +' '+time_cleaner(str(workbookTab[str(col_sampleTime)+str(x)].value))\n",
    "                                Chem_Element_datelist.append(parse(date))\n",
    "                                chem_element = workbookTab[str(col_analysis)+str(x)].value\n",
    "                                Chem_Element_list.append(chem_element)\n",
    "                        except:\n",
    "                            pass\n",
    "\n",
    "        Chem_Element_list_pair = list(zip(Chem_Element_list, Chem_Element_datelist[0:]))\n",
    "        Chem_Element_df = pd.DataFrame(Chem_Element_list_pair)\n",
    "        Chem_Element_df.columns = [col_title, 'DATETIME'] ##check if list title is updated\n",
    "        Chem_Element_df.set_index('DATETIME', inplace=True)\n",
    "\n",
    "        return Chem_Element_df\n",
    "    \n",
    "def join_DF(dfsList1):\n",
    "    df = dfsList1[0]\n",
    "    for i in range(1,len(dfsList1)):\n",
    "        df = df.join(dfsList1[i], how='outer')\n",
    "    return df\n",
    "\n",
    "def append_monthsDF(dfsListmonthly): #takes the list of dataframes from monthly lab results of one sampling area\n",
    "    df = dfsListmonthly[0]\n",
    "    for i in range(1,len(dfsListmonthly)):\n",
    "        df = df.append(dfsListmonthly[i], ignore_index=True)\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "#-------Load the DF_combined data from ZnDrop_Proj_Load_Data_Gathered_2017_to_2020Aug.ipynb file\n",
    "\n",
    "DF_NTRL_TK0513_MSTK01 = pd.read_excel(r'C:\\Users\\v.t.flores\\Documents\\df_ZnDrop_project_105TK05_2017_2020_PIdata.xlsx')\n",
    "\n",
    "DF_NTRL_TK0513_MSTK01_1 = DF_NTRL_TK0513_MSTK01.set_index('DATETIME')\n",
    "\n",
    "#convert the df to numeric\n",
    "for i in DF_NTRL_TK0513_MSTK01_1.columns:\n",
    "    DF_NTRL_TK0513_MSTK01_1[i] = pd.to_numeric(DF_NTRL_TK0513_MSTK01_1[i], errors='coerce')\n",
    "#\n",
    "#\n",
    "#-------------note that we use the interpolate to fill in missing values with linear interpolation\n",
    "#\n",
    "DF_NTRL_TK0513_MSTK01_2 = DF_NTRL_TK0513_MSTK01_1.interpolate(method='linear', limit_direction='forward', axis=0)    \n",
    "\n",
    "\n",
    "for col in DF_NTRL_TK0513_MSTK01_2.columns:\n",
    "    DF_NTRL_TK0513_MSTK01_2[col] = pd.to_numeric(DF_NTRL_TK0513_MSTK01_2[col], errors='coerce')\n",
    "\n",
    "DF_NTRL_TK0513_MSTK01_4 = DF_NTRL_TK0513_MSTK01_2.dropna()\n",
    "\n",
    "DF_NTRL_TK0513_MSTK01_4['Zn_drop_act'] = DF_NTRL_TK0513_MSTK01_4['Zn_drop_act']*100\n",
    "\n",
    "zndrop_predictors = ['104_Pb', '104_Zn', '104_Cu', '104_Ni', '104_Co', '104_Fe', '104_Mn',\n",
    "       '104_Cr', '104_Ca', '104_Si', '104_Al', '104_Mg', '104_Fe2', '104_pH60',\n",
    "       '104_ORP', '104_NTU', '104_Ft', 'tk13_Zn', 'tk13_solids%',\n",
    "       'DeZn_Feed_Flow', 'DeZn_Feed_T',\n",
    "       'DeZn_Seed_Flow', 'DeZn_TK05_T',\n",
    "       'H2S_tk01', 'H2S_tk02', 'tk05_Al', 'tk05_Ca', 'tk05_Co', 'tk05_Cr',\n",
    "       'tk05_Cu', 'tk05_Fe', 'tk05_Mg', 'tk05_Mn', 'tk05_Ni', 'tk05_Pb',\n",
    "       'tk05_Si', 'tk05_Zn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For 2014-16 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from ZnDrop_Proj_Load_Data_Gathered_2014_to_2016.ipynb. It's the excel file exported from this ipynb\n",
    "\n",
    "DF_NTRL_TK0513_MSTK01_2014_2016 = pd.read_excel(r'C:\\Users\\v.t.flores\\Documents\\df_ZnDrop_project_105TK05_2014_2016_PIdata.xlsx')\n",
    "\n",
    "DF_NTRL_TK0513_MSTK01_2014_2016_1 = DF_NTRL_TK0513_MSTK01_2014_2016.set_index('DATETIME')\n",
    "\n",
    "#convert the df to numeric\n",
    "for i in DF_NTRL_TK0513_MSTK01_2014_2016_1.columns:\n",
    "    DF_NTRL_TK0513_MSTK01_2014_2016_1[i] = pd.to_numeric(DF_NTRL_TK0513_MSTK01_2014_2016_1[i], errors='coerce')\n",
    "#\n",
    "#\n",
    "#-------------note that we use the interpolate to fill in missing values with linear interpolation\n",
    "#\n",
    "DF_NTRL_TK0513_MSTK01_2014_2016_1_2 = DF_NTRL_TK0513_MSTK01_2014_2016_1.interpolate(method='linear', limit_direction='forward', axis=0)    \n",
    "\n",
    "for i in DF_NTRL_TK0513_MSTK01_2014_2016_1_2.columns:\n",
    "    DF_NTRL_TK0513_MSTK01_2014_2016_1_2[i] = pd.to_numeric(DF_NTRL_TK0513_MSTK01_2014_2016_1_2[i], errors='coerce')\n",
    "\n",
    "DF_NTRL_TK0513_MSTK01_4_201516 = DF_NTRL_TK0513_MSTK01_2014_2016_1_2.interpolate(method='linear', limit_direction='forward')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_main_201516 = DF_NTRL_TK0513_MSTK01_4_201516.drop(['105_Zn', '106_Zn'], axis=1)\n",
    "DF_main_20172020 = DF_NTRL_TK0513_MSTK01_4.drop('Zn_drop', axis=1)\n",
    "\n",
    "DF_main_201516.columns = ['104_Pb', '104_Zn', '104_Cu', '104_Ni', '104_Co', '104_Fe', '104_Mn',\n",
    "       '104_Cr', '104_Ca', '104_Si', '104_Al', '104_Mg', '104_Fe2', '104_pH60',\n",
    "       '104_ORP', '104_NTU', '104_Ft', 'tk13_Zn', 'tk13_solids%',\n",
    "       'DeZn_Feed_Flow', 'DeZn_Feed_T', 'H2S_FT_TK01_A', 'H2S_FT_TK01_B',\n",
    "       'H2S_FT_TK02_A', 'H2S_FT_TK02_B', 'DeZn_Seed_Flow', 'DeZn_TK05_T',\n",
    "       'H2S_tk01', 'H2S_tk02', 'Zn_drop_act', 'tk05_Al', 'tk05_Ca', 'tk05_Co',\n",
    "       'tk05_Cr', 'tk05_Cu', 'tk05_Fe', 'tk05_Mg', 'tk05_Mn', 'tk05_Ni',\n",
    "       'tk05_Pb', 'tk05_Si', 'tk05_Zn']\n",
    "\n",
    "\n",
    "#append the datasets cto combine the 2015 to 2020 data\n",
    "#\n",
    "DF_MAIN_2015_2020 = DF_main_201516.append(DF_main_20172020, sort=True)\n",
    "#DF_MAIN_2015_2020 = DF_main_201516.append(DF_main_20172020, sort=True).interpolate(method='linear', limit_direction='forward' ).dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the filepaths and the monthyr data for year 2019\n",
    "currentmonthyr_09_2020 = datetime.date(2020,9,1)\n",
    "\n",
    "#filepath\n",
    "filepath_09_2020 = r'\\\\thgobna001\\userdata\\THPAL\\Department\\TAGANITO\\SHARED\\AnalysisResult\\ANALYSIS RESULTS 2020\\9) September _2020.xlsx'\n",
    "\n",
    "ntrl_Pb_3 = ['B', 'C', 'E', '104_Pb']\n",
    "ntrl_Zn_3 = ['B', 'C', 'F', '104_Zn']\n",
    "ntrl_Cu_3 = ['B', 'C', 'G', '104_Cu']\n",
    "ntrl_Ni_3 = ['B', 'C', 'H', '104_Ni']\n",
    "ntrl_Co_3 = ['B', 'C', 'I', '104_Co']\n",
    "ntrl_Fe_3 = ['B', 'C', 'J', '104_Fe']\n",
    "ntrl_Mn_3 = ['B', 'C', 'K', '104_Mn']\n",
    "ntrl_Cr_3 = ['B', 'C', 'L', '104_Cr']\n",
    "ntrl_Ca_3 = ['B', 'C', 'M', '104_Ca']\n",
    "ntrl_Si_3 = ['B', 'C', 'N', '104_Si']\n",
    "ntrl_Al_3 = ['B', 'C', 'O', '104_Al']\n",
    "ntrl_Mg_3 = ['B', 'C', 'P', '104_Mg']\n",
    "ntrl_Fe2_3 = ['B', 'C', 'R', '104_Fe2']\n",
    "ntrl_pH60_3 = ['B', 'C', 'BB', '104_pH60'] # check\n",
    "ntrl_ORP_3 = ['B', 'C', 'AJ', '104_ORP'] \n",
    "ntrl_NTU_3 = ['B', 'C', 'AN', '104_NTU'] # check\n",
    "ntrl_Ft_3 = ['B', 'C', 'AW', '104_Ft'] #check\n",
    "\n",
    "tk13_Zn_3 = ['B', 'C', 'E', 'tk13_Zn']\n",
    "tk13_Solids_3 = ['B', 'C', 'AZ', 'tk13_solids%'] #check\n",
    "\n",
    "MStk01_Zn_drop_3 = ['B', 'C', 'BD', 'Zn_drop']\n",
    "\n",
    "\n",
    "tk05_Pb = ['B', 'C', 'E', 'tk05_Pb']\n",
    "tk05_Zn = ['B', 'C', 'F', 'tk05_Zn']\n",
    "tk05_Cu = ['B', 'C', 'G', 'tk05_Cu']\n",
    "tk05_Ni = ['B', 'C', 'H', 'tk05_Ni']\n",
    "tk05_Co = ['B', 'C', 'I', 'tk05_Co']\n",
    "tk05_Fe = ['B', 'C', 'J', 'tk05_Fe']\n",
    "tk05_Mn = ['B', 'C', 'K', 'tk05_Mn']\n",
    "tk05_Cr = ['B', 'C', 'L', 'tk05_Cr']\n",
    "tk05_Ca = ['B', 'C', 'M', 'tk05_Ca']\n",
    "tk05_Si = ['B', 'C', 'N', 'tk05_Si']\n",
    "tk05_Al = ['B', 'C', 'O', 'tk05_Al']\n",
    "tk05_Mg = ['B', 'C', 'P', 'tk05_Mg']\n",
    " \n",
    "monthLab_3 = LabResults(currentmonthyr_09_2020, filepath_09_2020)\n",
    "df_month_3 = monthLab_3.generate_df_from_analysis('104PU01', ntrl_Pb_3).join(\n",
    "    monthLab_3.generate_df_from_analysis('104PU01', ntrl_Zn_3), how='outer').join(\n",
    "    monthLab_3.generate_df_from_analysis('104PU01', ntrl_Cu_3), how='outer').join(\n",
    "    monthLab_3.generate_df_from_analysis('104PU01', ntrl_Ni_3), how='outer').join(\n",
    "    monthLab_3.generate_df_from_analysis('104PU01', ntrl_Co_3), how='outer').join(\n",
    "    monthLab_3.generate_df_from_analysis('104PU01', ntrl_Fe_3), how='outer').join(\n",
    "    monthLab_3.generate_df_from_analysis('104PU01', ntrl_Mn_3), how='outer').join(\n",
    "    monthLab_3.generate_df_from_analysis('104PU01', ntrl_Cr_3), how='outer').join(\n",
    "    monthLab_3.generate_df_from_analysis('104PU01', ntrl_Ca_3), how='outer').join(\n",
    "    monthLab_3.generate_df_from_analysis('104PU01', ntrl_Si_3), how='outer').join(\n",
    "    monthLab_3.generate_df_from_analysis('104PU01', ntrl_Al_3), how='outer').join(\n",
    "    monthLab_3.generate_df_from_analysis('104PU01', ntrl_Mg_3), how='outer').join(\n",
    "    monthLab_3.generate_df_from_analysis('104PU01', ntrl_Fe2_3), how='outer').join(\n",
    "    monthLab_3.generate_df_from_analysis('104PU01', ntrl_pH60_3), how='outer').join(\n",
    "    monthLab_3.generate_df_from_analysis('104PU01', ntrl_ORP_3), how='outer').join(\n",
    "    monthLab_3.generate_df_from_analysis('104PU01', ntrl_NTU_3), how='outer').join(\n",
    "    monthLab_3.generate_df_from_analysis('104PU01', ntrl_Ft_3), how='outer').join(\n",
    "    monthLab_3.generate_df_from_analysis('105TK13', tk13_Zn_3), how='outer').join(\n",
    "    monthLab_3.generate_df_from_analysis('105TK13', tk13_Solids_3), how='outer').join(\n",
    "    monthLab_3.generate_df_from_analysis('106TK01', MStk01_Zn_drop_3), how='outer').join(\n",
    "    monthLab_3.generate_df_from_analysis('105TK05', tk05_Pb).join(\n",
    "        monthLab_3.generate_df_from_analysis('105TK05', tk05_Zn), how='outer').join(\n",
    "        monthLab_3.generate_df_from_analysis('105TK05', tk05_Cu), how='outer').join(\n",
    "        monthLab_3.generate_df_from_analysis('105TK05', tk05_Ni), how='outer').join(\n",
    "        monthLab_3.generate_df_from_analysis('105TK05', tk05_Co), how='outer').join(\n",
    "        monthLab_3.generate_df_from_analysis('105TK05', tk05_Fe), how='outer').join(\n",
    "        monthLab_3.generate_df_from_analysis('105TK05', tk05_Mn), how='outer').join(\n",
    "        monthLab_3.generate_df_from_analysis('105TK05', tk05_Cr), how='outer').join(\n",
    "        monthLab_3.generate_df_from_analysis('105TK05', tk05_Ca), how='outer').join(\n",
    "        monthLab_3.generate_df_from_analysis('105TK05', tk05_Si), how='outer').join(\n",
    "        monthLab_3.generate_df_from_analysis('105TK05', tk05_Al), how='outer').join(\n",
    "        monthLab_3.generate_df_from_analysis('105TK05', tk05_Mg), how='outer'))\n",
    "\n",
    "for i in df_month_3.columns:\n",
    "    df_month_3[i] = pd.to_numeric(df_month_3[i], errors='coerce')\n",
    "\n",
    "df_month_3 = df_month_3.interpolate(method='linear', limit_direction='forward', axis=0)\n",
    "df_month_3['Zn_drop_act'] = df_month_3['Zn_drop']*100\n",
    "\n",
    "\n",
    "df_month_3_a = df_month_3.drop('Zn_drop', axis=1)\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------Code for predicting the Zn drop value in 106TK01 by applying the coefficients  from RidgeRegression----------#\n",
    "\n",
    "#----Importing the Pi data for MS flow, rec gas, feed temp\n",
    "df_MSPi = pd.read_excel(r'C:\\Users\\v.t.flores\\Documents\\ZnDrop_Project_Pi_Sept2020.xlsx', sheet_name='PI_sept2020', index_col=False)\n",
    "\n",
    "#------------------Drop the row[0]. This is the title tag use in the pi datalink. We don't need it in pandas df.\n",
    "#------------------What remain are the column title and the rest of the rows of data.\n",
    "\n",
    "df_MSPi = df_MSPi.drop(df_MSPi.index[0])\n",
    "\n",
    "#Step2: Parse the DATETIME column\n",
    "df_MSPi['DATETIME'] = df_MSPi['DATETIME'].apply(lambda x: parse(str(x)))\n",
    "df_MSPi.set_index('DATETIME', inplace=True)\n",
    "\n",
    "\n",
    "# Step3: Convert each column to numeric to handle nan values and other comments like 'No data...'. Convering to numeric\n",
    "#------ converts them into a NaN value that pandas understands.\n",
    "for i in df_MSPi.columns:\n",
    "    df_MSPi[i] = pd.to_numeric(df_MSPi[i], errors='coerce')\n",
    "\n",
    "#Creating a column for the correct H2S flowrate\n",
    "df_MSPi['H2S_tk01'] = np.where(df_MSPi['H2S_FT_TK01_A']>df_MSPi['H2S_FT_TK01_B'],\\\n",
    "                                    df_MSPi['H2S_FT_TK01_A'], df_MSPi['H2S_FT_TK01_B'])\n",
    "\n",
    "df_MSPi['H2S_tk02'] = np.where(df_MSPi['H2S_FT_TK02_A']>df_MSPi['H2S_FT_TK02_B'],\\\n",
    "                                    df_MSPi['H2S_FT_TK02_A'], df_MSPi['H2S_FT_TK02_B'])    \n",
    "\n",
    "DF_labdata_and_Pi_Sept2020 = df_month_3_a.join(df_MSPi, how='outer')\n",
    "\n",
    "DF_labdata_and_Pi_Sept2020_ntrpltd = DF_labdata_and_Pi_Sept2020.interpolate(method='linear', limit_direction='both', axis=0)\n",
    "\n",
    "DF_MAIN_2015_2020 = DF_MAIN_2015_2020.append(DF_labdata_and_Pi_Sept2020_ntrpltd, sort=True)\n",
    "\n",
    "DF_MAIN_2015_2020 = DF_MAIN_2015_2020.interpolate(method='linear', limit_direction='forward' ).dropna()\n",
    "\n",
    "DF_NTRL_TK0513_MSTK01_4 = DF_MAIN_2015_2020\n",
    "\n",
    "DF_NTRL_TK0513_MSTK01_5 = DF_NTRL_TK0513_MSTK01_4[DF_NTRL_TK0513_MSTK01_4['H2S_tk01']>5] #----------------------filter_H2S_flow\n",
    "DF_NTRL_TK0513_MSTK01_5 = DF_NTRL_TK0513_MSTK01_5[DF_NTRL_TK0513_MSTK01_5['DeZn_Feed_T']>50] #----------------------filter_feedTemp\n",
    "\n",
    "#Clean data. Remove outliers\n",
    "# remove pH outliers below 2.0 or above 4\n",
    "DF_NTRL_TK0513_MSTK01_5[(DF_NTRL_TK0513_MSTK01_5['104_pH60']<2.0) | (DF_NTRL_TK0513_MSTK01_5['104_pH60']>4.0)]['104_pH60']\n",
    "\n",
    "DF_clean1 = DF_NTRL_TK0513_MSTK01_5\n",
    "DF_clean1_pH = DF_clean1.drop((DF_clean1[(DF_clean1['104_pH60']<2.0) | (DF_clean1['104_pH60']>4.0)].index))\n",
    "DF_clean1_pHFe = DF_clean1_pH.drop((DF_clean1_pH[DF_clean1_pH['104_Fe']<0.1].index))\n",
    "DF_clean1_pHFeNTU = DF_clean1_pHFe.drop((DF_clean1_pHFe[DF_clean1_pHFe['104_NTU']>1000].index))\n",
    "DF_clean1_pHFeNTUORP = DF_clean1_pHFeNTU.drop((DF_clean1_pHFeNTU[(DF_clean1_pHFeNTU['104_ORP']<90) | (DF_clean1_pHFeNTU['104_ORP']>1000)].index))\n",
    "DF_clean1_pHFeNTUORPMg = DF_clean1_pHFeNTUORP.drop(DF_clean1_pHFeNTUORP[DF_clean1_pHFeNTUORP['104_Mg']<1].index)\n",
    "DF_clean1_pHFeNTUORPMgPb = DF_clean1_pHFeNTUORPMg.drop((DF_clean1_pHFeNTUORPMg[DF_clean1_pHFeNTUORPMg['104_Pb']>0.001].index))\n",
    "DF_clean1_pHFeNTUORPMgPbMn = DF_clean1_pHFeNTUORPMgPb.drop(DF_clean1_pHFeNTUORPMgPb[DF_clean1_pHFeNTUORPMgPb['104_Mn']<1].index)\n",
    "DF_clean1_pHFeNTUORPMgPbMnAl = DF_clean1_pHFeNTUORPMgPbMn.drop(DF_clean1_pHFeNTUORPMgPbMn[DF_clean1_pHFeNTUORPMgPbMn['104_Al']<1].index)\n",
    "DF_clean1_pHFeNTUORPMgPbMnAlSi = DF_clean1_pHFeNTUORPMgPbMnAl.drop(DF_clean1_pHFeNTUORPMgPbMnAl[DF_clean1_pHFeNTUORPMgPbMnAl['104_Si']>2].index)\n",
    "DF_clean1_pHFeNTUORPMgPbMnAlSiZn = DF_clean1_pHFeNTUORPMgPbMnAlSi.drop(DF_clean1_pHFeNTUORPMgPbMnAlSi[DF_clean1_pHFeNTUORPMgPbMnAlSi['104_Zn']>0.2].index)\n",
    "DF_clean1_pHFeNTUORPMgPbMnAlSiZnCu = DF_clean1_pHFeNTUORPMgPbMnAlSiZn.drop(DF_clean1_pHFeNTUORPMgPbMnAlSiZn[DF_clean1_pHFeNTUORPMgPbMnAlSiZn['104_Cu']>0.1].index)\n",
    "DF_clean1_pHFeNTUORPMgPbMnAlSiZnCuFe2 = DF_clean1_pHFeNTUORPMgPbMnAlSiZnCu.drop(DF_clean1_pHFeNTUORPMgPbMnAlSiZnCu[DF_clean1_pHFeNTUORPMgPbMnAlSiZnCu['104_Fe2']<0.01].index)\n",
    "DF_clean1_pHFeNTUORPMgPbMnAlSiZnCuFe2Cr = DF_clean1_pHFeNTUORPMgPbMnAlSiZnCuFe2.drop(DF_clean1_pHFeNTUORPMgPbMnAlSiZnCuFe2[DF_clean1_pHFeNTUORPMgPbMnAlSiZnCuFe2['104_Cr']<0.05].index)\n",
    "DF_clean1_pHFeNTUORPMgPbMnAlSiZnCuFe2CrCa = DF_clean1_pHFeNTUORPMgPbMnAlSiZnCuFe2Cr.drop(DF_clean1_pHFeNTUORPMgPbMnAlSiZnCuFe2Cr[DF_clean1_pHFeNTUORPMgPbMnAlSiZnCuFe2Cr['104_Ca']<0.09].index)\n",
    "DF_clean2 = DF_clean1_pHFeNTUORPMgPbMnAlSiZnCuFe2CrCa\n",
    "\n",
    "DF_clean3_CaAl = DF_clean2.drop(DF_clean2[DF_clean2['tk05_Al']<1.0].index)\n",
    "DF_clean3_CaAlFeedF = DF_clean3_CaAl.drop(DF_clean3_CaAl[DF_clean3_CaAl['DeZn_Feed_Flow']<300].index)\n",
    "DF_clean3_CaAlFeedFZn = DF_clean3_CaAlFeedF.drop(DF_clean3_CaAlFeedF[DF_clean3_CaAlFeedF['tk05_Zn']<0.0001].index)\n",
    "DF_clean3_CaAlFeedFZnCo = DF_clean3_CaAlFeedFZn.drop(DF_clean3_CaAlFeedFZn[DF_clean3_CaAlFeedFZn['tk05_Co']<0.04].index)\n",
    "DF_clean3_CaAlFeedFZnCo2 = DF_clean3_CaAlFeedFZnCo.drop(DF_clean3_CaAlFeedFZnCo[DF_clean3_CaAlFeedFZnCo['tk05_Co']>0.9].index)\n",
    "DF_main_FULL_CLEAN = DF_clean3_CaAlFeedFZnCo2\n",
    "\n",
    "DF = DF_main_FULL_CLEAN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "def MSridge_regression(data, predictors, alpha, models_to_plot={}):\n",
    "    #Fit the model\n",
    "    ridgereg = Ridge(alpha=alpha,normalize=True)\n",
    "    ridgereg.fit(data[predictors],data['Zn_drop_act'])\n",
    "    y_pred = ridgereg.predict(data[predictors])\n",
    "    \n",
    "    rcParams['figure.figsize'] = 14, 12\n",
    "    #Check if a plot is to be made for the entered alpha\n",
    "    if alpha in models_to_plot:\n",
    "        plt.subplot(models_to_plot[alpha])\n",
    "        plt.tight_layout()\n",
    "        plt.plot(data.index,y_pred)\n",
    "        plt.plot(data.index, data['Zn_drop_act'],'.')\n",
    "        plt.title('Plot for alpha: %.3g'%alpha)\n",
    "    \n",
    "    #Return the result in pre-defined format\n",
    "    rss = sum((y_pred-data['Zn_drop_act'])**2)\n",
    "    ret = [rss]\n",
    "    ret.extend([ridgereg.intercept_])\n",
    "    ret.extend(ridgereg.coef_)\n",
    "    return ret\n",
    "\n",
    "#Initialize predictors to be set of 15 powers of x\n",
    "#predictors=['x']\n",
    "#predictors.extend(['x_%d'%i for i in range(2,16)])\n",
    "\n",
    "#Set the different values of alpha to be tested\n",
    "alpha_ridge = [1e-15, 1e-10, 1e-8, 1e-4, 1e-3,1e-2, 1, 5, 10, 20]\n",
    "\n",
    "#Initialize the dataframe for storing coefficients.\n",
    "col = ['rss','intercept'] + ['coef_x_%d'%i for i in range(1,16)]\n",
    "ind = ['alpha_%.2g'%alpha_ridge[i] for i in range(0,10)]\n",
    "coef_matrix_ridge = pd.DataFrame(index=ind, columns=col)\n",
    "\n",
    "models_to_plot = {1e-15:231, 1e-10:232, 1e-4:233, 1e-3:234, 1e-2:235, 5:236}\n",
    "\n",
    "\n",
    "zndrop_predictors = ['104_Pb', '104_Zn', '104_Cu', '104_Ni', '104_Co', '104_Fe', '104_Mn',\n",
    "       '104_Cr', '104_Ca', '104_Si', '104_Al', '104_Mg', '104_Fe2', '104_pH60_exp',\n",
    "       '104_ORP', '104_NTU', '104_Ft', 'tk13_Zn', 'tk13_solids%',\n",
    "       'DeZn_Feed_Flow', 'DeZn_Feed_T',\n",
    "       'DeZn_TK05_T',\n",
    "       'H2S_tk01', 'H2S_tk02', 'tk05_Al', 'tk05_Ca', 'tk05_Co', 'tk05_Cr',\n",
    "       'tk05_Cu', 'tk05_Fe', 'tk05_Mg', 'tk05_Mn', 'tk05_Ni', 'tk05_Pb',\n",
    "       'tk05_Si', 'tk05_Zn']\n",
    "\n",
    "for i in range(10):\n",
    "    MSridge_regression(DF_main_FULL_CLEAN, zndrop_predictors, alpha_ridge[i], models_to_plot)\n",
    "    \n",
    "    \n",
    "ridgereg = Ridge(alpha=.001,normalize=True)\n",
    "ridgereg.fit(DF_main_FULL_CLEAN[zndrop_predictors],DF_main_FULL_CLEAN['Zn_drop_act'])\n",
    "y_pred = ridgereg.predict(DF_main_FULL_CLEAN[zndrop_predictors])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.plot(DF_main_FULL_CLEAN['Zn_drop_act'].index, y_pred)\n",
    "plt.plot(DF_main_FULL_CLEAN['Zn_drop_act'].index, DF_main_FULL_CLEAN['Zn_drop_act'],'.')\n",
    "\n",
    "reg_intercept = ridgereg.intercept_\n",
    "reg_coef = ridgereg.coef_\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export the regression coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "df_reg_coef_intercepts_zndropPred = pd.DataFrame(reg_coef)\n",
    "df_reg_coef_intercepts_zndropPred['ridgereg_intercept_ZnDropPred'] = reg_intercept\n",
    "\n",
    "df_reg_coef_intercepts_zndropPred.columns = ['Parameters_coef', 'intercept']\n",
    "\n",
    "#df_reg_coef_intercepts_zndropPred.to_excel(r'C:\\Users\\v.t.flores\\Documents\\df_reg_coef_intercepts_zndropPred_rev2_20152020_plus_Sept.xlsx')\n",
    "\n",
    "zndrop_predictors = ['104_Pb', '104_Zn', '104_Cu', '104_Ni', '104_Co', '104_Fe', '104_Mn',\n",
    "       '104_Cr', '104_Ca', '104_Si', '104_Al', '104_Mg', '104_Fe2', '104_pH60_exp',\n",
    "       '104_ORP', '104_NTU', '104_Ft', 'tk13_Zn', 'tk13_solids%',\n",
    "       'DeZn_Feed_Flow', 'DeZn_Feed_T',\n",
    "       'DeZn_TK05_T',\n",
    "       'H2S_tk01', 'H2S_tk02', 'tk05_Al', 'tk05_Ca', 'tk05_Co', 'tk05_Cr',\n",
    "       'tk05_Cu', 'tk05_Fe', 'tk05_Mg', 'tk05_Mn', 'tk05_Ni', 'tk05_Pb',\n",
    "       'tk05_Si', 'tk05_Zn']\n",
    "\n",
    "for i in range(0, len(df_reg_coef_intercepts_zndropPred['Parameters_coef'])):\n",
    "    DF['Coef{}'.format(i)] = df_reg_coef_intercepts_zndropPred['Parameters_coef'][i]\n",
    "#\n",
    "#\n",
    "#\n",
    "DF['ZnDrop_pred'] = DF['104_Pb']*DF.Coef0 + \\\n",
    "                                      DF['104_Zn']*DF.Coef1 + \\\n",
    "                                      DF['104_Cu']*DF.Coef2 + \\\n",
    "                                      DF['104_Ni']*DF.Coef3 + \\\n",
    "                                      DF['104_Co']*DF.Coef4 + \\\n",
    "                                      DF['104_Fe']*DF.Coef5 + \\\n",
    "                                      DF['104_Mn']*DF.Coef6+\\\n",
    "                                      DF['104_Cr']*DF.Coef7 + \\\n",
    "                                      DF['104_Ca']*DF.Coef8 + \\\n",
    "                                      DF['104_Si']*DF.Coef9 + \\\n",
    "                                      DF['104_Al']*DF.Coef10 + \\\n",
    "                                      DF['104_Mg']*DF.Coef11 + \\\n",
    "                                      DF['104_Fe2']*DF.Coef12 + \\\n",
    "                                      DF['104_pH60_exp']*DF.Coef13 + \\\n",
    "                                      DF['104_ORP']*DF.Coef14+\\\n",
    "                                      DF['104_NTU']*DF.Coef15 + \\\n",
    "                                      DF['104_Ft']*DF.Coef16 + \\\n",
    "                                      DF['tk13_Zn']*DF.Coef17 + \\\n",
    "                                      DF['tk13_solids%']*DF.Coef18 + \\\n",
    "                                      DF['DeZn_Feed_Flow']*DF.Coef19 + \\\n",
    "                                      DF['DeZn_Feed_T']*DF.Coef20 + \\\n",
    "                                      DF['DeZn_TK05_T']*DF.Coef21 + \\\n",
    "                                      DF['H2S_tk01']*DF.Coef22 + \\\n",
    "                                      DF['H2S_tk02']*DF.Coef23 + \\\n",
    "                                      DF['tk05_Al']*DF.Coef24+\\\n",
    "                                      DF['tk05_Ca']*DF.Coef25 + \\\n",
    "                                      DF['tk05_Co']*DF.Coef26 + \\\n",
    "                                      DF['tk05_Cr']*DF.Coef27 + \\\n",
    "                                      DF['tk05_Cu']*DF.Coef28 + \\\n",
    "                                      DF['tk05_Fe']*DF.Coef29 + \\\n",
    "                                      DF['tk05_Mg']*DF.Coef30 + \\\n",
    "                                      DF['tk05_Mn']*DF.Coef31 + \\\n",
    "                                      DF['tk05_Ni']*DF.Coef32 + \\\n",
    "                                      DF['tk05_Pb']*DF.Coef33 + \\\n",
    "                                      DF['tk05_Si']*DF.Coef34 + \\\n",
    "                                      DF['tk05_Zn']*DF.Coef35+ reg_intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.to_excel(r'C:\\Users\\v.t.flores\\Documents\\Zn_drop_database_2015_2020_no_RetTime.xlsx')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
