{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exc1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from dateutil.parser import parse\n",
    "from itertools import compress\n",
    "from collections import OrderedDict\n",
    "from datetime import date\n",
    "import datetime\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:62: RuntimeWarning: invalid value encountered in sign\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:63: RuntimeWarning: invalid value encountered in sign\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:63: RuntimeWarning: invalid value encountered in greater\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:64: RuntimeWarning: invalid value encountered in sign\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:64: RuntimeWarning: invalid value encountered in less\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:71: RuntimeWarning: invalid value encountered in sign\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:72: RuntimeWarning: invalid value encountered in sign\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:72: RuntimeWarning: invalid value encountered in greater\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:73: RuntimeWarning: invalid value encountered in sign\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:73: RuntimeWarning: invalid value encountered in less\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done\n",
      "Done 2020-01-19 11:49:29.005539\n"
     ]
    }
   ],
   "source": [
    "#exc2\n",
    "#Sheet nov2019_Mg_PS\n",
    "\n",
    "#Step1: Load the Data for the month\n",
    "df_nov2019_Mg_PS =  pd.read_excel(r'C:\\Users\\v.t.flores\\Documents\\Analysis_November2019_MSdataCLEAN.xlsx', sheet_name='NOV19Datetime_Mg_PS', index_col=False)\n",
    "\n",
    "#Step2: Parse the DATETIME column\n",
    "df_nov2019_Mg_PS['DATETIME'] = df_nov2019_Mg_PS['DATETIME'].apply(lambda x: parse(str(x)))\n",
    "\n",
    "#Step3: Set the DATETIME column as the index\n",
    "df_nov2019_Mg_PS.set_index('DATETIME', inplace=True)\n",
    "\n",
    "#exc3\n",
    "#Sheet 106FT02A_spcl\n",
    "\n",
    "#Step1: Load the Data for the month\n",
    "df_106FT02A_spcl =  pd.read_excel(r'C:\\Users\\v.t.flores\\Documents\\Analysis_November2019_MSdataCLEAN.xlsx', sheet_name='106FT02A_spcl', index_col=False)\n",
    "\n",
    "#Step2: Parse the DATETIME column\n",
    "df_106FT02A_spcl['DATETIME'] = df_106FT02A_spcl['DATETIME'].apply(lambda x: parse(x))\n",
    "\n",
    "#Step3: Set the DATETIME column as the index\n",
    "df_106FT02A_spcl.set_index('DATETIME', inplace=True)\n",
    "\n",
    "#exc4\n",
    "#Sheet 106FT02B_spcl\n",
    "\n",
    "#Step1: Load the Data for the month\n",
    "df_106FT02B_spcl = pd.read_excel(r'C:\\Users\\v.t.flores\\Documents\\Analysis_November2019_MSdataCLEAN.xlsx', sheet_name='106FT02B_spcl', index_col=False)\n",
    "\n",
    "#Step2: Parse the DATETIME column\n",
    "df_106FT02B_spcl['DATETIME'] = df_106FT02B_spcl['DATETIME'].apply(lambda x: parse(x))\n",
    "\n",
    "#Step3: Set the DATETIME column as the index\n",
    "df_106FT02B_spcl.set_index('DATETIME', inplace=True)\n",
    "\n",
    "#exc5\n",
    "#Sheet From Pi\n",
    "#Step1: Load the Data for the month\n",
    "df_nov2019Pi = pd.read_excel(r'C:\\Users\\v.t.flores\\Documents\\Analysis_November2019_MSdataCLEAN.xlsx', sheet_name='From Pi', index_col=False)\n",
    "\n",
    "#Drop the row[1]\n",
    "df_nov2019Pi = df_nov2019Pi.drop(df_nov2019Pi.index[0])\n",
    "\n",
    "#Step2: Parse the DATETIME column\n",
    "df_nov2019Pi['DATETIME'] = df_nov2019Pi['DATETIME'].apply(lambda x: parse(str(x)))\n",
    "\n",
    "df_nov2019Pi.set_index('DATETIME', inplace=True)\n",
    "\n",
    "#exc6\n",
    "#This code merges the formatted data from the three sheets to on single dataframe named df_comb\n",
    "\n",
    "df_com_Pi_FT02A = df_nov2019Pi.join(df_106FT02A_spcl, how='outer')\n",
    "df_com_Mg_FT02B = df_nov2019_Mg_PS.join(df_106FT02B_spcl, how='outer')\n",
    "df_comb = df_com_Pi_FT02A.join(df_com_Mg_FT02B, how='outer')\n",
    "\n",
    "\n",
    "#exc7\n",
    "#finding peaks FT for A_filtration time\n",
    "\n",
    "df_comb['A_t_FEED'] = pd.to_numeric(df_comb['A_t_FEED'], errors='coerce')\n",
    "a = np.diff(np.sign(np.diff(df_comb['A_t_FEED']))).nonzero()[0] + 1               # local min & max\n",
    "b = (np.diff(np.sign(np.diff(df_comb['A_t_FEED']))) > 0).nonzero()[0] + 1         # local min\n",
    "c = (np.diff(np.sign(np.diff(df_comb['A_t_FEED']))) < 0).nonzero()[0] + 1         # local max\n",
    "# +1 due to the fact that diff reduces the original index number\n",
    "\n",
    "\n",
    "#finding peaks FT for A_N2 Dry time\n",
    "\n",
    "df_comb['A_t_DRY'] = pd.to_numeric(df_comb['A_t_DRY'], errors='coerce')\n",
    "d = np.diff(np.sign(np.diff(df_comb['A_t_DRY']))).nonzero()[0] + 1               # local min & max\n",
    "e = (np.diff(np.sign(np.diff(df_comb['A_t_DRY']))) > 0).nonzero()[0] + 1         # local min\n",
    "f = (np.diff(np.sign(np.diff(df_comb['A_t_DRY']))) < 0).nonzero()[0] + 1         # local max\n",
    "# +1 due to the fact that diff reduces the original index number\n",
    "\n",
    "#Use b as the starting index and f as the ending index for one full cylcle of Filtration to N2 Drying\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#This code here collects the index range for the each cycle\n",
    "try:\n",
    "    ft_cyc_lim = {}\n",
    "\n",
    "    for i in range(0, len(b)):\n",
    "        for j in range(0, len(f)):\n",
    "            if f[j] > b[i] and f[j] < b[i+1]:\n",
    "                if f[j+1]<b[i+1]:\n",
    "                    cyc_start = b[i]\n",
    "                    cyc_end = f[j+1]\n",
    "                    ft_cyc_lim.setdefault(cyc_start,cyc_end)\n",
    "\n",
    "except IndexError:\n",
    "    print('\\nDone')\n",
    "#------------------------------------------------------------     \n",
    "\n",
    "print('Done', str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 2020-01-17 08:18:56.265216\n"
     ]
    }
   ],
   "source": [
    "keyslist = list(ft_cyc_lim.keys()) #creates a list of the ft_cyc_lim keys so that we can iterate later\n",
    "\n",
    "\n",
    "#code for getting the CWP for CakeWash1 and CakeWash2\n",
    "##Working as of 1/15/2020\n",
    "A_CWP_1new = list()\n",
    "A_CWP_1new[:] = []\n",
    "\n",
    "A_CWP_1_indexList = list()\n",
    "A_CWP_1_indexList[:] = []\n",
    "\n",
    "A_CWP_2new = list()\n",
    "A_CWP_2new[:] = []\n",
    "\n",
    "A_CWP_2_indexList = list()\n",
    "A_CWP_2_indexList[:] = []\n",
    "\n",
    "A_CWP_1_inner = list()\n",
    "A_CWP_1_inner[:] = []\n",
    "\n",
    "A_CWP_2_inner = list()\n",
    "A_CWP_2_inner[:] = []\n",
    "\n",
    "A_Pair_CWP_1_List = list()\n",
    "A_Pair_CWP_2_List = list()\n",
    "\n",
    "try:\n",
    "    for i in range(0, len(keyslist)):\n",
    "        A_CWPList_i = list()\n",
    "        A_CWPList_i[:] = []\n",
    "        d = list()\n",
    "        d[:] = []\n",
    "        \n",
    "        A_CWPList_i = list(np.arange(keyslist[i],ft_cyc_lim[keyslist[i]]))\n",
    "        d = (np.diff(np.sign(np.diff(df_comb['106FT02A_CWP'].iloc[keyslist[i]:ft_cyc_lim[keyslist[i]]])))< 0).nonzero()[0] + 1\n",
    "        A_CWP_for_sort = list()\n",
    "        A_CWP_for_sort[:] = [] \n",
    "        \n",
    "        A_CWP_1_indexList.append((str(df_comb.index[keyslist[i]])+\" to \"+str(df_comb.index[ft_cyc_lim[keyslist[i]]])))\n",
    "        A_CWP_2_indexList.append((str(df_comb.index[keyslist[i]])+\" to \"+str(df_comb.index[ft_cyc_lim[keyslist[i]]])))\n",
    "        \n",
    "        for i in range(0, len(d)):\n",
    "            CWP_val_shortlist = df_comb['106FT02A_CWP'].iloc[A_CWPList_i[d[i]]]\n",
    "            A_CWP_for_sort.append(CWP_val_shortlist)\n",
    "                    \n",
    "        A_CWP_1 = sorted(A_CWP_for_sort)[len(A_CWP_for_sort)-1]\n",
    "        A_CWP_1_inner.append(A_CWP_1)\n",
    "        \n",
    "        A_CWP_2 = sorted(A_CWP_for_sort)[len(A_CWP_for_sort)-2]\n",
    "        A_CWP_2_inner.append(A_CWP_2)\n",
    "\n",
    "    A_Pair_CWP_1_List = list(zip(A_CWP_1_inner, A_CWP_1_indexList[0:]))\n",
    "    A_Pair_CWP_2_List = list(zip(A_CWP_2_inner, A_CWP_2_indexList[0:]))\n",
    "            \n",
    "    \n",
    "except IndexError:\n",
    "    print('IndexError')\n",
    "\n",
    "df_A_Pair_CWP_1 = pd.DataFrame(A_Pair_CWP_1_List)\n",
    "df_A_Pair_CWP_1.columns = ['A_CWP_1', 'DATETIME']\n",
    "df_A_Pair_CWP_1.set_index('DATETIME', inplace=True)\n",
    "    \n",
    "df_A_Pair_CWP_2 = pd.DataFrame(A_Pair_CWP_2_List)\n",
    "df_A_Pair_CWP_2.columns = ['A_CWP_2', 'DATETIME']\n",
    "df_A_Pair_CWP_2.set_index('DATETIME', inplace=True)\n",
    "    \n",
    "    \n",
    "print('Done', str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 2020-01-19 11:49:29.849528\n"
     ]
    }
   ],
   "source": [
    "# This code will use the index range (or limits) to create a list of values: feedtime range, cake wash time range,\n",
    "# then selects the max value as the parameter value for that range\n",
    "\n",
    "#FILTRATION TIME\n",
    "keyslist = list(ft_cyc_lim.keys()) #creates a list of the ft_cyc_lim keys so that we can iterate later\n",
    "#For loop Dictionary names \n",
    "A_Filt_MaxList= list()\n",
    "A_Filt_MaxList[:] = []\n",
    "A_feedt_Val_List = list()\n",
    "A_feedt_Val_List[:] = []\n",
    "A_feedt_index_List = list()\n",
    "A_feedt_index_List[:] = []\n",
    "A_Pair_Filt_List = list()\n",
    "A_Pair_Filt_List[:] = []\n",
    "try:         \n",
    "    for i in range(0, len(keyslist)):\n",
    "        A_feedt_Val_List = list()\n",
    "        A_feedt_Val_List[:] = []\n",
    "        for j in range(keyslist[i], ft_cyc_lim[keyslist[i]]):\n",
    "            A_feedt = df_comb['A_t_FEED'][j]\n",
    "            A_feedt_Val_List.append(A_feedt)\n",
    "        A_Filt_MaxList.append(sorted(A_feedt_Val_List)[-1])\n",
    "        A_feedt_index_List.append((str(df_comb.index[keyslist[i]])+\" to \"+str(df_comb.index[ft_cyc_lim[keyslist[i]]])))  \n",
    "    A_Pair_Filt_List = list(zip(A_Filt_MaxList, A_feedt_index_List[0:]))      \n",
    "except:\n",
    "    pass\n",
    "\n",
    "df_A_Pair_Filt_t = pd.DataFrame(A_Pair_Filt_List)\n",
    "df_A_Pair_Filt_t.columns = ['A_FILT_T', 'DATETIME']\n",
    "df_A_Pair_Filt_t.set_index('DATETIME', inplace=True)\n",
    "\n",
    "print('Done', str(datetime.datetime.now()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 2020-01-17 08:18:58.252377\n"
     ]
    }
   ],
   "source": [
    "#MANIFOLD PRESSURE\n",
    "keyslist = list(ft_cyc_lim.keys()) #creates a list of the ft_cyc_lim keys so that we can iterate later\n",
    "#For loop Dictionary names \n",
    "A_MANFP_MaxList = list()\n",
    "A_MANFP_MaxList[:] = []\n",
    "A_Pair_MANFP_List =list() \n",
    "A_Pair_MANFP_List[:] = []\n",
    "A_MANFP_index_List=list()      \n",
    "A_MANFP_index_List[:] = []\n",
    "try:         \n",
    "    for i in range(0, len(keyslist)):\n",
    "        A_MANFP_val_List=list() \n",
    "        A_MANFP_val_List[:] = []\n",
    "        for j in range(keyslist[i], ft_cyc_lim[keyslist[i]]):               \n",
    "            #Gets A manifold pressure of the cycle\n",
    "            A_MANFP = df_comb['106FT02A_MANFP'][j]         \n",
    "            A_MANFP_val_List.append(A_MANFP)\n",
    "        A_MANFP_MaxList.append(sorted(A_MANFP_val_List)[-1])\n",
    "        A_MANFP_index_List.append((str(df_comb.index[keyslist[i]])+\" to \"+str(df_comb.index[ft_cyc_lim[keyslist[i]]])))\n",
    "    A_Pair_MANFP_List = list(zip(A_MANFP_MaxList, A_MANFP_index_List[0:]))      \n",
    "                        \n",
    "except:\n",
    "    pass\n",
    "\n",
    "df_A_Pair_MANF_P = pd.DataFrame(A_Pair_MANFP_List)\n",
    "df_A_Pair_MANF_P.columns = ['A_MANF_P', 'DATETIME']\n",
    "df_A_Pair_MANF_P.set_index('DATETIME', inplace=True)\n",
    "\n",
    "print('Done', str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 2020-01-19 11:49:30.452924\n"
     ]
    }
   ],
   "source": [
    "#CWSH1\n",
    "##wORKING as of 2020.01.15\n",
    "\n",
    "keyslist = list(ft_cyc_lim.keys()) #creates a list of the ft_cyc_lim keys so that we can iterate later\n",
    "\n",
    "A_t_CWSH1_Maxlist = list()\n",
    "A_t_CWSH1_Maxlist[:] = []\n",
    "\n",
    "A_CWSH1_index_List=list()      \n",
    "A_CWSH1_index_List[:] = []\n",
    "\n",
    "A_Pair_CWSH1_List =list() \n",
    "A_Pair_CWSH1_List[:] = []\n",
    "try:         \n",
    "    for i in range(0, len(keyslist)):\n",
    "        A_t_CWSH1_val_List=list() \n",
    "        A_t_CWSH1_val_List[:] = []\n",
    "        for j in range(keyslist[i], ft_cyc_lim[keyslist[i]]):               \n",
    "            A_t_CWSH1 = df_comb['A_t_CWSH1'][j]         \n",
    "            A_t_CWSH1_val_List.append(A_t_CWSH1)\n",
    "        A_t_CWSH1_Maxlist.append(sorted(A_t_CWSH1_val_List)[-1])\n",
    "        A_CWSH1_index_List.append((str(df_comb.index[keyslist[i]])+\" to \"+str(df_comb.index[ft_cyc_lim[keyslist[i]]])))\n",
    "    A_Pair_CWSH1_List = list(zip(A_t_CWSH1_Maxlist, A_CWSH1_index_List[0:]))      \n",
    "                        \n",
    "except:\n",
    "    pass\n",
    "df_A_Pair_CWSH1 = pd.DataFrame(A_Pair_CWSH1_List)\n",
    "df_A_Pair_CWSH1.columns = ['A_CWSH1', 'DATETIME']\n",
    "df_A_Pair_CWSH1.set_index('DATETIME', inplace=True)\n",
    "\n",
    "print('Done', str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 2020-01-17 08:19:00.519806\n"
     ]
    }
   ],
   "source": [
    "#CWSH2\n",
    "##wORKING as of 2020.01.15\n",
    "keyslist = list(ft_cyc_lim.keys()) #creates a list of the ft_cyc_lim keys so that we can iterate later\n",
    "\n",
    "A_t_CWSH2_Maxlist = list()\n",
    "A_t_CWSH2_Maxlist[:] = []\n",
    "\n",
    "A_CWSH2_index_List=list()      \n",
    "A_CWSH2_index_List[:] = []\n",
    "\n",
    "A_Pair_CWSH2_List =list() \n",
    "A_Pair_CWSH2_List[:] = []\n",
    "try:         \n",
    "    for i in range(0, len(keyslist)):\n",
    "        A_t_CWSH2_val_List=list() \n",
    "        A_t_CWSH2_val_List[:] = []\n",
    "        for j in range(keyslist[i], ft_cyc_lim[keyslist[i]]):               \n",
    "            A_t_CWSH2 = df_comb['A_t_CWSH2'][j]         \n",
    "            A_t_CWSH2_val_List.append(A_t_CWSH2)\n",
    "        A_t_CWSH2_Maxlist.append(sorted(A_t_CWSH2_val_List)[-1])\n",
    "        A_CWSH2_index_List.append((str(df_comb.index[keyslist[i]])+\" to \"+str(df_comb.index[ft_cyc_lim[keyslist[i]]])))\n",
    "    A_Pair_CWSH2_List = list(zip(A_t_CWSH2_Maxlist, A_CWSH2_index_List[0:]))      \n",
    "                        \n",
    "except:\n",
    "    pass\n",
    "  \n",
    "df_A_Pair_CWSH2 = pd.DataFrame(A_Pair_CWSH2_List)\n",
    "df_A_Pair_CWSH2.columns = ['A_CWSH2', 'DATETIME']\n",
    "df_A_Pair_CWSH2.set_index('DATETIME', inplace=True)\n",
    "print('Done', str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 2020-01-19 11:49:31.059621\n"
     ]
    }
   ],
   "source": [
    "#Pressing_1\n",
    "##wORKING as of 2020.01.15\n",
    "keyslist = list(ft_cyc_lim.keys()) #creates a list of the ft_cyc_lim keys so that we can iterate later\n",
    "\n",
    "A_t_Press1_Maxlist = list()\n",
    "A_t_Press1_Maxlist[:] = []\n",
    "\n",
    "A_t_Press1_index_List=list()      \n",
    "A_t_Press1_index_List[:] = []\n",
    "\n",
    "A_Pair_A_t_Press1_List =list() \n",
    "A_Pair_A_t_Press1_List[:] = []\n",
    "try:         \n",
    "    for i in range(0, len(keyslist)):\n",
    "        A_t_Press1_val_List=list() \n",
    "        A_t_Press1_val_List[:] = []\n",
    "        for j in range(keyslist[i], ft_cyc_lim[keyslist[i]]):               \n",
    "            A_t_Press1 = df_comb['A_t_PRESS1'][j]         \n",
    "            A_t_Press1_val_List.append(A_t_Press1)\n",
    "        A_t_Press1_Maxlist.append(sorted(A_t_Press1_val_List)[-1])\n",
    "        A_t_Press1_index_List.append((str(df_comb.index[keyslist[i]])+\" to \"+str(df_comb.index[ft_cyc_lim[keyslist[i]]])))\n",
    "    A_Pair_Press1_List = list(zip(A_t_Press1_Maxlist, A_t_Press1_index_List[0:]))      \n",
    "                        \n",
    "except:\n",
    "    pass\n",
    "df_A_Pair_PRESS1_t = pd.DataFrame(A_Pair_Press1_List)\n",
    "df_A_Pair_PRESS1_t.columns = ['A_PRESS1_t', 'DATETIME']\n",
    "df_A_Pair_PRESS1_t.set_index('DATETIME', inplace=True)\n",
    "print('Done', str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 2020-01-17 08:19:02.670372\n"
     ]
    }
   ],
   "source": [
    "#Pressing_2\n",
    "##wORKING as of 2020.01.15\n",
    "keyslist = list(ft_cyc_lim.keys()) #creates a list of the ft_cyc_lim keys so that we can iterate later\n",
    "\n",
    "A_t_Press2_Maxlist = list()\n",
    "A_t_Press2_Maxlist[:] = []\n",
    "\n",
    "A_t_Press2_index_List=list()      \n",
    "A_t_Press2_index_List[:] = []\n",
    "\n",
    "A_Pair_Press2_List =list() \n",
    "A_Pair_Press2_List[:] = []\n",
    "try:         \n",
    "    for i in range(0, len(keyslist)):\n",
    "        A_t_Press2_val_List=list() \n",
    "        A_t_Press2_val_List[:] = []\n",
    "        for j in range(keyslist[i], ft_cyc_lim[keyslist[i]]):               \n",
    "            A_t_Press2 = df_comb['A_t_PRESS2'][j]         \n",
    "            A_t_Press2_val_List.append(A_t_Press2)\n",
    "        A_t_Press2_Maxlist.append(sorted(A_t_Press2_val_List)[-1])\n",
    "        A_t_Press2_index_List.append((str(df_comb.index[keyslist[i]])+\" to \"+str(df_comb.index[ft_cyc_lim[keyslist[i]]])))\n",
    "    A_Pair_Press2_List = list(zip(A_t_Press2_Maxlist, A_t_Press2_index_List[0:]))      \n",
    "                        \n",
    "except:\n",
    "    pass\n",
    "  \n",
    "df_A_Pair_PRESS2_t = pd.DataFrame(A_Pair_Press2_List)\n",
    "df_A_Pair_PRESS2_t.columns = ['A_PRESS2_t', 'DATETIME']\n",
    "df_A_Pair_PRESS2_t.set_index('DATETIME', inplace=True)\n",
    "print('Done', str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 2020-01-19 11:49:31.621731\n"
     ]
    }
   ],
   "source": [
    "#A_PU26A_OP\n",
    "##Working as of 2020.01.15\n",
    "A_PU26A_OP_Maxlist = list()\n",
    "A_PU26A_OP_Maxlist[:] = []\n",
    "\n",
    "A_PU26A_OP_index_List=list()      \n",
    "A_PU26A_OP_index_List[:] = []\n",
    "\n",
    "A_Pair_PU26A_OP_List =list() \n",
    "A_Pair_PU26A_OP_List[:] = []\n",
    "try:         \n",
    "    for i in range(0, len(keyslist)):\n",
    "        A_PU26A_OP_val_List=list() \n",
    "        A_PU26A_OP_val_List[:] = []\n",
    "        for j in range(keyslist[i], ft_cyc_lim[keyslist[i]]):               \n",
    "            A_PU26A_OP = df_comb['PU26A_OP'][j]      \n",
    "            A_PU26A_OP_val_List.append(A_PU26A_OP)\n",
    "        A_PU26A_OP_Maxlist.append(sorted(A_PU26A_OP_val_List)[-1])\n",
    "        A_PU26A_OP_index_List.append((str(df_comb.index[keyslist[i]])+\" to \"+str(df_comb.index[ft_cyc_lim[keyslist[i]]])))\n",
    "    A_Pair_PU26A_OP_List = list(zip(A_PU26A_OP_Maxlist, A_PU26A_OP_index_List[0:]))          \n",
    "except:\n",
    "    pass\n",
    "df_A_Pair_PU26A_OP = pd.DataFrame(A_Pair_PU26A_OP_List)\n",
    "df_A_Pair_PU26A_OP.columns = ['A_PU26A_OP', 'DATETIME']\n",
    "df_A_Pair_PU26A_OP.set_index('DATETIME', inplace=True)\n",
    "print('Done', str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 2020-01-17 08:19:04.754435\n"
     ]
    }
   ],
   "source": [
    "#A_PU27A_OP\n",
    "##Working as of 2020.01.15\n",
    "keyslist = list(ft_cyc_lim.keys()) #creates a list of the ft_cyc_lim keys so that we can iterate later\n",
    "\n",
    "A_PU27A_OP_Maxlist = list()\n",
    "A_PU27A_OP_Maxlist[:] = []\n",
    "\n",
    "A_PU27A_OP_index_List=list()      \n",
    "A_PU27A_OP_index_List[:] = []\n",
    "\n",
    "A_Pair_PU27A_OP_List =list() \n",
    "A_Pair_PU27A_OP_List[:] = []\n",
    "try:         \n",
    "    for i in range(0, len(keyslist)):\n",
    "        A_PU27A_OP_val_List=list() \n",
    "        A_PU27A_OP_val_List[:] = []\n",
    "        for j in range(keyslist[i], ft_cyc_lim[keyslist[i]]):               \n",
    "            A_PU27A_OP = df_comb['PU27A_OP'][j]      \n",
    "            A_PU27A_OP_val_List.append(A_PU27A_OP)\n",
    "        A_PU27A_OP_Maxlist.append(sorted(A_PU27A_OP_val_List)[-1])\n",
    "        A_PU27A_OP_index_List.append((str(df_comb.index[keyslist[i]])+\" to \"+str(df_comb.index[ft_cyc_lim[keyslist[i]]])))\n",
    "    A_Pair_PU27A_OP_List = list(zip(A_PU27A_OP_Maxlist, A_PU27A_OP_index_List[0:]))          \n",
    "except:\n",
    "    pass\n",
    "  \n",
    "df_A_Pair_PU27A_OP = pd.DataFrame(A_Pair_PU27A_OP_List)\n",
    "df_A_Pair_PU27A_OP.columns = ['A_PU27A_OP', 'DATETIME']\n",
    "df_A_Pair_PU27A_OP.set_index('DATETIME', inplace=True)\n",
    "print('Done', str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 2020-01-19 11:49:33.497693\n"
     ]
    }
   ],
   "source": [
    "#this code replaces the 'No Good Data' from 106PU26A_CUR column\n",
    "for x in range(0, len(df_comb['106PU26A_CUR'])):\n",
    "    if df_comb['106PU26A_CUR'][x] =='[-11059] No Good Data For Calculation':\n",
    "            df_comb['106PU26A_CUR'][x] = 0\n",
    "#A_PU26A_CUR\n",
    "##Working as of 2020.01.15\n",
    "keyslist = list(ft_cyc_lim.keys()) #creates a list of the ft_cyc_lim keys so that we can iterate later\n",
    "\n",
    "A_PU26A_CUR_Maxlist = list()\n",
    "A_PU26A_CUR_Maxlist[:] = []\n",
    "\n",
    "A_PU26A_CUR_index_List=list()      \n",
    "A_PU26A_CUR_index_List[:] = []\n",
    "\n",
    "A_Pair_PU26A_CUR_List =list() \n",
    "A_Pair_PU26A_CUR_List[:] = []\n",
    "try:         \n",
    "    for i in range(0, len(keyslist)):\n",
    "        A_PU26A_CUR_val=list() \n",
    "        A_PU26A_CUR_val[:] = []\n",
    "        for j in range(keyslist[i], ft_cyc_lim[keyslist[i]]):               \n",
    "            A_PU26A_CUR = df_comb['106PU26A_CUR'][j]      \n",
    "            A_PU26A_CUR_val.append(A_PU26A_CUR)\n",
    "        A_PU26A_CUR_Maxlist.append(sorted(A_PU26A_CUR_val)[-1])\n",
    "        A_PU26A_CUR_index_List.append((str(df_comb.index[keyslist[i]])+\" to \"+str(df_comb.index[ft_cyc_lim[keyslist[i]]])))\n",
    "    A_Pair_PU26A_CUR_List = list(zip(A_PU26A_CUR_Maxlist, A_PU26A_CUR_index_List[0:]))          \n",
    "except:\n",
    "    pass\n",
    "\n",
    "df_A_Pair_PU26A_CUR = pd.DataFrame(A_Pair_PU26A_CUR_List)\n",
    "df_A_Pair_PU26A_CUR.columns = ['A_PU26A_CUR', 'DATETIME']\n",
    "df_A_Pair_PU26A_CUR.set_index('DATETIME', inplace=True)\n",
    "print('Done', str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 2020-01-19 11:49:35.114758\n"
     ]
    }
   ],
   "source": [
    "#this code replaces the 'No Good Data' from 106PU26A_CUR column\n",
    "for x in range(0, len(df_comb['106PU27A_CUR'])):\n",
    "    if df_comb['106PU27A_CUR'][x] =='[-11059] No Good Data For Calculation':\n",
    "            df_comb['106PU27A_CUR'][x] = 0\n",
    "#A_PU27A_CUR\n",
    "##Working as of 2020.01.15 after a million trials!!!!!!!!!! mabuak na akong utok!!!\n",
    "keyslist = list(ft_cyc_lim.keys()) #creates a list of the ft_cyc_lim keys so that we can iterate later\n",
    "\n",
    "A_PU27A_CUR_Maxlist = list()\n",
    "A_PU27A_CUR_Maxlist[:] = []\n",
    "\n",
    "A_PU27A_CUR_index_List=list()      \n",
    "A_PU27A_CUR_index_List[:] = []\n",
    "\n",
    "A_Pair_PU27A_CUR_List =list() \n",
    "A_Pair_PU27A_CUR_List[:] = []\n",
    "try:         \n",
    "    for i in range(0, len(keyslist)):\n",
    "        A_PU27A_CUR_val=list() \n",
    "        A_PU27A_CUR_val[:] = []\n",
    "        for j in range(keyslist[i], ft_cyc_lim[keyslist[i]]):               \n",
    "            A_PU27A_CUR = df_comb['106PU27A_CUR'][j]      \n",
    "            A_PU27A_CUR_val.append(A_PU27A_CUR)\n",
    "        A_PU27A_CUR_Maxlist.append(sorted(A_PU27A_CUR_val)[-1])\n",
    "        A_PU27A_CUR_index_List.append((str(df_comb.index[keyslist[i]])+\" to \"+str(df_comb.index[ft_cyc_lim[keyslist[i]]])))\n",
    "    A_Pair_PU27A_CUR_List = list(zip(A_PU27A_CUR_Maxlist, A_PU27A_CUR_index_List[0:]))          \n",
    "except:\n",
    "    pass\n",
    "  \n",
    "df_A_Pair_PU27A_CUR = pd.DataFrame(A_Pair_PU27A_CUR_List)\n",
    "df_A_Pair_PU27A_CUR.columns = ['A_PU27A_CUR', 'DATETIME']\n",
    "df_A_Pair_PU27A_CUR.set_index('DATETIME', inplace=True)\n",
    "print('Done', str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 2020-01-19 11:49:35.189558\n"
     ]
    }
   ],
   "source": [
    "#A_N2 Dry\n",
    "##Working as of 2020-01-15 17:26:09.736327\n",
    "A_Pair_N2_Dry_List = list()\n",
    "A_Pair_N2_Dry_List[:] = []\n",
    "A_t_N2_Dry_indexList = list()\n",
    "A_t_N2_Dry_indexList[:] = []\n",
    "A_t_N2_Dry_val = list()\n",
    "A_t_N2_Dry_val[:] = []\n",
    "try:         \n",
    "    for i in range(0, len(keyslist)):   \n",
    "        A_t_N2_Dry = df_comb['A_t_DRY'][ft_cyc_lim[keyslist[i]]]\n",
    "        A_t_N2_Dry_val.append(A_t_N2_Dry)\n",
    "        A_t_N2_Dry_indexList.append((str(df_comb.index[keyslist[i]])+\" to \"+str(df_comb.index[ft_cyc_lim[keyslist[i]]])))\n",
    "    \n",
    "    A_Pair_N2_Dry_List = list(zip(A_t_N2_Dry_val, A_t_N2_Dry_indexList[0:]))          \n",
    "except:\n",
    "    pass\n",
    "\n",
    "df_A_Pair_N2DRY = pd.DataFrame(A_Pair_N2_Dry_List)\n",
    "df_A_Pair_N2DRY.columns = ['A_N2DRY', 'DATETIME']\n",
    "df_A_Pair_N2DRY.set_index('DATETIME', inplace=True)\n",
    "print('Done', str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 2020-01-19 11:49:35.292040\n"
     ]
    }
   ],
   "source": [
    "dfn = df_A_Pair_CWP_1.join(df_A_Pair_CWP_2, how='outer')\n",
    "dfn1 = df_A_Pair_Filt_t.join(df_A_Pair_MANF_P, how='outer')\n",
    "dfn2 = df_A_Pair_CWSH1.join(df_A_Pair_CWSH2, how='outer')\n",
    "dfn3 = df_A_Pair_PRESS1_t.join(df_A_Pair_PRESS2_t, how='outer')\n",
    "dfn4 = df_A_Pair_PU26A_OP.join(df_A_Pair_PU27A_OP, how='outer')\n",
    "dfn5 = df_A_Pair_PU26A_CUR.join(df_A_Pair_PU27A_CUR, how='outer')\n",
    "dfn6 = df_A_Pair_N2DRY.join(dfn, how='outer')\n",
    "dfn7 = dfn1.join(dfn2, how='outer')\n",
    "dfn8 = dfn3.join(dfn4, how='outer')\n",
    "dfn9 = dfn5.join(dfn6, how='outer')\n",
    "dfn10 = dfn7.join(dfn8, how='outer')\n",
    "dfn11 = dfn9.join(dfn10, how='outer')\n",
    "print('Done', str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####This block of code appends the Analysis Results from 106TH01 UF\n",
    "import datetime\n",
    "from dateutil.parser import parse\n",
    "import pandas as pd\n",
    "\n",
    "import openpyxl\n",
    "wb1 = openpyxl.load_workbook(r'C:\\Users\\v.t.flores\\Documents\\Copy of 11.) November_ 2019.xlsx')\n",
    "TH01_UF_sheet = wb1['106TH01 UF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "TH01_UF_sheet['S'+str(9)].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TH01_UF_sheet['B'+str(9)].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "Done 2020-01-17 12:55:06.727257\n"
     ]
    }
   ],
   "source": [
    "#This code finds the indexloc of the cells with day number from the sampling date column\n",
    "rows_n = list()\n",
    "try:\n",
    "    for i in range (1, TH01_UF_sheet.max_row+1):\n",
    "        if type(TH01_UF_sheet['B'+ str(i)].value) == int:\n",
    "            #print(str(i)+':'+str(TH01_UF_sheet['B'+ str(i)].value))\n",
    "            rows_n.append(i)\n",
    "except:\n",
    "    pass\n",
    "#--------------------------\n",
    "#This code finds the Pb concentration and the datetime\n",
    "Pb_df_list = list()\n",
    "Pb_df_list[:] = []\n",
    "PbList = list()\n",
    "PbList[:] = []\n",
    "timeList = list()\n",
    "timeList[:] = []\n",
    "\n",
    "for i in range(0, len(rows_n)-1):\n",
    "    for j in range(rows_n[i], rows_n[i+1]):        \n",
    "        if TH01_UF_sheet['S'+str(j)].value != None and type(TH01_UF_sheet['S'+str(j)].value) == float:\n",
    "            if  type(TH01_UF_sheet['C'+str(j)].value) == datetime.datetime:\n",
    "                time_val = TH01_UF_sheet['C'+str(j)].value           \n",
    "                strdate = parse(str(time_val))\n",
    "                newtime = str(strdate).split(\" \")[1]\n",
    "                if newtime == '03:00:00':\n",
    "                    newdate = str(datetime.date(2019,11,1)-timedelta(1)+timedelta(TH01_UF_sheet['B'+str(rows_n[i+1])].value))+' '+newtime\n",
    "                else:\n",
    "                    newdate = str(datetime.date(2019,11,1)-timedelta(1) +timedelta(TH01_UF_sheet['B'+str(rows_n[i])].value))+' '+newtime\n",
    "          \n",
    "            elif type(TH01_UF_sheet['C'+str(j)].value) == datetime.time:\n",
    "                time_val = TH01_UF_sheet['C'+str(j)].value           \n",
    "                strdate = str(time_val)\n",
    "                if strdate == '03:00:00':\n",
    "                    newdate = str(datetime.date(2019,11,1)-timedelta(1)+timedelta(TH01_UF_sheet['B'+str(rows_n[i+1])].value))+' '+strdate\n",
    "                else:\n",
    "                    newdate = str(datetime.date(2019,11,1)-timedelta(1) +timedelta(TH01_UF_sheet['B'+str(rows_n[i])].value))+' '+strdate       \n",
    "        \n",
    "            timeList.append(parse(newdate))\n",
    "            Pb_val = TH01_UF_sheet['S'+str(j)].value\n",
    "            PbList.append(Pb_val)\n",
    "    #print(TH01_UF_sheet['B'+str(rows_n[i])].value)\n",
    "Pb_df_list = list(zip(PbList, timeList[0:]))\n",
    "\n",
    "#converting lists to dataframe\n",
    "Pb_df = pd.DataFrame(Pb_df_list)\n",
    "Pb_df.columns = ['Pb', 'DATETIME']\n",
    "Pb_df.set_index('DATETIME', inplace=True)\n",
    "print('done')\n",
    "#--------------\n",
    "#This code finds the Zn concentration and the datetime\n",
    "\n",
    "Zn_df_list = list()\n",
    "Zn_df_list[:] = []\n",
    "ZnList = list()\n",
    "ZnList[:] = []\n",
    "ZntimeList = list()\n",
    "ZntimeList[:] = []\n",
    "\n",
    "for i in range(0, len(rows_n)-1):\n",
    "    for j in range(rows_n[i], rows_n[i+1]):        \n",
    "        if TH01_UF_sheet['T'+str(j)].value != None and type(TH01_UF_sheet['T'+str(j)].value) == float:\n",
    "            if  type(TH01_UF_sheet['C'+str(j)].value) == datetime.datetime:\n",
    "                time_val = TH01_UF_sheet['C'+str(j)].value           \n",
    "                strdate = parse(str(time_val))\n",
    "                newtime = str(strdate).split(\" \")[1]\n",
    "                if newtime == '03:00:00':\n",
    "                    newdate = str(datetime.date(2019,11,1)-timedelta(1)+timedelta(TH01_UF_sheet['B'+str(rows_n[i+1])].value))+' '+newtime\n",
    "                else:\n",
    "                    newdate = str(datetime.date(2019,11,1)-timedelta(1) +timedelta(TH01_UF_sheet['B'+str(rows_n[i])].value))+' '+newtime\n",
    "          \n",
    "            elif type(TH01_UF_sheet['C'+str(j)].value) == datetime.time:\n",
    "                time_val = TH01_UF_sheet['C'+str(j)].value           \n",
    "                strdate = str(time_val)\n",
    "                if strdate == '03:00:00':\n",
    "                    newdate = str(datetime.date(2019,11,1)-timedelta(1)+timedelta(TH01_UF_sheet['B'+str(rows_n[i+1])].value))+' '+strdate\n",
    "                else:\n",
    "                    newdate = str(datetime.date(2019,11,1)-timedelta(1) +timedelta(TH01_UF_sheet['B'+str(rows_n[i])].value))+' '+strdate       \n",
    "            \n",
    "            timeList.append(parse(newdate))\n",
    "            Zn_val = TH01_UF_sheet['T'+str(j)].value\n",
    "            ZnList.append(Zn_val)\n",
    "    #print(TH01_UF_sheet['B'+str(rows_n[i])].value)\n",
    "Zn_df_list = list(zip(ZnList, timeList[0:]))\n",
    "\n",
    "#converting lists to dataframe\n",
    "Zn_df = pd.DataFrame(Zn_df_list)\n",
    "Zn_df.columns = ['Zn', 'DATETIME']\n",
    "Zn_df.set_index('DATETIME', inplace=True)\n",
    "\n",
    "#--------------\n",
    "#This code finds the Cu concentration and the datetime\n",
    "\n",
    "Cu_df_list = list()\n",
    "Cu_df_list[:] = []\n",
    "CuList = list()\n",
    "CuList[:] = []\n",
    "CutimeList = list()\n",
    "CutimeList[:] = []\n",
    "\n",
    "for i in range(0, len(rows_n)-1):\n",
    "    for j in range(rows_n[i], rows_n[i+1]):        \n",
    "        if TH01_UF_sheet['U'+str(j)].value != None and type(TH01_UF_sheet['U'+str(j)].value) == float: ##check if column is updated\n",
    "            if  type(TH01_UF_sheet['C'+str(j)].value) == datetime.datetime:\n",
    "                time_val = TH01_UF_sheet['C'+str(j)].value           \n",
    "                strdate = parse(str(time_val))\n",
    "                newtime = str(strdate).split(\" \")[1]\n",
    "                if newtime == '03:00:00':\n",
    "                    newdate = str(datetime.date(2019,11,1)-timedelta(1)+timedelta(TH01_UF_sheet['B'+str(rows_n[i+1])].value))+' '+newtime\n",
    "                else:\n",
    "                    newdate = str(datetime.date(2019,11,1)-timedelta(1) +timedelta(TH01_UF_sheet['B'+str(rows_n[i])].value))+' '+newtime\n",
    "          \n",
    "            elif type(TH01_UF_sheet['C'+str(j)].value) == datetime.time:\n",
    "                time_val = TH01_UF_sheet['C'+str(j)].value           \n",
    "                strdate = str(time_val)\n",
    "                if strdate == '03:00:00':\n",
    "                    newdate = str(datetime.date(2019,11,1)-timedelta(1)+timedelta(TH01_UF_sheet['B'+str(rows_n[i+1])].value))+' '+strdate\n",
    "                else:\n",
    "                    newdate = str(datetime.date(2019,11,1)-timedelta(1) +timedelta(TH01_UF_sheet['B'+str(rows_n[i])].value))+' '+strdate       \n",
    "               \n",
    "            timeList.append(parse(newdate))\n",
    "            Cu_val = TH01_UF_sheet['U'+str(j)].value ##check if column and varname is updated\n",
    "            CuList.append(Cu_val) ##check if list title is updated\n",
    "Cu_df_list = list(zip(CuList, timeList[0:]))\n",
    "\n",
    "#converting lists to dataframe\n",
    "Cu_df = pd.DataFrame(Zn_df_list)\n",
    "Cu_df.columns = ['Cu', 'DATETIME'] ##check if list title is updated\n",
    "Cu_df.set_index('DATETIME', inplace=True)\n",
    "\n",
    "#--------------\n",
    "#This code finds the Mg concentration and the datetime\n",
    "Mg_df_list = list()\n",
    "Mg_df_list[:] = []\n",
    "MgList = list()\n",
    "MgList[:] = []\n",
    "MgtimeList = list()\n",
    "MgtimeList[:] = []\n",
    "\n",
    "for i in range(0, len(rows_n)-1):\n",
    "    for j in range(rows_n[i], rows_n[i+1]):        \n",
    "        if TH01_UF_sheet['AD'+str(j)].value != None and type(TH01_UF_sheet['AD'+str(j)].value) == float: ##check if column is updated\n",
    "            if  type(TH01_UF_sheet['C'+str(j)].value) == datetime.datetime:\n",
    "                time_val = TH01_UF_sheet['C'+str(j)].value           \n",
    "                strdate = parse(str(time_val))\n",
    "                newtime = str(strdate).split(\" \")[1]\n",
    "                if newtime == '03:00:00':\n",
    "                    newdate = str(datetime.date(2019,11,1)-timedelta(1)+timedelta(TH01_UF_sheet['B'+str(rows_n[i+1])].value))+' '+newtime\n",
    "                else:\n",
    "                    newdate = str(datetime.date(2019,11,1)-timedelta(1) +timedelta(TH01_UF_sheet['B'+str(rows_n[i])].value))+' '+newtime\n",
    "          \n",
    "            elif type(TH01_UF_sheet['C'+str(j)].value) == datetime.time:\n",
    "                time_val = TH01_UF_sheet['C'+str(j)].value           \n",
    "                strdate = str(time_val)\n",
    "                if strdate == '03:00:00':\n",
    "                    newdate = str(datetime.date(2019,11,1)-timedelta(1)+timedelta(TH01_UF_sheet['B'+str(rows_n[i+1])].value))+' '+strdate\n",
    "                else:\n",
    "                    newdate = str(datetime.date(2019,11,1)-timedelta(1) +timedelta(TH01_UF_sheet['B'+str(rows_n[i])].value))+' '+strdate       \n",
    "                     \n",
    "            timeList.append(parse(newdate))\n",
    "            Mg_val = TH01_UF_sheet['AD'+str(j)].value ##check if column and varname are updated\n",
    "            MgList.append(Mg_val) ##check if list title is updated\n",
    "Mg_df_list = list(zip(MgList, timeList[0:])) ##check if the list titles and the df list are updated\n",
    "\n",
    "#converting lists to dataframe\n",
    "Mg_df = pd.DataFrame(Mg_df_list) ##check if the element list title is updated\n",
    "Mg_df.columns = ['Mg', 'DATETIME'] ##check if list title and the column name are updated\n",
    "Mg_df.set_index('DATETIME', inplace=True)\n",
    "#--------------\n",
    "\n",
    "dfEl1 = Pb_df.join(Mg_df, how='outer')\n",
    "dfEl2 = Cu_df.join(Zn_df, how='outer')\n",
    "dfEL3 = dfEl1.join(dfEl2, how='outer')\n",
    "print('Done', str(datetime.datetime.now()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fcn for formatting the dates from range str\n",
    "def datesplitter_start(x):\n",
    "    return parse(x.split('to')[0])\n",
    "def datesplitter_end(x):\n",
    "    return parse(x.split('to')[1])\n",
    "#---------\n",
    "dfn11['newdt'] = dfn11.index\n",
    "dfn11['startdate'] = dfn11['newdt'].apply(lambda x: datesplitter_start(x))\n",
    "dfn11['enddate'] = dfn11['newdt'].apply(lambda x: datesplitter_end(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for date index formattter\n",
    "df_anl_indexList = list()\n",
    "df_anl_indexList[:] = []\n",
    "df_n11_indexList = list()\n",
    "df_n11_indexList[:] = []\n",
    "\n",
    "try:\n",
    "    for i in range(0, 175):\n",
    "        for j in range(0, len(dfn11)):\n",
    "            if dfn11['enddate'][j-1] <= dfEL3.index[i] and dfn11['enddate'][j] >= dfEL3.index[i]:\n",
    "                df_n11_indexList.append(dfn11.index[j])\n",
    "                df_anl_indexList.append(dfEL3.index[i]) \n",
    "except IndexError:\n",
    "    print('IndexError')\n",
    "\n",
    "Analys_indexList_Pair = list(zip(df_anl_indexList, df_n11_indexList[0:]))\n",
    "dfEL4 = pd.DataFrame(Analys_indexList_Pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for changing the index to Datetime in range format (from date1 to date2)\n",
    "df_anl_indexList = list()\n",
    "df_anl_indexList[:] = []\n",
    "df_n11_indexList = list()\n",
    "df_n11_indexList[:] = []\n",
    "try:\n",
    "    for i in range(0, 175):\n",
    "        for j in range(0, len(dfn11)):\n",
    "            if dfn11['enddate'][j-1] <= dfEL3.index[i] and dfn11['enddate'][j] >= dfEL3.index[i]:\n",
    "                df_n11_indexList.append(dfn11.index[j])\n",
    "                df_anl_indexList.append(dfEL3.index[i]) \n",
    "except IndexError:\n",
    "    print('IndexError')  \n",
    "Analys_indexList_Pair = list(zip(df_anl_indexList, df_n11_indexList[0:]))\n",
    "dfEL4 = pd.DataFrame(Analys_indexList_Pair)\n",
    "dfEL4.columns = ['DATETIME', 'FT_cycletimerange']\n",
    "dfEL4.set_index('DATETIME', inplace=True)\n",
    "\n",
    "dfEL5 = dfEL3.join(dfEL4, how='outer')\n",
    "dfEL5.columns = ['106TH_UF_Pb', '106TH_UF_Mg', '106TH_UF_Cu', '106TH_UF_Zn', 'DATETIME']\n",
    "dfEL5.set_index('DATETIME', inplace=True)\n",
    "df_Cycle_LabRes = dfn11.join(dfEL5, how='outer')\n",
    "\n",
    "#---------------dfEL5 is the is the analysis results data indexed by daterange format. readt for merging with dfn11(FT02A data from Pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfEL5.to_excel(r'C:\\Users\\v.t.flores\\Documents\\20200117AM_datetimerangep_i.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileCreateError",
     "evalue": "[Errno 13] Permission denied: 'C:\\\\Users\\\\v.t.flores\\\\Documents\\\\20200117AM_Cycle_LabRes_i.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xlsxwriter\\workbook.py\u001b[0m in \u001b[0;36mclose\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    310\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_store_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xlsxwriter\\workbook.py\u001b[0m in \u001b[0;36m_store_workbook\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    626\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 627\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    628\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xlsxwriter\\workbook.py\u001b[0m in \u001b[0;36m_store_workbook\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    624\u001b[0m             xlsx_file = ZipFile(self.filename, \"w\", compression=ZIP_DEFLATED,\n\u001b[1;32m--> 625\u001b[1;33m                                 allowZip64=self.allow_zip64)\n\u001b[0m\u001b[0;32m    626\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, file, mode, compression, allowZip64, compresslevel)\u001b[0m\n\u001b[0;32m   1206\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1207\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1208\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'C:\\\\Users\\\\v.t.flores\\\\Documents\\\\20200117AM_Cycle_LabRes_i.xlsx'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileCreateError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-251-a30027e067ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_Cycle_LabRes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'C:\\Users\\v.t.flores\\Documents\\20200117AM_Cycle_LabRes_i.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_excel\u001b[1;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, encoding, inf_rep, verbose, freeze_panes)\u001b[0m\n\u001b[0;32m   2254\u001b[0m             \u001b[0mstartcol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstartcol\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2255\u001b[0m             \u001b[0mfreeze_panes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfreeze_panes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2256\u001b[1;33m             \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2257\u001b[0m         )\n\u001b[0;32m   2258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\excel.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine)\u001b[0m\n\u001b[0;32m    740\u001b[0m         )\n\u001b[0;32m    741\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mneed_save\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 742\u001b[1;33m             \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_xlsxwriter.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    193\u001b[0m         \"\"\"\n\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     def write_cells(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xlsxwriter\\workbook.py\u001b[0m in \u001b[0;36mclose\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    311\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_store_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 313\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mFileCreateError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    314\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mLargeZipFile\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m                 raise FileSizeError(\"Filesize would require ZIP64 extensions. \"\n",
      "\u001b[1;31mFileCreateError\u001b[0m: [Errno 13] Permission denied: 'C:\\\\Users\\\\v.t.flores\\\\Documents\\\\20200117AM_Cycle_LabRes_i.xlsx'"
     ]
    }
   ],
   "source": [
    "df_Cycle_LabRes.to_excel(r'C:\\Users\\v.t.flores\\Documents\\20200117AM_Cycle_LabRes_i.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfEL4.to_excel(r'C:\\Users\\v.t.flores\\Documents\\20200117AM_datetimerangep_dfEL4.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn12.to_excel(r'C:\\Users\\v.t.flores\\Documents\\201911Data_Mg_Inv_20200116.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
