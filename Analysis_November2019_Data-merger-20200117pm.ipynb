{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exc1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from dateutil.parser import parse\n",
    "from itertools import compress\n",
    "from collections import OrderedDict\n",
    "from datetime import date\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "from openpyxl.utils import get_column_letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:62: RuntimeWarning: invalid value encountered in sign\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:63: RuntimeWarning: invalid value encountered in sign\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:63: RuntimeWarning: invalid value encountered in greater\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:64: RuntimeWarning: invalid value encountered in sign\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:64: RuntimeWarning: invalid value encountered in less\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:71: RuntimeWarning: invalid value encountered in sign\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:72: RuntimeWarning: invalid value encountered in sign\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:72: RuntimeWarning: invalid value encountered in greater\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:73: RuntimeWarning: invalid value encountered in sign\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:73: RuntimeWarning: invalid value encountered in less\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done\n",
      "Done 2020-01-17 13:37:36.919951\n"
     ]
    }
   ],
   "source": [
    "#exc2\n",
    "#Sheet nov2019_Mg_PS\n",
    "\n",
    "#Step1: Load the Data for the month\n",
    "df_nov2019_Mg_PS =  pd.read_excel(r'C:\\Users\\v.t.flores\\Documents\\Analysis_November2019_MSdataCLEAN.xlsx', sheet_name='NOV19Datetime_Mg_PS', index_col=False)\n",
    "\n",
    "#Step2: Parse the DATETIME column\n",
    "df_nov2019_Mg_PS['DATETIME'] = df_nov2019_Mg_PS['DATETIME'].apply(lambda x: parse(str(x)))\n",
    "\n",
    "#Step3: Set the DATETIME column as the index\n",
    "df_nov2019_Mg_PS.set_index('DATETIME', inplace=True)\n",
    "\n",
    "#exc3\n",
    "#Sheet 106FT02A_spcl\n",
    "\n",
    "#Step1: Load the Data for the month\n",
    "df_106FT02A_spcl =  pd.read_excel(r'C:\\Users\\v.t.flores\\Documents\\Analysis_November2019_MSdataCLEAN.xlsx', sheet_name='106FT02A_spcl', index_col=False)\n",
    "\n",
    "#Step2: Parse the DATETIME column\n",
    "df_106FT02A_spcl['DATETIME'] = df_106FT02A_spcl['DATETIME'].apply(lambda x: parse(x))\n",
    "\n",
    "#Step3: Set the DATETIME column as the index\n",
    "df_106FT02A_spcl.set_index('DATETIME', inplace=True)\n",
    "\n",
    "#exc4\n",
    "#Sheet 106FT02B_spcl\n",
    "\n",
    "#Step1: Load the Data for the month\n",
    "df_106FT02B_spcl = pd.read_excel(r'C:\\Users\\v.t.flores\\Documents\\Analysis_November2019_MSdataCLEAN.xlsx', sheet_name='106FT02B_spcl', index_col=False)\n",
    "\n",
    "#Step2: Parse the DATETIME column\n",
    "df_106FT02B_spcl['DATETIME'] = df_106FT02B_spcl['DATETIME'].apply(lambda x: parse(x))\n",
    "\n",
    "#Step3: Set the DATETIME column as the index\n",
    "df_106FT02B_spcl.set_index('DATETIME', inplace=True)\n",
    "\n",
    "#exc5\n",
    "#Sheet From Pi\n",
    "#Step1: Load the Data for the month\n",
    "df_nov2019Pi = pd.read_excel(r'C:\\Users\\v.t.flores\\Documents\\Analysis_November2019_MSdataCLEAN.xlsx', sheet_name='From Pi', index_col=False)\n",
    "\n",
    "#Drop the row[1]\n",
    "df_nov2019Pi = df_nov2019Pi.drop(df_nov2019Pi.index[0])\n",
    "\n",
    "#Step2: Parse the DATETIME column\n",
    "df_nov2019Pi['DATETIME'] = df_nov2019Pi['DATETIME'].apply(lambda x: parse(str(x)))\n",
    "\n",
    "df_nov2019Pi.set_index('DATETIME', inplace=True)\n",
    "\n",
    "#exc6\n",
    "#This code merges the formatted data from the three sheets to on single dataframe named df_comb\n",
    "\n",
    "df_com_Pi_FT02A = df_nov2019Pi.join(df_106FT02A_spcl, how='outer')\n",
    "df_com_Mg_FT02B = df_nov2019_Mg_PS.join(df_106FT02B_spcl, how='outer')\n",
    "df_comb = df_com_Pi_FT02A.join(df_com_Mg_FT02B, how='outer')\n",
    "\n",
    "\n",
    "#exc7\n",
    "#finding peaks FT for A_filtration time\n",
    "\n",
    "df_comb['A_t_FEED'] = pd.to_numeric(df_comb['A_t_FEED'], errors='coerce')\n",
    "a = np.diff(np.sign(np.diff(df_comb['A_t_FEED']))).nonzero()[0] + 1               # local min & max\n",
    "b = (np.diff(np.sign(np.diff(df_comb['A_t_FEED']))) > 0).nonzero()[0] + 1         # local min\n",
    "c = (np.diff(np.sign(np.diff(df_comb['A_t_FEED']))) < 0).nonzero()[0] + 1         # local max\n",
    "# +1 due to the fact that diff reduces the original index number\n",
    "\n",
    "\n",
    "#finding peaks FT for A_N2 Dry time\n",
    "\n",
    "df_comb['A_t_DRY'] = pd.to_numeric(df_comb['A_t_DRY'], errors='coerce')\n",
    "d = np.diff(np.sign(np.diff(df_comb['A_t_DRY']))).nonzero()[0] + 1               # local min & max\n",
    "e = (np.diff(np.sign(np.diff(df_comb['A_t_DRY']))) > 0).nonzero()[0] + 1         # local min\n",
    "f = (np.diff(np.sign(np.diff(df_comb['A_t_DRY']))) < 0).nonzero()[0] + 1         # local max\n",
    "# +1 due to the fact that diff reduces the original index number\n",
    "\n",
    "#Use b as the starting index and f as the ending index for one full cylcle of Filtration to N2 Drying\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#This code here collects the index range for the each cycle\n",
    "try:\n",
    "    ft_cyc_lim = {}\n",
    "\n",
    "    for i in range(0, len(b)):\n",
    "        for j in range(0, len(f)):\n",
    "            if f[j] > b[i] and f[j] < b[i+1]:\n",
    "                if f[j+1]<b[i+1]:\n",
    "                    cyc_start = b[i]\n",
    "                    cyc_end = f[j+1]\n",
    "                    ft_cyc_lim.setdefault(cyc_start,cyc_end)\n",
    "\n",
    "except IndexError:\n",
    "    print('\\nDone')\n",
    "#------------------------------------------------------------     \n",
    "\n",
    "print('Done', str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 2020-01-17 13:37:37.269221\n"
     ]
    }
   ],
   "source": [
    "keyslist = list(ft_cyc_lim.keys()) #creates a list of the ft_cyc_lim keys so that we can iterate later\n",
    "\n",
    "\n",
    "#code for getting the CWP for CakeWash1 and CakeWash2\n",
    "##Working as of 1/15/2020\n",
    "A_CWP_1new = list()\n",
    "A_CWP_1new[:] = []\n",
    "\n",
    "A_CWP_1_indexList = list()\n",
    "A_CWP_1_indexList[:] = []\n",
    "\n",
    "A_CWP_2new = list()\n",
    "A_CWP_2new[:] = []\n",
    "\n",
    "A_CWP_2_indexList = list()\n",
    "A_CWP_2_indexList[:] = []\n",
    "\n",
    "A_CWP_1_inner = list()\n",
    "A_CWP_1_inner[:] = []\n",
    "\n",
    "A_CWP_2_inner = list()\n",
    "A_CWP_2_inner[:] = []\n",
    "\n",
    "A_Pair_CWP_1_List = list()\n",
    "A_Pair_CWP_2_List = list()\n",
    "\n",
    "try:\n",
    "    for i in range(0, len(keyslist)):\n",
    "        A_CWPList_i = list()\n",
    "        A_CWPList_i[:] = []\n",
    "        d = list()\n",
    "        d[:] = []\n",
    "        \n",
    "        A_CWPList_i = list(np.arange(keyslist[i],ft_cyc_lim[keyslist[i]]))\n",
    "        d = (np.diff(np.sign(np.diff(df_comb['106FT02A_CWP'].iloc[keyslist[i]:ft_cyc_lim[keyslist[i]]])))< 0).nonzero()[0] + 1\n",
    "        A_CWP_for_sort = list()\n",
    "        A_CWP_for_sort[:] = [] \n",
    "        \n",
    "        A_CWP_1_indexList.append((str(df_comb.index[keyslist[i]])+\" to \"+str(df_comb.index[ft_cyc_lim[keyslist[i]]])))\n",
    "        A_CWP_2_indexList.append((str(df_comb.index[keyslist[i]])+\" to \"+str(df_comb.index[ft_cyc_lim[keyslist[i]]])))\n",
    "        \n",
    "        for i in range(0, len(d)):\n",
    "            CWP_val_shortlist = df_comb['106FT02A_CWP'].iloc[A_CWPList_i[d[i]]]\n",
    "            A_CWP_for_sort.append(CWP_val_shortlist)\n",
    "                    \n",
    "        A_CWP_1 = sorted(A_CWP_for_sort)[len(A_CWP_for_sort)-1]\n",
    "        A_CWP_1_inner.append(A_CWP_1)\n",
    "        \n",
    "        A_CWP_2 = sorted(A_CWP_for_sort)[len(A_CWP_for_sort)-2]\n",
    "        A_CWP_2_inner.append(A_CWP_2)\n",
    "\n",
    "    A_Pair_CWP_1_List = list(zip(A_CWP_1_inner, A_CWP_1_indexList[0:]))\n",
    "    A_Pair_CWP_2_List = list(zip(A_CWP_2_inner, A_CWP_2_indexList[0:]))\n",
    "            \n",
    "    \n",
    "except IndexError:\n",
    "    print('IndexError')\n",
    "\n",
    "df_A_Pair_CWP_1 = pd.DataFrame(A_Pair_CWP_1_List)\n",
    "df_A_Pair_CWP_1.columns = ['A_CWP_1', 'DATETIME']\n",
    "df_A_Pair_CWP_1.set_index('DATETIME', inplace=True)\n",
    "    \n",
    "df_A_Pair_CWP_2 = pd.DataFrame(A_Pair_CWP_2_List)\n",
    "df_A_Pair_CWP_2.columns = ['A_CWP_2', 'DATETIME']\n",
    "df_A_Pair_CWP_2.set_index('DATETIME', inplace=True)\n",
    "    \n",
    "    \n",
    "print('Done', str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 2020-01-17 13:37:37.826781\n"
     ]
    }
   ],
   "source": [
    "# This code will use the index range (or limits) to create a list of values: feedtime range, cake wash time range,\n",
    "# then selects the max value as the parameter value for that range\n",
    "\n",
    "#FILTRATION TIME\n",
    "keyslist = list(ft_cyc_lim.keys()) #creates a list of the ft_cyc_lim keys so that we can iterate later\n",
    "#For loop Dictionary names \n",
    "A_Filt_MaxList= list()\n",
    "A_Filt_MaxList[:] = []\n",
    "A_feedt_Val_List = list()\n",
    "A_feedt_Val_List[:] = []\n",
    "A_feedt_index_List = list()\n",
    "A_feedt_index_List[:] = []\n",
    "A_Pair_Filt_List = list()\n",
    "A_Pair_Filt_List[:] = []\n",
    "try:         \n",
    "    for i in range(0, len(keyslist)):\n",
    "        A_feedt_Val_List = list()\n",
    "        A_feedt_Val_List[:] = []\n",
    "        for j in range(keyslist[i], ft_cyc_lim[keyslist[i]]):\n",
    "            A_feedt = df_comb['A_t_FEED'][j]\n",
    "            A_feedt_Val_List.append(A_feedt)\n",
    "        A_Filt_MaxList.append(sorted(A_feedt_Val_List)[-1])\n",
    "        A_feedt_index_List.append((str(df_comb.index[keyslist[i]])+\" to \"+str(df_comb.index[ft_cyc_lim[keyslist[i]]])))  \n",
    "    A_Pair_Filt_List = list(zip(A_Filt_MaxList, A_feedt_index_List[0:]))      \n",
    "except:\n",
    "    pass\n",
    "\n",
    "df_A_Pair_Filt_t = pd.DataFrame(A_Pair_Filt_List)\n",
    "df_A_Pair_Filt_t.columns = ['A_FILT_T', 'DATETIME']\n",
    "df_A_Pair_Filt_t.set_index('DATETIME', inplace=True)\n",
    "\n",
    "print('Done', str(datetime.datetime.now()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 2020-01-17 13:37:38.383191\n"
     ]
    }
   ],
   "source": [
    "#MANIFOLD PRESSURE\n",
    "keyslist = list(ft_cyc_lim.keys()) #creates a list of the ft_cyc_lim keys so that we can iterate later\n",
    "#For loop Dictionary names \n",
    "A_MANFP_MaxList = list()\n",
    "A_MANFP_MaxList[:] = []\n",
    "A_Pair_MANFP_List =list() \n",
    "A_Pair_MANFP_List[:] = []\n",
    "A_MANFP_index_List=list()      \n",
    "A_MANFP_index_List[:] = []\n",
    "try:         \n",
    "    for i in range(0, len(keyslist)):\n",
    "        A_MANFP_val_List=list() \n",
    "        A_MANFP_val_List[:] = []\n",
    "        for j in range(keyslist[i], ft_cyc_lim[keyslist[i]]):               \n",
    "            #Gets A manifold pressure of the cycle\n",
    "            A_MANFP = df_comb['106FT02A_MANFP'][j]         \n",
    "            A_MANFP_val_List.append(A_MANFP)\n",
    "        A_MANFP_MaxList.append(sorted(A_MANFP_val_List)[-1])\n",
    "        A_MANFP_index_List.append((str(df_comb.index[keyslist[i]])+\" to \"+str(df_comb.index[ft_cyc_lim[keyslist[i]]])))\n",
    "    A_Pair_MANFP_List = list(zip(A_MANFP_MaxList, A_MANFP_index_List[0:]))      \n",
    "                        \n",
    "except:\n",
    "    pass\n",
    "\n",
    "df_A_Pair_MANF_P = pd.DataFrame(A_Pair_MANFP_List)\n",
    "df_A_Pair_MANF_P.columns = ['A_MANF_P', 'DATETIME']\n",
    "df_A_Pair_MANF_P.set_index('DATETIME', inplace=True)\n",
    "\n",
    "print('Done', str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 2020-01-17 13:37:38.933391\n"
     ]
    }
   ],
   "source": [
    "#CWSH1\n",
    "##wORKING as of 2020.01.15\n",
    "\n",
    "keyslist = list(ft_cyc_lim.keys()) #creates a list of the ft_cyc_lim keys so that we can iterate later\n",
    "\n",
    "A_t_CWSH1_Maxlist = list()\n",
    "A_t_CWSH1_Maxlist[:] = []\n",
    "\n",
    "A_CWSH1_index_List=list()      \n",
    "A_CWSH1_index_List[:] = []\n",
    "\n",
    "A_Pair_CWSH1_List =list() \n",
    "A_Pair_CWSH1_List[:] = []\n",
    "try:         \n",
    "    for i in range(0, len(keyslist)):\n",
    "        A_t_CWSH1_val_List=list() \n",
    "        A_t_CWSH1_val_List[:] = []\n",
    "        for j in range(keyslist[i], ft_cyc_lim[keyslist[i]]):               \n",
    "            A_t_CWSH1 = df_comb['A_t_CWSH1'][j]         \n",
    "            A_t_CWSH1_val_List.append(A_t_CWSH1)\n",
    "        A_t_CWSH1_Maxlist.append(sorted(A_t_CWSH1_val_List)[-1])\n",
    "        A_CWSH1_index_List.append((str(df_comb.index[keyslist[i]])+\" to \"+str(df_comb.index[ft_cyc_lim[keyslist[i]]])))\n",
    "    A_Pair_CWSH1_List = list(zip(A_t_CWSH1_Maxlist, A_CWSH1_index_List[0:]))      \n",
    "                        \n",
    "except:\n",
    "    pass\n",
    "df_A_Pair_CWSH1 = pd.DataFrame(A_Pair_CWSH1_List)\n",
    "df_A_Pair_CWSH1.columns = ['A_CWSH1', 'DATETIME']\n",
    "df_A_Pair_CWSH1.set_index('DATETIME', inplace=True)\n",
    "\n",
    "print('Done', str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 2020-01-17 13:37:39.489211\n"
     ]
    }
   ],
   "source": [
    "#CWSH2\n",
    "##wORKING as of 2020.01.15\n",
    "keyslist = list(ft_cyc_lim.keys()) #creates a list of the ft_cyc_lim keys so that we can iterate later\n",
    "\n",
    "A_t_CWSH2_Maxlist = list()\n",
    "A_t_CWSH2_Maxlist[:] = []\n",
    "\n",
    "A_CWSH2_index_List=list()      \n",
    "A_CWSH2_index_List[:] = []\n",
    "\n",
    "A_Pair_CWSH2_List =list() \n",
    "A_Pair_CWSH2_List[:] = []\n",
    "try:         \n",
    "    for i in range(0, len(keyslist)):\n",
    "        A_t_CWSH2_val_List=list() \n",
    "        A_t_CWSH2_val_List[:] = []\n",
    "        for j in range(keyslist[i], ft_cyc_lim[keyslist[i]]):               \n",
    "            A_t_CWSH2 = df_comb['A_t_CWSH2'][j]         \n",
    "            A_t_CWSH2_val_List.append(A_t_CWSH2)\n",
    "        A_t_CWSH2_Maxlist.append(sorted(A_t_CWSH2_val_List)[-1])\n",
    "        A_CWSH2_index_List.append((str(df_comb.index[keyslist[i]])+\" to \"+str(df_comb.index[ft_cyc_lim[keyslist[i]]])))\n",
    "    A_Pair_CWSH2_List = list(zip(A_t_CWSH2_Maxlist, A_CWSH2_index_List[0:]))      \n",
    "                        \n",
    "except:\n",
    "    pass\n",
    "  \n",
    "df_A_Pair_CWSH2 = pd.DataFrame(A_Pair_CWSH2_List)\n",
    "df_A_Pair_CWSH2.columns = ['A_CWSH2', 'DATETIME']\n",
    "df_A_Pair_CWSH2.set_index('DATETIME', inplace=True)\n",
    "print('Done', str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 2020-01-17 13:37:40.041298\n"
     ]
    }
   ],
   "source": [
    "#Pressing_1\n",
    "##wORKING as of 2020.01.15\n",
    "keyslist = list(ft_cyc_lim.keys()) #creates a list of the ft_cyc_lim keys so that we can iterate later\n",
    "\n",
    "A_t_Press1_Maxlist = list()\n",
    "A_t_Press1_Maxlist[:] = []\n",
    "\n",
    "A_t_Press1_index_List=list()      \n",
    "A_t_Press1_index_List[:] = []\n",
    "\n",
    "A_Pair_A_t_Press1_List =list() \n",
    "A_Pair_A_t_Press1_List[:] = []\n",
    "try:         \n",
    "    for i in range(0, len(keyslist)):\n",
    "        A_t_Press1_val_List=list() \n",
    "        A_t_Press1_val_List[:] = []\n",
    "        for j in range(keyslist[i], ft_cyc_lim[keyslist[i]]):               \n",
    "            A_t_Press1 = df_comb['A_t_PRESS1'][j]         \n",
    "            A_t_Press1_val_List.append(A_t_Press1)\n",
    "        A_t_Press1_Maxlist.append(sorted(A_t_Press1_val_List)[-1])\n",
    "        A_t_Press1_index_List.append((str(df_comb.index[keyslist[i]])+\" to \"+str(df_comb.index[ft_cyc_lim[keyslist[i]]])))\n",
    "    A_Pair_Press1_List = list(zip(A_t_Press1_Maxlist, A_t_Press1_index_List[0:]))      \n",
    "                        \n",
    "except:\n",
    "    pass\n",
    "df_A_Pair_PRESS1_t = pd.DataFrame(A_Pair_Press1_List)\n",
    "df_A_Pair_PRESS1_t.columns = ['A_PRESS1_t', 'DATETIME']\n",
    "df_A_Pair_PRESS1_t.set_index('DATETIME', inplace=True)\n",
    "print('Done', str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 2020-01-17 13:37:40.587954\n"
     ]
    }
   ],
   "source": [
    "#Pressing_2\n",
    "##wORKING as of 2020.01.15\n",
    "keyslist = list(ft_cyc_lim.keys()) #creates a list of the ft_cyc_lim keys so that we can iterate later\n",
    "\n",
    "A_t_Press2_Maxlist = list()\n",
    "A_t_Press2_Maxlist[:] = []\n",
    "\n",
    "A_t_Press2_index_List=list()      \n",
    "A_t_Press2_index_List[:] = []\n",
    "\n",
    "A_Pair_Press2_List =list() \n",
    "A_Pair_Press2_List[:] = []\n",
    "try:         \n",
    "    for i in range(0, len(keyslist)):\n",
    "        A_t_Press2_val_List=list() \n",
    "        A_t_Press2_val_List[:] = []\n",
    "        for j in range(keyslist[i], ft_cyc_lim[keyslist[i]]):               \n",
    "            A_t_Press2 = df_comb['A_t_PRESS2'][j]         \n",
    "            A_t_Press2_val_List.append(A_t_Press2)\n",
    "        A_t_Press2_Maxlist.append(sorted(A_t_Press2_val_List)[-1])\n",
    "        A_t_Press2_index_List.append((str(df_comb.index[keyslist[i]])+\" to \"+str(df_comb.index[ft_cyc_lim[keyslist[i]]])))\n",
    "    A_Pair_Press2_List = list(zip(A_t_Press2_Maxlist, A_t_Press2_index_List[0:]))      \n",
    "                        \n",
    "except:\n",
    "    pass\n",
    "  \n",
    "df_A_Pair_PRESS2_t = pd.DataFrame(A_Pair_Press2_List)\n",
    "df_A_Pair_PRESS2_t.columns = ['A_PRESS2_t', 'DATETIME']\n",
    "df_A_Pair_PRESS2_t.set_index('DATETIME', inplace=True)\n",
    "print('Done', str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 2020-01-17 13:37:41.130163\n"
     ]
    }
   ],
   "source": [
    "#A_PU26A_OP\n",
    "##Working as of 2020.01.15\n",
    "A_PU26A_OP_Maxlist = list()\n",
    "A_PU26A_OP_Maxlist[:] = []\n",
    "\n",
    "A_PU26A_OP_index_List=list()      \n",
    "A_PU26A_OP_index_List[:] = []\n",
    "\n",
    "A_Pair_PU26A_OP_List =list() \n",
    "A_Pair_PU26A_OP_List[:] = []\n",
    "try:         \n",
    "    for i in range(0, len(keyslist)):\n",
    "        A_PU26A_OP_val_List=list() \n",
    "        A_PU26A_OP_val_List[:] = []\n",
    "        for j in range(keyslist[i], ft_cyc_lim[keyslist[i]]):               \n",
    "            A_PU26A_OP = df_comb['PU26A_OP'][j]      \n",
    "            A_PU26A_OP_val_List.append(A_PU26A_OP)\n",
    "        A_PU26A_OP_Maxlist.append(sorted(A_PU26A_OP_val_List)[-1])\n",
    "        A_PU26A_OP_index_List.append((str(df_comb.index[keyslist[i]])+\" to \"+str(df_comb.index[ft_cyc_lim[keyslist[i]]])))\n",
    "    A_Pair_PU26A_OP_List = list(zip(A_PU26A_OP_Maxlist, A_PU26A_OP_index_List[0:]))          \n",
    "except:\n",
    "    pass\n",
    "df_A_Pair_PU26A_OP = pd.DataFrame(A_Pair_PU26A_OP_List)\n",
    "df_A_Pair_PU26A_OP.columns = ['A_PU26A_OP', 'DATETIME']\n",
    "df_A_Pair_PU26A_OP.set_index('DATETIME', inplace=True)\n",
    "print('Done', str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 2020-01-17 13:37:41.680913\n"
     ]
    }
   ],
   "source": [
    "#A_PU27A_OP\n",
    "##Working as of 2020.01.15\n",
    "keyslist = list(ft_cyc_lim.keys()) #creates a list of the ft_cyc_lim keys so that we can iterate later\n",
    "\n",
    "A_PU27A_OP_Maxlist = list()\n",
    "A_PU27A_OP_Maxlist[:] = []\n",
    "\n",
    "A_PU27A_OP_index_List=list()      \n",
    "A_PU27A_OP_index_List[:] = []\n",
    "\n",
    "A_Pair_PU27A_OP_List =list() \n",
    "A_Pair_PU27A_OP_List[:] = []\n",
    "try:         \n",
    "    for i in range(0, len(keyslist)):\n",
    "        A_PU27A_OP_val_List=list() \n",
    "        A_PU27A_OP_val_List[:] = []\n",
    "        for j in range(keyslist[i], ft_cyc_lim[keyslist[i]]):               \n",
    "            A_PU27A_OP = df_comb['PU27A_OP'][j]      \n",
    "            A_PU27A_OP_val_List.append(A_PU27A_OP)\n",
    "        A_PU27A_OP_Maxlist.append(sorted(A_PU27A_OP_val_List)[-1])\n",
    "        A_PU27A_OP_index_List.append((str(df_comb.index[keyslist[i]])+\" to \"+str(df_comb.index[ft_cyc_lim[keyslist[i]]])))\n",
    "    A_Pair_PU27A_OP_List = list(zip(A_PU27A_OP_Maxlist, A_PU27A_OP_index_List[0:]))          \n",
    "except:\n",
    "    pass\n",
    "  \n",
    "df_A_Pair_PU27A_OP = pd.DataFrame(A_Pair_PU27A_OP_List)\n",
    "df_A_Pair_PU27A_OP.columns = ['A_PU27A_OP', 'DATETIME']\n",
    "df_A_Pair_PU27A_OP.set_index('DATETIME', inplace=True)\n",
    "print('Done', str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 2020-01-17 13:37:43.386747\n"
     ]
    }
   ],
   "source": [
    "#this code replaces the 'No Good Data' from 106PU26A_CUR column\n",
    "for x in range(0, len(df_comb['106PU26A_CUR'])):\n",
    "    if df_comb['106PU26A_CUR'][x] =='[-11059] No Good Data For Calculation':\n",
    "            df_comb['106PU26A_CUR'][x] = 0\n",
    "#A_PU26A_CUR\n",
    "##Working as of 2020.01.15\n",
    "keyslist = list(ft_cyc_lim.keys()) #creates a list of the ft_cyc_lim keys so that we can iterate later\n",
    "\n",
    "A_PU26A_CUR_Maxlist = list()\n",
    "A_PU26A_CUR_Maxlist[:] = []\n",
    "\n",
    "A_PU26A_CUR_index_List=list()      \n",
    "A_PU26A_CUR_index_List[:] = []\n",
    "\n",
    "A_Pair_PU26A_CUR_List =list() \n",
    "A_Pair_PU26A_CUR_List[:] = []\n",
    "try:         \n",
    "    for i in range(0, len(keyslist)):\n",
    "        A_PU26A_CUR_val=list() \n",
    "        A_PU26A_CUR_val[:] = []\n",
    "        for j in range(keyslist[i], ft_cyc_lim[keyslist[i]]):               \n",
    "            A_PU26A_CUR = df_comb['106PU26A_CUR'][j]      \n",
    "            A_PU26A_CUR_val.append(A_PU26A_CUR)\n",
    "        A_PU26A_CUR_Maxlist.append(sorted(A_PU26A_CUR_val)[-1])\n",
    "        A_PU26A_CUR_index_List.append((str(df_comb.index[keyslist[i]])+\" to \"+str(df_comb.index[ft_cyc_lim[keyslist[i]]])))\n",
    "    A_Pair_PU26A_CUR_List = list(zip(A_PU26A_CUR_Maxlist, A_PU26A_CUR_index_List[0:]))          \n",
    "except:\n",
    "    pass\n",
    "\n",
    "df_A_Pair_PU26A_CUR = pd.DataFrame(A_Pair_PU26A_CUR_List)\n",
    "df_A_Pair_PU26A_CUR.columns = ['A_PU26A_CUR', 'DATETIME']\n",
    "df_A_Pair_PU26A_CUR.set_index('DATETIME', inplace=True)\n",
    "print('Done', str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 2020-01-17 13:37:44.954329\n"
     ]
    }
   ],
   "source": [
    "#this code replaces the 'No Good Data' from 106PU26A_CUR column\n",
    "for x in range(0, len(df_comb['106PU27A_CUR'])):\n",
    "    if df_comb['106PU27A_CUR'][x] =='[-11059] No Good Data For Calculation':\n",
    "            df_comb['106PU27A_CUR'][x] = 0\n",
    "#A_PU27A_CUR\n",
    "##Working as of 2020.01.15 after a million trials!!!!!!!!!! mabuak na akong utok!!!\n",
    "keyslist = list(ft_cyc_lim.keys()) #creates a list of the ft_cyc_lim keys so that we can iterate later\n",
    "\n",
    "A_PU27A_CUR_Maxlist = list()\n",
    "A_PU27A_CUR_Maxlist[:] = []\n",
    "\n",
    "A_PU27A_CUR_index_List=list()      \n",
    "A_PU27A_CUR_index_List[:] = []\n",
    "\n",
    "A_Pair_PU27A_CUR_List =list() \n",
    "A_Pair_PU27A_CUR_List[:] = []\n",
    "try:         \n",
    "    for i in range(0, len(keyslist)):\n",
    "        A_PU27A_CUR_val=list() \n",
    "        A_PU27A_CUR_val[:] = []\n",
    "        for j in range(keyslist[i], ft_cyc_lim[keyslist[i]]):               \n",
    "            A_PU27A_CUR = df_comb['106PU27A_CUR'][j]      \n",
    "            A_PU27A_CUR_val.append(A_PU27A_CUR)\n",
    "        A_PU27A_CUR_Maxlist.append(sorted(A_PU27A_CUR_val)[-1])\n",
    "        A_PU27A_CUR_index_List.append((str(df_comb.index[keyslist[i]])+\" to \"+str(df_comb.index[ft_cyc_lim[keyslist[i]]])))\n",
    "    A_Pair_PU27A_CUR_List = list(zip(A_PU27A_CUR_Maxlist, A_PU27A_CUR_index_List[0:]))          \n",
    "except:\n",
    "    pass\n",
    "  \n",
    "df_A_Pair_PU27A_CUR = pd.DataFrame(A_Pair_PU27A_CUR_List)\n",
    "df_A_Pair_PU27A_CUR.columns = ['A_PU27A_CUR', 'DATETIME']\n",
    "df_A_Pair_PU27A_CUR.set_index('DATETIME', inplace=True)\n",
    "print('Done', str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 2020-01-17 13:37:45.012148\n"
     ]
    }
   ],
   "source": [
    "#A_N2 Dry\n",
    "##Working as of 2020-01-15 17:26:09.736327\n",
    "A_Pair_N2_Dry_List = list()\n",
    "A_Pair_N2_Dry_List[:] = []\n",
    "A_t_N2_Dry_indexList = list()\n",
    "A_t_N2_Dry_indexList[:] = []\n",
    "A_t_N2_Dry_val = list()\n",
    "A_t_N2_Dry_val[:] = []\n",
    "try:         \n",
    "    for i in range(0, len(keyslist)):   \n",
    "        A_t_N2_Dry = df_comb['A_t_DRY'][ft_cyc_lim[keyslist[i]]]\n",
    "        A_t_N2_Dry_val.append(A_t_N2_Dry)\n",
    "        A_t_N2_Dry_indexList.append((str(df_comb.index[keyslist[i]])+\" to \"+str(df_comb.index[ft_cyc_lim[keyslist[i]]])))\n",
    "    \n",
    "    A_Pair_N2_Dry_List = list(zip(A_t_N2_Dry_val, A_t_N2_Dry_indexList[0:]))          \n",
    "except:\n",
    "    pass\n",
    "\n",
    "df_A_Pair_N2DRY = pd.DataFrame(A_Pair_N2_Dry_List)\n",
    "df_A_Pair_N2DRY.columns = ['A_N2DRY', 'DATETIME']\n",
    "df_A_Pair_N2DRY.set_index('DATETIME', inplace=True)\n",
    "print('Done', str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 2020-01-17 13:37:45.102201\n"
     ]
    }
   ],
   "source": [
    "dfn = df_A_Pair_CWP_1.join(df_A_Pair_CWP_2, how='outer')\n",
    "dfn1 = df_A_Pair_Filt_t.join(df_A_Pair_MANF_P, how='outer')\n",
    "dfn2 = df_A_Pair_CWSH1.join(df_A_Pair_CWSH2, how='outer')\n",
    "dfn3 = df_A_Pair_PRESS1_t.join(df_A_Pair_PRESS2_t, how='outer')\n",
    "dfn4 = df_A_Pair_PU26A_OP.join(df_A_Pair_PU27A_OP, how='outer')\n",
    "dfn5 = df_A_Pair_PU26A_CUR.join(df_A_Pair_PU27A_CUR, how='outer')\n",
    "dfn6 = df_A_Pair_N2DRY.join(dfn, how='outer')\n",
    "dfn7 = dfn1.join(dfn2, how='outer')\n",
    "dfn8 = dfn3.join(dfn4, how='outer')\n",
    "dfn9 = dfn5.join(dfn6, how='outer')\n",
    "dfn10 = dfn7.join(dfn8, how='outer')\n",
    "dfn11 = dfn9.join(dfn10, how='outer')\n",
    "print('Done', str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####This block of code appends the Analysis Results from 106TH01 UF\n",
    "import datetime\n",
    "from dateutil.parser import parse\n",
    "import pandas as pd\n",
    "\n",
    "import openpyxl\n",
    "wb1 = openpyxl.load_workbook(r'C:\\Users\\v.t.flores\\Documents\\Copy of 11.) November_ 2019.xlsx')\n",
    "TH01_UF_sheet = wb1['106TH01 UF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "TH01_UF_sheet['S'+str(9)].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TH01_UF_sheet['B'+str(9)].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "Done 2020-01-17 12:55:06.727257\n"
     ]
    }
   ],
   "source": [
    "#This code finds the indexloc of the cells with day number from the sampling date column\n",
    "rows_n = list()\n",
    "try:\n",
    "    for i in range (1, TH01_UF_sheet.max_row+1):\n",
    "        if type(TH01_UF_sheet['B'+ str(i)].value) == int:\n",
    "            #print(str(i)+':'+str(TH01_UF_sheet['B'+ str(i)].value))\n",
    "            rows_n.append(i)\n",
    "except:\n",
    "    pass\n",
    "#--------------------------\n",
    "#This code finds the Pb concentration and the datetime\n",
    "Pb_df_list = list()\n",
    "Pb_df_list[:] = []\n",
    "PbList = list()\n",
    "PbList[:] = []\n",
    "timeList = list()\n",
    "timeList[:] = []\n",
    "\n",
    "for i in range(0, len(rows_n)-1):\n",
    "    for j in range(rows_n[i], rows_n[i+1]):        \n",
    "        if TH01_UF_sheet['S'+str(j)].value != None and type(TH01_UF_sheet['S'+str(j)].value) == float:\n",
    "            if  type(TH01_UF_sheet['C'+str(j)].value) == datetime.datetime:\n",
    "                time_val = TH01_UF_sheet['C'+str(j)].value           \n",
    "                strdate = parse(str(time_val))\n",
    "                newtime = str(strdate).split(\" \")[1]\n",
    "                if newtime == '03:00:00':\n",
    "                    newdate = str(datetime.date(2019,11,1)-timedelta(1)+timedelta(TH01_UF_sheet['B'+str(rows_n[i+1])].value))+' '+newtime\n",
    "                else:\n",
    "                    newdate = str(datetime.date(2019,11,1)-timedelta(1) +timedelta(TH01_UF_sheet['B'+str(rows_n[i])].value))+' '+newtime\n",
    "          \n",
    "            elif type(TH01_UF_sheet['C'+str(j)].value) == datetime.time:\n",
    "                time_val = TH01_UF_sheet['C'+str(j)].value           \n",
    "                strdate = str(time_val)\n",
    "                if strdate == '03:00:00':\n",
    "                    newdate = str(datetime.date(2019,11,1)-timedelta(1)+timedelta(TH01_UF_sheet['B'+str(rows_n[i+1])].value))+' '+strdate\n",
    "                else:\n",
    "                    newdate = str(datetime.date(2019,11,1)-timedelta(1) +timedelta(TH01_UF_sheet['B'+str(rows_n[i])].value))+' '+strdate       \n",
    "        \n",
    "            timeList.append(parse(newdate))\n",
    "            Pb_val = TH01_UF_sheet['S'+str(j)].value\n",
    "            PbList.append(Pb_val)\n",
    "    #print(TH01_UF_sheet['B'+str(rows_n[i])].value)\n",
    "Pb_df_list = list(zip(PbList, timeList[0:]))\n",
    "\n",
    "#converting lists to dataframe\n",
    "Pb_df = pd.DataFrame(Pb_df_list)\n",
    "Pb_df.columns = ['Pb', 'DATETIME']\n",
    "Pb_df.set_index('DATETIME', inplace=True)\n",
    "print('done')\n",
    "#--------------\n",
    "#This code finds the Zn concentration and the datetime\n",
    "\n",
    "Zn_df_list = list()\n",
    "Zn_df_list[:] = []\n",
    "ZnList = list()\n",
    "ZnList[:] = []\n",
    "ZntimeList = list()\n",
    "ZntimeList[:] = []\n",
    "\n",
    "for i in range(0, len(rows_n)-1):\n",
    "    for j in range(rows_n[i], rows_n[i+1]):        \n",
    "        if TH01_UF_sheet['T'+str(j)].value != None and type(TH01_UF_sheet['T'+str(j)].value) == float:\n",
    "            if  type(TH01_UF_sheet['C'+str(j)].value) == datetime.datetime:\n",
    "                time_val = TH01_UF_sheet['C'+str(j)].value           \n",
    "                strdate = parse(str(time_val))\n",
    "                newtime = str(strdate).split(\" \")[1]\n",
    "                if newtime == '03:00:00':\n",
    "                    newdate = str(datetime.date(2019,11,1)-timedelta(1)+timedelta(TH01_UF_sheet['B'+str(rows_n[i+1])].value))+' '+newtime\n",
    "                else:\n",
    "                    newdate = str(datetime.date(2019,11,1)-timedelta(1) +timedelta(TH01_UF_sheet['B'+str(rows_n[i])].value))+' '+newtime\n",
    "          \n",
    "            elif type(TH01_UF_sheet['C'+str(j)].value) == datetime.time:\n",
    "                time_val = TH01_UF_sheet['C'+str(j)].value           \n",
    "                strdate = str(time_val)\n",
    "                if strdate == '03:00:00':\n",
    "                    newdate = str(datetime.date(2019,11,1)-timedelta(1)+timedelta(TH01_UF_sheet['B'+str(rows_n[i+1])].value))+' '+strdate\n",
    "                else:\n",
    "                    newdate = str(datetime.date(2019,11,1)-timedelta(1) +timedelta(TH01_UF_sheet['B'+str(rows_n[i])].value))+' '+strdate       \n",
    "            \n",
    "            timeList.append(parse(newdate))\n",
    "            Zn_val = TH01_UF_sheet['T'+str(j)].value\n",
    "            ZnList.append(Zn_val)\n",
    "    #print(TH01_UF_sheet['B'+str(rows_n[i])].value)\n",
    "Zn_df_list = list(zip(ZnList, timeList[0:]))\n",
    "\n",
    "#converting lists to dataframe\n",
    "Zn_df = pd.DataFrame(Zn_df_list)\n",
    "Zn_df.columns = ['Zn', 'DATETIME']\n",
    "Zn_df.set_index('DATETIME', inplace=True)\n",
    "\n",
    "#--------------\n",
    "#This code finds the Cu concentration and the datetime\n",
    "\n",
    "Cu_df_list = list()\n",
    "Cu_df_list[:] = []\n",
    "CuList = list()\n",
    "CuList[:] = []\n",
    "CutimeList = list()\n",
    "CutimeList[:] = []\n",
    "\n",
    "for i in range(0, len(rows_n)-1):\n",
    "    for j in range(rows_n[i], rows_n[i+1]):        \n",
    "        if TH01_UF_sheet['U'+str(j)].value != None and type(TH01_UF_sheet['U'+str(j)].value) == float: ##check if column is updated\n",
    "            if  type(TH01_UF_sheet['C'+str(j)].value) == datetime.datetime:\n",
    "                time_val = TH01_UF_sheet['C'+str(j)].value           \n",
    "                strdate = parse(str(time_val))\n",
    "                newtime = str(strdate).split(\" \")[1]\n",
    "                if newtime == '03:00:00':\n",
    "                    newdate = str(datetime.date(2019,11,1)-timedelta(1)+timedelta(TH01_UF_sheet['B'+str(rows_n[i+1])].value))+' '+newtime\n",
    "                else:\n",
    "                    newdate = str(datetime.date(2019,11,1)-timedelta(1) +timedelta(TH01_UF_sheet['B'+str(rows_n[i])].value))+' '+newtime\n",
    "          \n",
    "            elif type(TH01_UF_sheet['C'+str(j)].value) == datetime.time:\n",
    "                time_val = TH01_UF_sheet['C'+str(j)].value           \n",
    "                strdate = str(time_val)\n",
    "                if strdate == '03:00:00':\n",
    "                    newdate = str(datetime.date(2019,11,1)-timedelta(1)+timedelta(TH01_UF_sheet['B'+str(rows_n[i+1])].value))+' '+strdate\n",
    "                else:\n",
    "                    newdate = str(datetime.date(2019,11,1)-timedelta(1) +timedelta(TH01_UF_sheet['B'+str(rows_n[i])].value))+' '+strdate       \n",
    "               \n",
    "            timeList.append(parse(newdate))\n",
    "            Cu_val = TH01_UF_sheet['U'+str(j)].value ##check if column and varname is updated\n",
    "            CuList.append(Cu_val) ##check if list title is updated\n",
    "Cu_df_list = list(zip(CuList, timeList[0:]))\n",
    "\n",
    "#converting lists to dataframe\n",
    "Cu_df = pd.DataFrame(Zn_df_list)\n",
    "Cu_df.columns = ['Cu', 'DATETIME'] ##check if list title is updated\n",
    "Cu_df.set_index('DATETIME', inplace=True)\n",
    "\n",
    "#--------------\n",
    "#This code finds the Mg concentration and the datetime\n",
    "Mg_df_list = list()\n",
    "Mg_df_list[:] = []\n",
    "MgList = list()\n",
    "MgList[:] = []\n",
    "MgtimeList = list()\n",
    "MgtimeList[:] = []\n",
    "\n",
    "for i in range(0, len(rows_n)-1):\n",
    "    for j in range(rows_n[i], rows_n[i+1]):        \n",
    "        if TH01_UF_sheet['AD'+str(j)].value != None and type(TH01_UF_sheet['AD'+str(j)].value) == float: ##check if column is updated\n",
    "            if  type(TH01_UF_sheet['C'+str(j)].value) == datetime.datetime:\n",
    "                time_val = TH01_UF_sheet['C'+str(j)].value           \n",
    "                strdate = parse(str(time_val))\n",
    "                newtime = str(strdate).split(\" \")[1]\n",
    "                if newtime == '03:00:00':\n",
    "                    newdate = str(datetime.date(2019,11,1)-timedelta(1)+timedelta(TH01_UF_sheet['B'+str(rows_n[i+1])].value))+' '+newtime\n",
    "                else:\n",
    "                    newdate = str(datetime.date(2019,11,1)-timedelta(1) +timedelta(TH01_UF_sheet['B'+str(rows_n[i])].value))+' '+newtime\n",
    "          \n",
    "            elif type(TH01_UF_sheet['C'+str(j)].value) == datetime.time:\n",
    "                time_val = TH01_UF_sheet['C'+str(j)].value           \n",
    "                strdate = str(time_val)\n",
    "                if strdate == '03:00:00':\n",
    "                    newdate = str(datetime.date(2019,11,1)-timedelta(1)+timedelta(TH01_UF_sheet['B'+str(rows_n[i+1])].value))+' '+strdate\n",
    "                else:\n",
    "                    newdate = str(datetime.date(2019,11,1)-timedelta(1) +timedelta(TH01_UF_sheet['B'+str(rows_n[i])].value))+' '+strdate       \n",
    "                     \n",
    "            timeList.append(parse(newdate))\n",
    "            Mg_val = TH01_UF_sheet['AD'+str(j)].value ##check if column and varname are updated\n",
    "            MgList.append(Mg_val) ##check if list title is updated\n",
    "Mg_df_list = list(zip(MgList, timeList[0:])) ##check if the list titles and the df list are updated\n",
    "\n",
    "#converting lists to dataframe\n",
    "Mg_df = pd.DataFrame(Mg_df_list) ##check if the element list title is updated\n",
    "Mg_df.columns = ['Mg', 'DATETIME'] ##check if list title and the column name are updated\n",
    "Mg_df.set_index('DATETIME', inplace=True)\n",
    "#--------------\n",
    "\n",
    "dfEl1 = Pb_df.join(Mg_df, how='outer')\n",
    "dfEl2 = Cu_df.join(Zn_df, how='outer')\n",
    "dfEL3 = dfEl1.join(dfEl2, how='outer')\n",
    "print('Done', str(datetime.datetime.now()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fcn for formatting the dates from range str\n",
    "def datesplitter_start(x):\n",
    "    return parse(x.split('to')[0])\n",
    "def datesplitter_end(x):\n",
    "    return parse(x.split('to')[1])\n",
    "#---------\n",
    "dfn11['newdt'] = dfn11.index\n",
    "dfn11['startdate'] = dfn11['newdt'].apply(lambda x: datesplitter_start(x))\n",
    "dfn11['enddate'] = dfn11['newdt'].apply(lambda x: datesplitter_end(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for date index formattter\n",
    "df_anl_indexList = list()\n",
    "df_anl_indexList[:] = []\n",
    "df_n11_indexList = list()\n",
    "df_n11_indexList[:] = []\n",
    "\n",
    "try:\n",
    "    for i in range(0, 175):\n",
    "        for j in range(0, len(dfn11)):\n",
    "            if dfn11['enddate'][j-1] <= dfEL3.index[i] and dfn11['enddate'][j] >= dfEL3.index[i]:\n",
    "                df_n11_indexList.append(dfn11.index[j])\n",
    "                df_anl_indexList.append(dfEL3.index[i]) \n",
    "except IndexError:\n",
    "    print('IndexError')\n",
    "\n",
    "Analys_indexList_Pair = list(zip(df_anl_indexList, df_n11_indexList[0:]))\n",
    "dfEL4 = pd.DataFrame(Analys_indexList_Pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for changing the index to Datetime in range format (from date1 to date2)\n",
    "df_anl_indexList = list()\n",
    "df_anl_indexList[:] = []\n",
    "df_n11_indexList = list()\n",
    "df_n11_indexList[:] = []\n",
    "try:\n",
    "    for i in range(0, 175):\n",
    "        for j in range(0, len(dfn11)):\n",
    "            if dfn11['enddate'][j-1] <= dfEL3.index[i] and dfn11['enddate'][j] >= dfEL3.index[i]:\n",
    "                df_n11_indexList.append(dfn11.index[j])\n",
    "                df_anl_indexList.append(dfEL3.index[i]) \n",
    "except IndexError:\n",
    "    print('IndexError')  \n",
    "Analys_indexList_Pair = list(zip(df_anl_indexList, df_n11_indexList[0:]))\n",
    "dfEL4 = pd.DataFrame(Analys_indexList_Pair)\n",
    "dfEL4.columns = ['DATETIME', 'FT_cycletimerange']\n",
    "dfEL4.set_index('DATETIME', inplace=True)\n",
    "\n",
    "dfEL5 = dfEL3.join(dfEL4, how='outer')\n",
    "dfEL5.columns = ['106TH_UF_Pb', '106TH_UF_Mg', '106TH_UF_Cu', '106TH_UF_Zn', 'DATETIME']\n",
    "dfEL5.set_index('DATETIME', inplace=True)\n",
    "df_Cycle_LabRes = dfn11.join(dfEL5, how='outer')\n",
    "\n",
    "#---------------dfEL5 is the is the analysis results data indexed by daterange format. readt for merging with dfn11(FT02A data from Pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfEL5.to_excel(r'C:\\Users\\v.t.flores\\Documents\\20200117AM_datetimerangep_i.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Cycle_LabRes.to_excel(r'C:\\Users\\v.t.flores\\Documents\\20200117AM_Cycle_LabRes_i.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfEL4.to_excel(r'C:\\Users\\v.t.flores\\Documents\\20200117AM_datetimerangep_dfEL4.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn12.to_excel(r'C:\\Users\\v.t.flores\\Documents\\201911Data_Mg_Inv_20200116.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 2020-01-17 13:09:33.400000\n"
     ]
    }
   ],
   "source": [
    "# This code will use the index range (or limits) to create a list of values: feedtime range, cake wash time range,\n",
    "# then selects the max value as the parameter value for that range\n",
    "\n",
    "#FILTRATION TIME\n",
    "keyslist = list(ft_cyc_lim.keys()) #creates a list of the ft_cyc_lim keys so that we can iterate later\n",
    "#For loop Dictionary names \n",
    "A_Filt_MaxList= list()\n",
    "A_Filt_MaxList[:] = []\n",
    "A_feedt_Val_List = list()\n",
    "A_feedt_Val_List[:] = []\n",
    "A_feedt_index_List = list()\n",
    "A_feedt_index_List[:] = []\n",
    "A_Pair_Filt_List = list()\n",
    "A_Pair_Filt_List[:] = []\n",
    "try:         \n",
    "    for i in range(0, len(keyslist)):\n",
    "        A_feedt_Val_List = list()\n",
    "        A_feedt_Val_List[:] = []\n",
    "        for j in range(keyslist[i], ft_cyc_lim[keyslist[i]]):\n",
    "            A_feedt = df_comb['A_t_FEED'][j]\n",
    "            A_feedt_Val_List.append(A_feedt)\n",
    "        A_Filt_MaxList.append(sorted(A_feedt_Val_List)[-1])\n",
    "        A_feedt_index_List.append((str(df_comb.index[keyslist[i]])+\" to \"+str(df_comb.index[ft_cyc_lim[keyslist[i]]])))  \n",
    "    A_Pair_Filt_List = list(zip(A_Filt_MaxList, A_feedt_index_List[0:]))      \n",
    "except:\n",
    "    pass\n",
    "\n",
    "df_A_Pair_Filt_t = pd.DataFrame(A_Pair_Filt_List)\n",
    "df_A_Pair_Filt_t.columns = ['A_FILT_T', 'DATETIME']\n",
    "df_A_Pair_Filt_t.set_index('DATETIME', inplace=True)\n",
    "\n",
    "print('Done', str(datetime.datetime.now()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A_FILT_T</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATETIME</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2019-11-01 00:11:00 to 2019-11-01 00:34:00</td>\n",
       "      <td>458.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-01 00:36:00 to 2019-11-01 00:59:00</td>\n",
       "      <td>484.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-01 01:02:00 to 2019-11-01 01:24:00</td>\n",
       "      <td>506.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-01 01:27:00 to 2019-11-01 01:51:00</td>\n",
       "      <td>564.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-01 01:53:00 to 2019-11-01 02:16:00</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-01 02:19:00 to 2019-11-01 02:42:00</td>\n",
       "      <td>458.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-01 02:44:00 to 2019-11-01 03:06:00</td>\n",
       "      <td>447.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-01 03:08:00 to 2019-11-01 03:31:00</td>\n",
       "      <td>475.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-01 03:34:00 to 2019-11-01 03:56:00</td>\n",
       "      <td>510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-01 03:59:00 to 2019-11-01 04:23:00</td>\n",
       "      <td>560.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-01 04:25:00 to 2019-11-01 04:49:00</td>\n",
       "      <td>572.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-01 05:19:00 to 2019-11-01 05:40:00</td>\n",
       "      <td>385.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-01 05:43:00 to 2019-11-01 06:04:00</td>\n",
       "      <td>398.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-01 06:06:00 to 2019-11-01 06:28:00</td>\n",
       "      <td>448.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-01 06:32:00 to 2019-11-01 06:54:00</td>\n",
       "      <td>476.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-01 06:56:00 to 2019-11-01 07:20:00</td>\n",
       "      <td>494.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-01 07:23:00 to 2019-11-01 07:47:00</td>\n",
       "      <td>518.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-01 07:49:00 to 2019-11-01 08:13:00</td>\n",
       "      <td>537.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-01 08:15:00 to 2019-11-01 08:40:00</td>\n",
       "      <td>601.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            A_FILT_T\n",
       "DATETIME                                            \n",
       "2019-11-01 00:11:00 to 2019-11-01 00:34:00     458.0\n",
       "2019-11-01 00:36:00 to 2019-11-01 00:59:00     484.0\n",
       "2019-11-01 01:02:00 to 2019-11-01 01:24:00     506.0\n",
       "2019-11-01 01:27:00 to 2019-11-01 01:51:00     564.0\n",
       "2019-11-01 01:53:00 to 2019-11-01 02:16:00     500.0\n",
       "2019-11-01 02:19:00 to 2019-11-01 02:42:00     458.0\n",
       "2019-11-01 02:44:00 to 2019-11-01 03:06:00     447.0\n",
       "2019-11-01 03:08:00 to 2019-11-01 03:31:00     475.0\n",
       "2019-11-01 03:34:00 to 2019-11-01 03:56:00     510.0\n",
       "2019-11-01 03:59:00 to 2019-11-01 04:23:00     560.0\n",
       "2019-11-01 04:25:00 to 2019-11-01 04:49:00     572.0\n",
       "2019-11-01 05:19:00 to 2019-11-01 05:40:00     385.0\n",
       "2019-11-01 05:43:00 to 2019-11-01 06:04:00     398.0\n",
       "2019-11-01 06:06:00 to 2019-11-01 06:28:00     448.0\n",
       "2019-11-01 06:32:00 to 2019-11-01 06:54:00     476.0\n",
       "2019-11-01 06:56:00 to 2019-11-01 07:20:00     494.0\n",
       "2019-11-01 07:23:00 to 2019-11-01 07:47:00     518.0\n",
       "2019-11-01 07:49:00 to 2019-11-01 08:13:00     537.0\n",
       "2019-11-01 08:15:00 to 2019-11-01 08:40:00     601.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_A_Pair_Filt_t.head(19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(239, 263)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(keyslist[9], ft_cyc_lim[keyslist[9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filtration_time_data_Nov2019 = pd.DataFrame(df_comb['A_t_FEED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filtration_time_data_Nov2019.to_excel(r'C:\\Users\\v.t.flores\\Documents\\20200117AM_Filtration_time_data_Nov2019.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "FT02_Spcl = wb1['106FT02AB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Pb_df_list = list()\n",
    "Pb_df_list[:] = []\n",
    "PbList = list()\n",
    "PbList[:] = []\n",
    "timeList = list()\n",
    "timeList[:] = []\n",
    "\n",
    "for i in range(0, len(rows_prod_day)-1):\n",
    "    for j in range(rows_prod_day[i], rows_prod_day[i+1]):        \n",
    "        if FT02_Spcl['S'+str(j)].value != None and type(FT02_Spcl['S'+str(j)].value) == float:\n",
    "            if  type(FT02_Spcl['C'+str(j)].value) == datetime.datetime:\n",
    "                time_val = FT02_Spcl['C'+str(j)].value           \n",
    "                strdate = parse(str(time_val))\n",
    "                newtime = str(strdate).split(\" \")[1]\n",
    "                if newtime == '03:00:00':\n",
    "                    newdate = str(datetime.date(2019,11,1)-timedelta(1)+timedelta(FT02_Spcl['B'+str(rows_n[i+1])].value))+' '+newtime\n",
    "                else:\n",
    "                    newdate = str(datetime.date(2019,11,1)-timedelta(1) +timedelta(FT02_Spcl['B'+str(rows_n[i])].value))+' '+newtime\n",
    "          \n",
    "            elif type(FT02_Spcl['C'+str(j)].value) == datetime.time:\n",
    "                time_val = FT02_Spcl['C'+str(j)].value           \n",
    "                strdate = str(time_val)\n",
    "                if strdate == '03:00:00':\n",
    "                    newdate = str(datetime.date(2019,11,1)-timedelta(1)+timedelta(FT02_Spcl['B'+str(rows_n[i+1])].value))+' '+strdate\n",
    "                else:\n",
    "                    newdate = str(datetime.date(2019,11,1)-timedelta(1) +timedelta(FT02_Spcl['B'+str(rows_n[i])].value))+' '+strdate       \n",
    "        \n",
    "            timeList.append(parse(newdate))\n",
    "            Pb_val = FT02_Spcl['S'+str(j)].value\n",
    "            PbList.append(Pb_val)\n",
    "    #print(TH01_UF_sheet['B'+str(rows_n[i])].value)\n",
    "Pb_df_list = list(zip(PbList, timeList[0:]))\n",
    "\n",
    "\n",
    "print('done')\n",
    "#--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'T'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_column_letter(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, max)\n",
    "FT02_Spcl.cell.(row=i, column=j).value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code finds the indexloc of the cells with day number from the sampling date column\n",
    "rows_prod_day = list()\n",
    "try:\n",
    "    for i in range (1, FT02_Spcl.max_row+1):\n",
    "        if type(FT02_Spcl['B'+ str(i)].value) == int:\n",
    "            #print(str(i)+':'+str(TH01_UF_sheet['B'+ str(i)].value))\n",
    "            rows_prod_day.append(i)\n",
    "except:\n",
    "    pass\n",
    "#--------------------------\n",
    "\n",
    "\n",
    "RosterData = {}\n",
    "for i in range(2, sheet.max_row + 1):\n",
    "    for j in range(2, sheet.max_column + 1):\n",
    "        \n",
    "        Smpl_t = sheet.cell(row=i, column=4).value.split(',')[0].upper()\n",
    "        date = sheet.cell(row=i, column=13).value\n",
    "        shift = sheet.cell(row=i, column=12).value\n",
    "        \n",
    "        if  nameP is not None:\n",
    "            if date is not None:\n",
    "                if shift is not None:            \n",
    "                    RosterData.setdefault(nameP, {})\n",
    "                    RosterData[nameP].setdefault(date, shift)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft02A_smpl_t_index = list()\n",
    "ft02A_smpl_t_index[:] = []\n",
    "for i in range(0, len(rows_prod_day)):\n",
    "    print(FT02_Spcl['B'+ str(rows_prod_day[i])].value)\n",
    "    for j in (rows_prod_day[i], rows_prod_day[i]):\n",
    "        if FT02_Spcl['C'+ str(j)].value =='106FT02A':\n",
    "            ft02A_smpl_t_index.append(j)\n",
    "            print(ft02A_smpl_t_index.append(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "325"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_prod_day[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106FT02A\n",
      "2019-11-02\n",
      "106FT02A\n",
      "2019-11-02\n",
      "106FT02A\n",
      "2019-11-02\n",
      "106FT02A\n",
      "2019-11-03\n",
      "106FT02A\n",
      "2019-11-03\n",
      "106FT02A\n",
      "2019-11-03\n",
      "106FT02A\n",
      "2019-11-03\n",
      "106FT02A\n",
      "2019-11-04\n",
      "106FT02A\n",
      "2019-11-04\n",
      "106FT02A\n",
      "2019-11-04\n",
      "106FT02A\n",
      "2019-11-05\n",
      "106FT02A\n",
      "2019-11-05\n",
      "106FT02A\n",
      "2019-11-05\n",
      "106FT02A\n",
      "2019-11-06\n",
      "106FT02A\n",
      "2019-11-06\n",
      "106FT02A\n",
      "2019-11-06\n",
      "106FT02A\n",
      "2019-11-07\n",
      "106FT02A\n",
      "2019-11-07\n",
      "106FT02A\n",
      "2019-11-07\n",
      "106FT02A\n",
      "2019-11-08\n",
      "106FT02A\n",
      "2019-11-08\n",
      "106FT02A\n",
      "2019-11-08\n",
      "106FT02A\n",
      "2019-11-08\n",
      "106FT02A\n",
      "2019-11-09\n",
      "106FT02A\n",
      "2019-11-09\n",
      "106FT02A\n",
      "2019-11-09\n",
      "106FT02A\n",
      "2019-11-10\n",
      "106FT02A\n",
      "2019-11-10\n",
      "106FT02A\n",
      "2019-11-11\n",
      "106FT02A\n",
      "2019-11-11\n",
      "106FT02A\n",
      "2019-11-11\n",
      "106FT02A\n",
      "2019-11-11\n",
      "106FT02A\n",
      "2019-11-11\n",
      "106FT02A\n",
      "2019-11-12\n",
      "106FT02A\n",
      "2019-11-12\n",
      "106FT02A\n",
      "2019-11-12\n",
      "106FT02A\n",
      "2019-11-13\n",
      "106FT02A\n",
      "2019-11-13\n",
      "106FT02A\n",
      "2019-11-13\n",
      "106FT02A\n",
      "2019-11-14\n",
      "106FT02A\n",
      "2019-11-14\n",
      "106FT02A\n",
      "2019-11-14\n",
      "106FT02A\n",
      "2019-11-15\n",
      "106FT02A\n",
      "2019-11-15\n",
      "106FT02A\n",
      "2019-11-15\n",
      "106FT02A\n",
      "2019-11-16\n",
      "106FT02A\n",
      "2019-11-16\n",
      "106FT02A\n",
      "2019-11-17\n",
      "106FT02A\n",
      "2019-11-17\n",
      "106FT02A\n",
      "2019-11-17\n",
      "106FT02A\n",
      "2019-11-18\n",
      "106FT02A\n",
      "2019-11-18\n",
      "106FT02A\n",
      "2019-11-18\n",
      "106FT02A\n",
      "2019-11-18\n",
      "106FT02A\n",
      "2019-11-18\n",
      "106FT02A\n",
      "2019-11-19\n",
      "106FT02A\n",
      "2019-11-19\n",
      "106FT02A\n",
      "2019-11-19\n",
      "106FT02A\n",
      "2019-11-19\n",
      "106FT02A\n",
      "2019-11-20\n",
      "106FT02A\n",
      "2019-11-20\n",
      "106FT02A\n",
      "2019-11-20\n",
      "106FT02A\n",
      "2019-11-21\n",
      "106FT02A\n",
      "2019-11-21\n",
      "106FT02A\n",
      "2019-11-21\n",
      "106FT02A\n",
      "2019-11-22\n",
      "106FT02A\n",
      "2019-11-22\n",
      "106FT02A\n",
      "2019-11-22\n",
      "106FT02A\n",
      "2019-11-23\n",
      "106FT02A\n",
      "2019-11-23\n",
      "106FT02A\n",
      "2019-11-23\n",
      "106FT02A\n",
      "2019-11-24\n",
      "106FT02A\n",
      "2019-11-24\n",
      "106FT02A\n",
      "2019-11-24\n",
      "106FT02A\n",
      "2019-11-24\n",
      "106FT02A\n",
      "2019-11-25\n",
      "106FT02A\n",
      "2019-11-25\n",
      "106FT02A\n",
      "2019-11-25\n",
      "106FT02A\n",
      "2019-11-26\n",
      "106FT02A\n",
      "2019-11-26\n",
      "106FT02A\n",
      "2019-11-26\n",
      "106FT02A\n",
      "2019-11-27\n",
      "106FT02A\n",
      "2019-11-27\n",
      "106FT02A\n",
      "2019-11-27\n",
      "106FT02A\n",
      "2019-11-28\n",
      "106FT02A\n",
      "2019-11-28\n",
      "106FT02A\n",
      "2019-11-28\n",
      "106FT02A\n",
      "2019-11-28\n",
      "106FT02A\n",
      "2019-11-29\n",
      "106FT02A\n",
      "2019-11-29\n",
      "106FT02A\n",
      "2019-11-29\n",
      "106FT02A\n",
      "2019-11-30\n",
      "106FT02A\n",
      "2019-11-30\n"
     ]
    }
   ],
   "source": [
    "for k in range(0, len(rows_prod_day)):\n",
    "    if rows_prod[k]\n",
    "        for m in range(rows_prod_day[k], rows_prod_day[k+1]):\n",
    "            if FT02_Spcl['C'+ str(m)].value =='106FT02A':\n",
    "                print(FT02_Spcl['C'+ str(m)].value)\n",
    "                #a = str(FT02_Spcl['D'+ str(m)].value).split(':')[0]\n",
    "                #b = str(FT02_Spcl['D'+ str(m)].value).split(':')[1]\n",
    "                print(datetime.date(2019,11,1)-datetime.timedelta(1)+datetime.timedelta(FT02_Spcl['B'+ str(rows_prod_day[k])].value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019-11-02'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(datetime.date(2019,11,1)+datetime.timedelta(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.time(5, 46)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FT02_Spcl['D'+ str(10)].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FT02_Spcl['B'+ str(325)].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, FT02_Spcl.max_row + 1):\n",
    "    if FT02_Spcl['C'+ str(i)].value == '106FT02A' or FT02_Spcl['C'+ str(i)].value == '106FT02B':\n",
    "        a = i "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "333"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-167-e7afc1a14549>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-167-e7afc1a14549>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    #print(k,m)\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "for k in range(0, len(rows_prod_day)):\n",
    "    for m in range(rows_prod_day[k], rows_prod_day[k+1]):\n",
    "        if FT02_Spcl['C'+ str(m)].value =='106FT02A':\n",
    "            #print(k,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01:18:00\n",
      "01:03:00\n",
      "None\n",
      "04:57:00\n",
      "23:48:00\n",
      "None\n",
      "09:33:00\n",
      "10:17:00\n",
      "None\n",
      "13:05:00\n",
      "13:00:00\n",
      "None\n",
      "16:47:00\n",
      "16:42:00\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, FT02_Spcl.max_row + 1):\n",
    "    if FT02_Spcl['C'+ str(i)].value == '106FT02A' or FT02_Spcl['C'+ str(i)].value == '106FT02B':\n",
    "        a = i\n",
    "\n",
    "\n",
    "for k in range(0, len(rows_prod_day)): # index numbers for the days of the month of november\n",
    "    if rows_prod_day[k] != rows_prod_day[-1]: # checking if the cell index is the last in the indexlist rows_prod_day\n",
    "        for m in range(rows_prod_day[k], rows_prod_day[k+1]): # loop for range between each day in november\n",
    "            if FT02_Spcl['C'+str(rows_prod_day[k])].value == '106FT02A': # check if this is a product from A\n",
    "                a = FT02_Spcl['D'+ str(m)].value\n",
    "                print(a)\n",
    "            elif FT02_Spcl['C'+str(rows_prod_day[k])].value == '106FT02B':# check if this is a product from B\n",
    "                b = FT02_Spcl['D'+ str(m)].value    \n",
    "                print(b)\n",
    "\n",
    "    elif rows_prod_day[k] == rows_prod_day[-1]: #for the case where the cell is the last in the indexlist of the rows_prod_day\n",
    "        for s in range(rows_prod_day[k], 333): #fix the 333 later!!!\n",
    "            if type(FT02_Spcl['D'+str(s)].value) == datetime.time:\n",
    "                if FT02_Spcl['C'+str(rows_prod_day[k])].value == '106FT02A': # check if this is a product from A\n",
    "                    c = FT02_Spcl['D'+ str(s)].value\n",
    "                    print(c)\n",
    "                elif FT02_Spcl['C'+str(rows_prod_day[k])].value == '106FT02B':# check if this is a product from B\n",
    "                    d = FT02_Spcl['D'+ str(s)].value    \n",
    "                    print(d)\n",
    "                \n",
    "                #print(datetime.date(2019,11,1)-datetime.timedelta(1)+datetime.timedelta(FT02_Spcl['B'+ str(rows_prod_day[k])].value))\n",
    "                #print(FT02_Spcl['D'+ str(s)].value)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(0, len(rows_prod_day)):\n",
    "    if rows_prod[k]\n",
    "        for m in range(rows_prod_day[k], rows_prod_day[k+1]):\n",
    "            if FT02_Spcl['C'+ str(m)].value =='106FT02A':\n",
    "                print(FT02_Spcl['C'+ str(m)].value)\n",
    "                #a = str(FT02_Spcl['D'+ str(m)].value).split(':')[0]\n",
    "                #b = str(FT02_Spcl['D'+ str(m)].value).split(':')[1]\n",
    "                print(datetime.date(2019,11,1)-datetime.timedelta(1)+datetime.timedelta(FT02_Spcl['B'+ str(rows_prod_day[k])].value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-30\n"
     ]
    }
   ],
   "source": [
    "print(datetime.date(2019,11,1)-datetime.timedelta(1)+datetime.timedelta(FT02_Spcl['B'+ str(rows_prod_day[29])].value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
