{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT THE LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exc1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from dateutil.parser import parse\n",
    "from itertools import compress\n",
    "from collections import OrderedDict\n",
    "from datetime import date\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD THE PI DATA and LABORATORY ANALYSIS RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sheet From Pi\n",
    "#Step1: Load the Data for the month\n",
    "df_Pi_FT01_PU01 = pd.read_excel(r'C:\\Users\\v.t.flores\\Documents\\POLISHING_PUMP_FLOW_DET.xlsx', sheet_name='PI_DATA', index_col=False)\n",
    "#Drop the row[1]\n",
    "df_Pi_FT01_PU01 = df_Pi_FT01_PU01.drop(df_Pi_FT01_PU01.index[0])\n",
    "#Set the index\n",
    "df_Pi_FT01_PU01.set_index('DATETIME', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# DECLARE THE FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fcn dfn\n",
    "#used in the analysis results data. cleans up the sampling time entry\n",
    "def time_cleaner(x):\n",
    "    time_regex = re.compile(r'[0-8a-zA-Z:]', re.IGNORECASE| re.VERBOSE|re.DOTALL)\n",
    "    timeact = time_regex.findall(x)\n",
    "    newtime = ''.join(timeact[0:5])\n",
    "    f_time = check_ending_char(newtime)\n",
    "    f_time1 = check_starting_char(f_time)\n",
    "    t = parse(f_time1)\n",
    "    new_str_time = str(t.hour)+':'+str(t.minute)+':'+str(t.second)\n",
    "    return new_str_time\n",
    "\n",
    "\n",
    "#fcn for formatting the dates from range str\n",
    "def datesplitter_start(x):\n",
    "    return parse(x.split('to')[0])\n",
    "def datesplitter_end(x):\n",
    "    return parse(x.split('to')[1])\n",
    "\n",
    "#------------------\n",
    "\n",
    "def remove_no_good_data_N2Dry_Feed(df): #removes the string value and fills it with the last good value\n",
    "    \n",
    "    df = pd.to_numeric(df, errors='coerce')\n",
    "    for x in range(0, len(df)):\n",
    "        if type(df[x]) == str:\n",
    "            df[x] = df[x-1]\n",
    "    df.fillna(method='ffill', inplace=True)\n",
    "    return df\n",
    "\n",
    "#---------------------------\n",
    "def replace_no_good_data_with_LastGoodValues(df_col):\n",
    "    \n",
    "    df_col = pd.to_numeric(df_col, errors='coerce')\n",
    "    for x in range(0, len(df_col)):\n",
    "        if type(df_col[x]== str):\n",
    "            if det_no_data(df_col[x]) == 'Calculation':\n",
    "                df_col[x] = np.nan\n",
    "\n",
    "    df_col.fillna(method='ffill', inplace= True)\n",
    "    return df_col\n",
    "#--------------------------------------------\n",
    "def replace_no_good_data_with_Zero(df_col):\n",
    "\n",
    "    df_col = pd.to_numeric(df_col, errors='coerce')\n",
    "    for x in range(0, len(df_col)):\n",
    "        if type(df_col[x]) == str:\n",
    "            if det_no_data(df_col[x]) == 'Calculation':\n",
    "                df_col[x] = 0\n",
    "    df_col.fillna(value=0, inplace=True)\n",
    "    \n",
    "    return df_col\n",
    "#--------------------------------------------\n",
    "#--------------------------------------------\n",
    "def replace_neg_data_with_Zero(df_col):\n",
    "    df_col = pd.to_numeric(df_col, errors='coerce')\n",
    "    for x in range(0, len(df_col)):\n",
    "        if df_col[x] < 0:\n",
    "            df_col[x] = 0\n",
    "    return df_col\n",
    "#--------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean the Data Using the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. All param_df_generated 2020-05-21 10:26:47.733917\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Clean data from no good values\n",
    "df_Pi_FT01_PU01['105TK05_LVL'] = replace_no_good_data_with_Zero(df_Pi_FT01_PU01['105TK05_LVL'])\n",
    "df_Pi_FT01_PU01['105TK05_TEMP'] = replace_no_good_data_with_Zero(df_Pi_FT01_PU01['105TK05_TEMP'])\n",
    "df_Pi_FT01_PU01['105PU01A_CUR'] = replace_no_good_data_with_Zero(df_Pi_FT01_PU01['105PU01A_CUR'])\n",
    "df_Pi_FT01_PU01['105PU01A_FLOW'] = replace_no_good_data_with_Zero(df_Pi_FT01_PU01['105PU01A_FLOW'])\n",
    "df_Pi_FT01_PU01['105FT01A_PDI'] = replace_no_good_data_with_Zero(df_Pi_FT01_PU01['105FT01A_PDI'])\n",
    "df_Pi_FT01_PU01['105PU01B_CUR'] = replace_no_good_data_with_Zero(df_Pi_FT01_PU01['105PU01B_CUR'])\n",
    "df_Pi_FT01_PU01['105PU01B_FLOW'] = replace_no_good_data_with_Zero(df_Pi_FT01_PU01['105PU01B_FLOW'])\n",
    "df_Pi_FT01_PU01['105FT01B_PDI'] = replace_no_good_data_with_Zero(df_Pi_FT01_PU01['105FT01B_PDI'])\n",
    "df_Pi_FT01_PU01['105PU01C_CUR'] = replace_no_good_data_with_Zero(df_Pi_FT01_PU01['105PU01C_CUR'])\n",
    "df_Pi_FT01_PU01['105PU01C_FLOW'] = replace_no_good_data_with_Zero(df_Pi_FT01_PU01['105PU01C_FLOW'])\n",
    "df_Pi_FT01_PU01['105FT01C_PDI'] = replace_no_good_data_with_Zero(df_Pi_FT01_PU01['105FT01C_PDI'])\n",
    "df_Pi_FT01_PU01['105PU01D_CUR'] = replace_no_good_data_with_Zero(df_Pi_FT01_PU01['105PU01D_CUR'])\n",
    "df_Pi_FT01_PU01['105PU01D_FLOW'] = replace_no_good_data_with_Zero(df_Pi_FT01_PU01['105PU01D_FLOW'])\n",
    "df_Pi_FT01_PU01['105FT01D_PDI'] = replace_no_good_data_with_Zero(df_Pi_FT01_PU01['105FT01D_PDI'])\n",
    "df_Pi_FT01_PU01['105PU01E_CUR'] = replace_no_good_data_with_Zero(df_Pi_FT01_PU01['105PU01E_CUR'])\n",
    "df_Pi_FT01_PU01['105PU01E_FLOW'] = replace_no_good_data_with_Zero(df_Pi_FT01_PU01['105PU01E_FLOW'])\n",
    "df_Pi_FT01_PU01['105FT01E_PDI'] = replace_no_good_data_with_Zero(df_Pi_FT01_PU01['105FT01E_PDI'])\n",
    "df_Pi_FT01_PU01['105PU01F_CUR'] = replace_no_good_data_with_Zero(df_Pi_FT01_PU01['105PU01F_CUR'])\n",
    "df_Pi_FT01_PU01['105PU01F_FLOW'] = replace_no_good_data_with_Zero(df_Pi_FT01_PU01['105PU01F_FLOW'])\n",
    "df_Pi_FT01_PU01['105FT01F_PDI'] = replace_no_good_data_with_Zero(df_Pi_FT01_PU01['105FT01F_PDI'])\n",
    "df_Pi_FT01_PU01['105PU01G_CUR'] = replace_no_good_data_with_Zero(df_Pi_FT01_PU01['105PU01G_FLOW'])\n",
    "\n",
    "\n",
    "print('Done. All param_df_generated', datetime.datetime.now())\n",
    "#------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Pi_FT01_PU01['105TK05_LVL'] = replace_neg_data_with_Zero(df_Pi_FT01_PU01['105TK05_LVL'])\n",
    "df_Pi_FT01_PU01['105TK05_TEMP'] = replace_neg_data_with_Zero(df_Pi_FT01_PU01['105TK05_TEMP'])\n",
    "df_Pi_FT01_PU01['105PU01A_CUR'] = replace_neg_data_with_Zero(df_Pi_FT01_PU01['105PU01A_CUR'])\n",
    "df_Pi_FT01_PU01['105PU01A_FLOW'] = replace_neg_data_with_Zero(df_Pi_FT01_PU01['105PU01A_FLOW'])\n",
    "df_Pi_FT01_PU01['105FT01A_PDI'] = replace_neg_data_with_Zero(df_Pi_FT01_PU01['105FT01A_PDI'])\n",
    "df_Pi_FT01_PU01['105PU01B_CUR'] = replace_neg_data_with_Zero(df_Pi_FT01_PU01['105PU01B_CUR'])\n",
    "df_Pi_FT01_PU01['105PU01B_FLOW'] = replace_neg_data_with_Zero(df_Pi_FT01_PU01['105PU01B_FLOW'])\n",
    "df_Pi_FT01_PU01['105FT01B_PDI'] = replace_neg_data_with_Zero(df_Pi_FT01_PU01['105FT01B_PDI'])\n",
    "df_Pi_FT01_PU01['105PU01C_CUR'] = replace_neg_data_with_Zero(df_Pi_FT01_PU01['105PU01C_CUR'])\n",
    "df_Pi_FT01_PU01['105PU01C_FLOW'] = replace_neg_data_with_Zero(df_Pi_FT01_PU01['105PU01C_FLOW'])\n",
    "df_Pi_FT01_PU01['105FT01C_PDI'] = replace_neg_data_with_Zero(df_Pi_FT01_PU01['105FT01C_PDI'])\n",
    "df_Pi_FT01_PU01['105PU01D_CUR'] = replace_neg_data_with_Zero(df_Pi_FT01_PU01['105PU01D_CUR'])\n",
    "df_Pi_FT01_PU01['105PU01D_FLOW'] = replace_neg_data_with_Zero(df_Pi_FT01_PU01['105PU01D_FLOW'])\n",
    "df_Pi_FT01_PU01['105FT01D_PDI'] = replace_neg_data_with_Zero(df_Pi_FT01_PU01['105FT01D_PDI'])\n",
    "df_Pi_FT01_PU01['105PU01E_CUR'] = replace_neg_data_with_Zero(df_Pi_FT01_PU01['105PU01E_CUR'])\n",
    "df_Pi_FT01_PU01['105PU01E_FLOW'] = replace_neg_data_with_Zero(df_Pi_FT01_PU01['105PU01E_FLOW'])\n",
    "df_Pi_FT01_PU01['105FT01E_PDI'] = replace_neg_data_with_Zero(df_Pi_FT01_PU01['105FT01E_PDI'])\n",
    "df_Pi_FT01_PU01['105PU01F_CUR'] = replace_neg_data_with_Zero(df_Pi_FT01_PU01['105PU01F_CUR'])\n",
    "df_Pi_FT01_PU01['105PU01F_FLOW'] = replace_neg_data_with_Zero(df_Pi_FT01_PU01['105PU01F_FLOW'])\n",
    "df_Pi_FT01_PU01['105FT01F_PDI'] = replace_neg_data_with_Zero(df_Pi_FT01_PU01['105FT01F_PDI'])\n",
    "df_Pi_FT01_PU01['105PU01G_CUR'] = replace_neg_data_with_Zero(df_Pi_FT01_PU01['105PU01G_FLOW'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter list including 105TK05 temp and 105TK05 lvl\n",
    "DF_105PU01 = df_Pi_FT01_PU01\n",
    "A_lst_DF = DF_105PU01[['105TK05_LVL', '105TK05_TEMP', '105PU01A_CUR', '105FT01A_PDI', '105PU01A_FLOW', 'SEL_A']]\n",
    "B_lst_DF = DF_105PU01[['105TK05_LVL', '105TK05_TEMP', '105PU01B_CUR','105FT01B_PDI', '105PU01B_FLOW', 'SEL_B']]\n",
    "C_lst_DF = DF_105PU01[['105TK05_LVL', '105TK05_TEMP', '105PU01C_CUR','105FT01C_PDI', '105PU01C_FLOW', 'SEL_C']]\n",
    "D_lst_DF = DF_105PU01[['105TK05_LVL', '105TK05_TEMP', '105PU01D_CUR','105FT01D_PDI', '105PU01D_FLOW', 'SEL_D']]\n",
    "E_lst_DF = DF_105PU01[['105TK05_LVL', '105TK05_TEMP', '105PU01E_CUR','105FT01E_PDI', '105PU01E_FLOW', 'SEL_E']]\n",
    "F_lst_DF = DF_105PU01[['105TK05_LVL', '105TK05_TEMP', '105PU01F_CUR','105FT01F_PDI', '105PU01F_FLOW', 'SEL_F']]\n",
    "G_lst_DF = DF_105PU01[['105TK05_LVL', '105TK05_TEMP', '105PU01G_CUR','105FT01F_PDI', '105PU01F_FLOW', 'SEL_F']]\n",
    "\n",
    "A_lst_DF = A_lst_DF[A_lst_DF['SEL_A'] == 'OFF']\n",
    "A_lst_DF = A_lst_DF[0:-1]\n",
    "B_lst_DF = B_lst_DF[B_lst_DF['SEL_B'] == 'OFF']\n",
    "B_lst_DF = B_lst_DF[0:-1]\n",
    "C_lst_DF = C_lst_DF[C_lst_DF['SEL_C'] == 'OFF']\n",
    "C_lst_DF = C_lst_DF[0:-1]\n",
    "D_lst_DF = D_lst_DF[D_lst_DF['SEL_D'] == 'OFF']\n",
    "D_lst_DF = D_lst_DF[0:-1]\n",
    "E_lst_DF = E_lst_DF[E_lst_DF['SEL_E'] == 'OFF']\n",
    "E_lst_DF = E_lst_DF[0:-1]\n",
    "F_lst_DF = F_lst_DF[F_lst_DF['SEL_F'] == 'OFF']\n",
    "F_lst_DF = F_lst_DF[0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>105TK05_LVL</th>\n",
       "      <th>105TK05_TEMP</th>\n",
       "      <th>105PU01A_CUR</th>\n",
       "      <th>105FT01A_PDI</th>\n",
       "      <th>105PU01A_FLOW</th>\n",
       "      <th>SEL_A</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATETIME</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2020-01-01 00:00:00</td>\n",
       "      <td>70.885667</td>\n",
       "      <td>70.282751</td>\n",
       "      <td>66.482693</td>\n",
       "      <td>43.533333</td>\n",
       "      <td>687.993749</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-01 01:00:00</td>\n",
       "      <td>74.845333</td>\n",
       "      <td>69.730750</td>\n",
       "      <td>66.445520</td>\n",
       "      <td>47.816667</td>\n",
       "      <td>690.458751</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-01 02:00:00</td>\n",
       "      <td>73.670333</td>\n",
       "      <td>69.745750</td>\n",
       "      <td>65.698880</td>\n",
       "      <td>50.900000</td>\n",
       "      <td>690.233751</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-01 03:00:00</td>\n",
       "      <td>69.273167</td>\n",
       "      <td>70.667499</td>\n",
       "      <td>63.755893</td>\n",
       "      <td>50.183333</td>\n",
       "      <td>689.806251</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-01 04:00:00</td>\n",
       "      <td>61.485000</td>\n",
       "      <td>70.898750</td>\n",
       "      <td>27.769613</td>\n",
       "      <td>23.433333</td>\n",
       "      <td>688.893750</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-05-21 05:00:00</td>\n",
       "      <td>71.411667</td>\n",
       "      <td>71.162500</td>\n",
       "      <td>63.373506</td>\n",
       "      <td>18.700000</td>\n",
       "      <td>681.692499</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-05-21 06:00:00</td>\n",
       "      <td>72.994333</td>\n",
       "      <td>70.894500</td>\n",
       "      <td>69.511867</td>\n",
       "      <td>27.600000</td>\n",
       "      <td>678.561252</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-05-21 07:00:00</td>\n",
       "      <td>78.503666</td>\n",
       "      <td>70.914500</td>\n",
       "      <td>69.959987</td>\n",
       "      <td>34.050000</td>\n",
       "      <td>680.236250</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-05-21 08:00:00</td>\n",
       "      <td>78.937000</td>\n",
       "      <td>71.090249</td>\n",
       "      <td>68.186093</td>\n",
       "      <td>38.500000</td>\n",
       "      <td>680.003747</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-05-21 09:00:00</td>\n",
       "      <td>84.356834</td>\n",
       "      <td>71.100249</td>\n",
       "      <td>68.099280</td>\n",
       "      <td>46.250000</td>\n",
       "      <td>679.293751</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3215 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     105TK05_LVL  105TK05_TEMP  105PU01A_CUR  105FT01A_PDI  \\\n",
       "DATETIME                                                                     \n",
       "2020-01-01 00:00:00    70.885667     70.282751     66.482693     43.533333   \n",
       "2020-01-01 01:00:00    74.845333     69.730750     66.445520     47.816667   \n",
       "2020-01-01 02:00:00    73.670333     69.745750     65.698880     50.900000   \n",
       "2020-01-01 03:00:00    69.273167     70.667499     63.755893     50.183333   \n",
       "2020-01-01 04:00:00    61.485000     70.898750     27.769613     23.433333   \n",
       "...                          ...           ...           ...           ...   \n",
       "2020-05-21 05:00:00    71.411667     71.162500     63.373506     18.700000   \n",
       "2020-05-21 06:00:00    72.994333     70.894500     69.511867     27.600000   \n",
       "2020-05-21 07:00:00    78.503666     70.914500     69.959987     34.050000   \n",
       "2020-05-21 08:00:00    78.937000     71.090249     68.186093     38.500000   \n",
       "2020-05-21 09:00:00    84.356834     71.100249     68.099280     46.250000   \n",
       "\n",
       "                     105PU01A_FLOW SEL_A  \n",
       "DATETIME                                  \n",
       "2020-01-01 00:00:00     687.993749   OFF  \n",
       "2020-01-01 01:00:00     690.458751   OFF  \n",
       "2020-01-01 02:00:00     690.233751   OFF  \n",
       "2020-01-01 03:00:00     689.806251   OFF  \n",
       "2020-01-01 04:00:00     688.893750   OFF  \n",
       "...                            ...   ...  \n",
       "2020-05-21 05:00:00     681.692499   OFF  \n",
       "2020-05-21 06:00:00     678.561252   OFF  \n",
       "2020-05-21 07:00:00     680.236250   OFF  \n",
       "2020-05-21 08:00:00     680.003747   OFF  \n",
       "2020-05-21 09:00:00     679.293751   OFF  \n",
       "\n",
       "[3215 rows x 6 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_lst_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter list including 105TK05 temp and 105TK05 lvl\n",
    "\n",
    "A_lst = DF_105PU01[['105TK05_LVL', '105TK05_TEMP', '105PU01A_CUR', '105FT01A_PDI', '105PU01A_FLOW']]\n",
    "B_lst = DF_105PU01[['105TK05_LVL', '105TK05_TEMP', '105PU01B_CUR','105FT01B_PDI', '105PU01B_FLOW']]\n",
    "C_lst = DF_105PU01[['105TK05_LVL', '105TK05_TEMP', '105PU01C_CUR','105FT01C_PDI', '105PU01C_FLOW']]\n",
    "D_lst = DF_105PU01[['105TK05_LVL', '105TK05_TEMP', '105PU01D_CUR','105FT01D_PDI', '105PU01D_FLOW']]\n",
    "E_lst = DF_105PU01[['105TK05_LVL', '105TK05_TEMP', '105PU01E_CUR','105FT01E_PDI', '105PU01E_FLOW']]\n",
    "F_lst = DF_105PU01[['105TK05_LVL', '105TK05_TEMP', '105PU01F_CUR','105FT01F_PDI', '105PU01F_FLOW']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARAMETERS: CUR, PDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "A_lst_xset = A_lst_DF[['105PU01A_CUR','105FT01A_PDI']]\n",
    "B_lst_xset = B_lst_DF[['105PU01B_CUR','105FT01B_PDI']]\n",
    "C_lst_xset = C_lst_DF[['105PU01C_CUR','105FT01C_PDI']]\n",
    "D_lst_xset = D_lst_DF[['105PU01D_CUR','105FT01D_PDI']]\n",
    "E_lst_xset = E_lst_DF[['105PU01E_CUR','105FT01E_PDI']]\n",
    "F_lst_xset = F_lst_DF[['105PU01F_CUR','105FT01F_PDI']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IMPORT THE MACHINE LEARNING LIBRARIES\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lm_A = LinearRegression()\n",
    "lm_A.fit(X1_train,y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT THE MACHINE LEARNING LIBRARIES\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X1A = A_lst.dropna()\n",
    "y1A = DF_105PU01['105PU01A_FLOW'].dropna()\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1A, y1A, test_size=0.20, random_state=0)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lm_A = LinearRegression()\n",
    "lm_A.fit(X1_train,y1_train)\n",
    "\n",
    "coeff_df_FLOW_PU01A = pd.DataFrame(zip(lm_A.coef_, X1A.columns), columns=['105PU01A_FLOW','PU01A_Param'])\n",
    "A = lm_A.intercept_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNCTIONS TO GENERATE THE COEFFICIENTS AND INTERCEPTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lm_coefficients(df_column_toPredict, colname_lst, pumpLetter):\n",
    "    X1 = colname_lst.dropna()\n",
    "    y1 = df_column_toPredict.dropna()\n",
    "    X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.20, random_state=0)\n",
    "\n",
    "    lm = LinearRegression()\n",
    "    lm.fit(X1_train,y1_train)\n",
    "\n",
    "    coeff_df_FLOW_PU01 = pd.DataFrame(zip(lm.coef_, X1.columns), columns=['105PU01'+str(pumpLetter)+'_FLOW','PU01'+str(pumpLetter)+'_Param'])\n",
    "    \n",
    "    return coeff_df_FLOW_PU01\n",
    "\n",
    "#--------------------------------------\n",
    "def generate_lm_intercept(df_column_toPredict, colname_lst, pumpLetter):\n",
    "    X1 = colname_lst.dropna()\n",
    "    y1 = df_column_toPredict.dropna()\n",
    "    X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.20, random_state=0)\n",
    "\n",
    "    lm = LinearRegression()\n",
    "    lm.fit(X1_train,y1_train)\n",
    "\n",
    "    coeff_df_FLOW_PU01 = pd.DataFrame(zip(lm.coef_, X1.columns), columns=['105PU01'+str(pumpLetter)+'_FLOW','PU01'+str(pumpLetter)+'_Param'])\n",
    "    intercept_pumpflow = lm.intercept_\n",
    "    \n",
    "    return intercept_pumpflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_a = A_lst_DF['105PU01A_FLOW']\n",
    "col_b = B_lst_DF['105PU01B_FLOW']\n",
    "col_c = C_lst_DF['105PU01C_FLOW']\n",
    "col_d = D_lst_DF['105PU01D_FLOW']\n",
    "col_e = E_lst_DF['105PU01E_FLOW']\n",
    "col_f = F_lst_DF['105PU01F_FLOW']\n",
    "\n",
    "A_coefficients_df = generate_lm_coefficients(col_a, A_lst_xset, 'A')\n",
    "A_intercept = generate_lm_intercept(col_a, A_lst_xset, 'A')\n",
    "\n",
    "B_coefficients_df = generate_lm_coefficients(col_b, B_lst_xset, 'B')\n",
    "B_intercept = generate_lm_intercept(col_b, B_lst_xset, 'B')\n",
    "\n",
    "C_coefficients_df = generate_lm_coefficients(col_c, C_lst_xset, 'C')\n",
    "C_intercept = generate_lm_intercept(col_c, C_lst_xset, 'C')\n",
    "\n",
    "D_coefficients_df = generate_lm_coefficients(col_d, D_lst_xset, 'D')\n",
    "D_intercept = generate_lm_intercept(col_d, D_lst_xset, 'D')\n",
    "\n",
    "E_coefficients_df = generate_lm_coefficients(col_e, E_lst_xset, 'E')\n",
    "E_intercept = generate_lm_intercept(col_e, E_lst_xset, 'E')\n",
    "\n",
    "F_coefficients_df = generate_lm_coefficients(col_f, F_lst_xset, 'F')\n",
    "F_intercept = generate_lm_intercept(col_f, F_lst_xset, 'F')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>105PU01A_FLOW</th>\n",
       "      <th>PU01A_Param</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.005661</td>\n",
       "      <td>105PU01A_CUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.014687</td>\n",
       "      <td>105FT01A_PDI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   105PU01A_FLOW   PU01A_Param\n",
       "0      -0.005661  105PU01A_CUR\n",
       "1       0.014687  105FT01A_PDI"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_coefficients_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "685.807318922585"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter list NOT including 105TK05 temp and 105TK05 lvl\n",
    "\n",
    "A_lst_cur_pdi = DF_105PU01[['105PU01A_CUR','105FT01A_PDI']]\n",
    "B_lst_cur_pdi = DF_105PU01[['105PU01B_CUR','105FT01B_PDI']]\n",
    "C_lst_cur_pdi = DF_105PU01[['105PU01C_CUR','105FT01C_PDI']]\n",
    "D_lst_cur_pdi = DF_105PU01[['105PU01D_CUR','105FT01D_PDI']]\n",
    "E_lst_cur_pdi = DF_105PU01[['105PU01E_CUR','105FT01E_PDI']]\n",
    "F_lst_cur_pdi = DF_105PU01[['105PU01F_CUR','105FT01F_PDI']]\n",
    "\n",
    "\n",
    "A_coefficients_df_cur_pdi = generate_lm_coefficients(col_a, A_lst_cur_pdi, 'A')\n",
    "A_intercept_cur_pdi = generate_lm_intercept(col_a, A_lst_cur_pdi, 'A')\n",
    "\n",
    "B_coefficients_df_cur_pdi = generate_lm_coefficients(col_b, B_lst_cur_pdi, 'B')\n",
    "B_intercept_cur_pdi = generate_lm_intercept(col_b, B_lst_cur_pdi, 'B')\n",
    "\n",
    "C_coefficients_df_cur_pdi = generate_lm_coefficients(col_c, C_lst_cur_pdi, 'C')\n",
    "C_intercept_cur_pdi = generate_lm_intercept(col_c, C_lst_cur_pdi, 'C')\n",
    "\n",
    "D_coefficients_df_cur_pdi = generate_lm_coefficients(col_d, D_lst_cur_pdi, 'D')\n",
    "D_intercept_cur_pdi = generate_lm_intercept(col_d, D_lst_cur_pdi, 'D')\n",
    "\n",
    "E_coefficients_df_cur_pdi = generate_lm_coefficients(col_e, E_lst_cur_pdi, 'E')\n",
    "E_intercept_cur_pdi = generate_lm_intercept(col_e, E_lst_cur_pdi, 'E')\n",
    "\n",
    "F_coefficients_df_cur_pdi = generate_lm_coefficients(col_f, F_lst_cur_pdi, 'F')\n",
    "F_intercept_cur_pdi = generate_lm_intercept(col_f, F_lst_cur_pdi, 'F')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>105PU01B_FLOW</th>\n",
       "      <th>PU01B_Param</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.678319</td>\n",
       "      <td>105PU01B_CUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.381785</td>\n",
       "      <td>105FT01B_PDI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   105PU01B_FLOW   PU01B_Param\n",
       "0       3.678319  105PU01B_CUR\n",
       "1      -0.381785  105FT01B_PDI"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B_coefficients_df_cur_pdi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "A_lst_DF.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "ax = sns.scatterplot(x=\"105PU01A_CUR\", y=\"105PU01A_FLOW\", data=A_lst_DF)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
