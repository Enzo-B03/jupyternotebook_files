{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT THE LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exc1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from dateutil.parser import parse\n",
    "from itertools import compress\n",
    "from collections import OrderedDict\n",
    "from datetime import date\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD THE PI DATA and LABORATORY ANALYSIS RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sheet From Pi\n",
    "#Step1: Load the Data for the month\n",
    "df_JAN2020Pi = pd.read_excel(r'C:\\Users\\v.t.flores\\Documents\\POLISHING_PUMP_FLOW_DET.xlsx', sheet_name='PI_DATA', index_col=False)\n",
    "\n",
    "#Drop the row[1]\n",
    "df_JAN2020Pi = df_JAN2020Pi.drop(df_JAN2020Pi.index[0])\n",
    "\n",
    "#Step2: Parse the DATETIME column\n",
    "#df_JAN2020Pi['DATETIME'] = df_JAN2020Pi['DATETIME'].apply(lambda x: parse(str(x)))\n",
    "\n",
    "df_JAN2020Pi.set_index('DATETIME', inplace=True)\n",
    "df_comb = df_JAN2020Pi\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# DECLARE THE FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fcn dfn\n",
    "#used in the analysis results data. cleans up the sampling time entry\n",
    "def time_cleaner(x):\n",
    "    time_regex = re.compile(r'[0-8a-zA-Z:]', re.IGNORECASE| re.VERBOSE|re.DOTALL)\n",
    "    timeact = time_regex.findall(x)\n",
    "    newtime = ''.join(timeact[0:5])\n",
    "    f_time = check_ending_char(newtime)\n",
    "    f_time1 = check_starting_char(f_time)\n",
    "    t = parse(f_time1)\n",
    "    new_str_time = str(t.hour)+':'+str(t.minute)+':'+str(t.second)\n",
    "    return new_str_time\n",
    "\n",
    "\n",
    "#fcn for formatting the dates from range str\n",
    "def datesplitter_start(x):\n",
    "    return parse(x.split('to')[0])\n",
    "def datesplitter_end(x):\n",
    "    return parse(x.split('to')[1])\n",
    "\n",
    "#------------------\n",
    "\n",
    "def remove_no_good_data_N2Dry_Feed(df): #removes the string value and fills it with the last good value\n",
    "    \n",
    "    df = pd.to_numeric(df, errors='coerce')\n",
    "    for x in range(0, len(df)):\n",
    "        if type(df[x]) == str:\n",
    "            df[x] = df[x-1]\n",
    "    df.fillna(method='ffill', inplace=True)\n",
    "    return df\n",
    "\n",
    "#---------------------------\n",
    "def replace_no_good_data_with_LastGoodValues(df_col):\n",
    "    \n",
    "    df_col = pd.to_numeric(df_col, errors='coerce')\n",
    "    for x in range(0, len(df_col)):\n",
    "        if type(df_col[x]== str):\n",
    "            if det_no_data(df_col[x]) == 'Calculation':\n",
    "                df_col[x] = np.nan\n",
    "\n",
    "    df_col.fillna(method='ffill', inplace= True)\n",
    "    return df_col\n",
    "#--------------------------------------------\n",
    "def replace_no_good_data_with_Zero(df_col):\n",
    "\n",
    "    df_col = pd.to_numeric(df_col, errors='coerce')\n",
    "    for x in range(0, len(df_col)):\n",
    "        if type(df_col[x]) == str:\n",
    "            if det_no_data(df_col[x]) == 'Calculation':\n",
    "                df_col[x] = 0\n",
    "    df_col.fillna(value=0, inplace=True)\n",
    "    \n",
    "    return df_col\n",
    "#--------------------------------------------\n",
    "def replace_neg_data_with_Zero(df_col):\n",
    "\n",
    "    df_col = pd.to_numeric(df_col, errors='coerce')\n",
    "    for x in range(0, len(df_col)):\n",
    "        if df_col[x] < 0:\n",
    "            df_col[x] = 0    \n",
    "    return df_col\n",
    "#--------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_105PU01 = df_comb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean the Data Using the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comb['105TK05_LVL'] = replace_neg_data_with_Zero(df_comb['105TK05_LVL'])\n",
    "df_comb['105TK05_TEMP'] = replace_neg_data_with_Zero(df_comb['105TK05_TEMP'])\n",
    "df_comb['105PU01A_CUR'] = replace_neg_data_with_Zero(df_comb['105PU01A_CUR'])\n",
    "df_comb['105PU01A_FLOW'] = replace_neg_data_with_Zero(df_comb['105PU01A_FLOW'])\n",
    "df_comb['105FT01A_PDI'] = replace_neg_data_with_Zero(df_comb['105FT01A_PDI'])\n",
    "df_comb['105PU01B_CUR'] = replace_neg_data_with_Zero(df_comb['105PU01B_CUR'])\n",
    "df_comb['105PU01B_FLOW'] = replace_neg_data_with_Zero(df_comb['105PU01B_FLOW'])\n",
    "df_comb['105FT01B_PDI'] = replace_neg_data_with_Zero(df_comb['105FT01B_PDI'])\n",
    "df_comb['105PU01C_CUR'] = replace_neg_data_with_Zero(df_comb['105PU01C_CUR'])\n",
    "df_comb['105PU01C_FLOW'] = replace_neg_data_with_Zero(df_comb['105PU01C_FLOW'])\n",
    "df_comb['105FT01C_PDI'] = replace_neg_data_with_Zero(df_comb['105FT01C_PDI'])\n",
    "df_comb['105PU01D_CUR'] = replace_neg_data_with_Zero(df_comb['105PU01D_CUR'])\n",
    "df_comb['105PU01D_FLOW'] = replace_neg_data_with_Zero(df_comb['105PU01D_FLOW'])\n",
    "df_comb['105FT01D_PDI'] = replace_neg_data_with_Zero(df_comb['105FT01D_PDI'])\n",
    "df_comb['105PU01E_CUR'] = replace_neg_data_with_Zero(df_comb['105PU01E_CUR'])\n",
    "df_comb['105PU01E_FLOW'] = replace_neg_data_with_Zero(df_comb['105PU01E_FLOW'])\n",
    "df_comb['105FT01E_PDI'] = replace_neg_data_with_Zero(df_comb['105FT01E_PDI'])\n",
    "df_comb['105PU01F_CUR'] = replace_neg_data_with_Zero(df_comb['105PU01F_CUR'])\n",
    "df_comb['105PU01F_FLOW'] = replace_neg_data_with_Zero(df_comb['105PU01F_FLOW'])\n",
    "df_comb['105FT01F_PDI'] = replace_neg_data_with_Zero(df_comb['105FT01F_PDI'])\n",
    "df_comb['105PU01G_CUR'] = replace_neg_data_with_Zero(df_comb['105PU01G_FLOW'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter list including 105TK05 temp and 105TK05 lvl\n",
    "A_lst_DF = DF_105PU01[['105TK05_LVL', '105TK05_TEMP', '105PU01A_CUR', '105FT01A_PDI', '105PU01A_FLOW', 'SEL_A']]\n",
    "B_lst_DF = DF_105PU01[['105TK05_LVL', '105TK05_TEMP', '105PU01B_CUR','105FT01B_PDI', '105PU01B_FLOW', 'SEL_B']]\n",
    "C_lst_DF = DF_105PU01[['105TK05_LVL', '105TK05_TEMP', '105PU01C_CUR','105FT01C_PDI', '105PU01C_FLOW', 'SEL_C']]\n",
    "D_lst_DF = DF_105PU01[['105TK05_LVL', '105TK05_TEMP', '105PU01D_CUR','105FT01D_PDI', '105PU01D_FLOW', 'SEL_D']]\n",
    "E_lst_DF = DF_105PU01[['105TK05_LVL', '105TK05_TEMP', '105PU01E_CUR','105FT01E_PDI', '105PU01E_FLOW', 'SEL_E']]\n",
    "F_lst_DF = DF_105PU01[['105TK05_LVL', '105TK05_TEMP', '105PU01F_CUR','105FT01F_PDI', '105PU01F_FLOW', 'SEL_F']]\n",
    "G_lst_DF = DF_105PU01[['105TK05_LVL', '105TK05_TEMP', '105PU01G_CUR','105FT01F_PDI', '105PU01F_FLOW', 'SEL_F']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "A_lst_DF.dropna(inplace = True)\n",
    "B_lst_DF.dropna(inplace = True)\n",
    "C_lst_DF.dropna(inplace = True)\n",
    "D_lst_DF.dropna(inplace = True)\n",
    "E_lst_DF.dropna(inplace = True)\n",
    "F_lst_DF.dropna(inplace = True)\n",
    "G_lst_DF.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_lst_DF = A_lst_DF[A_lst_DF['SEL_A'] != 'ON']\n",
    "B_lst_DF = B_lst_DF[B_lst_DF['SEL_B'] != 'ON']\n",
    "C_lst_DF = C_lst_DF[C_lst_DF['SEL_C'] != 'ON']\n",
    "D_lst_DF = D_lst_DF[D_lst_DF['SEL_D'] != 'ON']\n",
    "E_lst_DF = E_lst_DF[E_lst_DF['SEL_E'] != 'ON']\n",
    "F_lst_DF = F_lst_DF[F_lst_DF['SEL_F'] != 'ON']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARAMETERS: CUR, PDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "A_lst_xset = A_lst_DF[['105PU01A_CUR','105FT01A_PDI']]\n",
    "B_lst_xset = B_lst_DF[['105PU01B_CUR','105FT01B_PDI']]\n",
    "C_lst_xset = C_lst_DF[['105PU01C_CUR','105FT01C_PDI']]\n",
    "D_lst_xset = D_lst_DF[['105PU01D_CUR','105FT01D_PDI']]\n",
    "E_lst_xset = E_lst_DF[['105PU01E_CUR','105FT01E_PDI']]\n",
    "F_lst_xset = F_lst_DF[['105PU01F_CUR','105FT01F_PDI']]\n",
    "\n",
    "col_a = A_lst_DF['105PU01A_FLOW']\n",
    "col_b = B_lst_DF['105PU01B_FLOW']\n",
    "col_c = C_lst_DF['105PU01C_FLOW']\n",
    "col_d = D_lst_DF['105PU01D_FLOW']\n",
    "col_e = E_lst_DF['105PU01E_FLOW']\n",
    "col_f = F_lst_DF['105PU01F_FLOW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>105PU01A_CUR</th>\n",
       "      <th>105FT01A_PDI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATETIME</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2020-01-01 00:00:00</td>\n",
       "      <td>66.482693</td>\n",
       "      <td>43.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-01 01:00:00</td>\n",
       "      <td>66.445520</td>\n",
       "      <td>47.816667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-01 02:00:00</td>\n",
       "      <td>65.698880</td>\n",
       "      <td>50.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-01 03:00:00</td>\n",
       "      <td>63.755893</td>\n",
       "      <td>50.183333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-01 04:00:00</td>\n",
       "      <td>27.769613</td>\n",
       "      <td>23.433333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-02-07 19:00:00</td>\n",
       "      <td>72.225293</td>\n",
       "      <td>9.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-02-07 20:00:00</td>\n",
       "      <td>74.062653</td>\n",
       "      <td>15.383333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-02-07 21:00:00</td>\n",
       "      <td>74.366613</td>\n",
       "      <td>20.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-02-07 22:00:00</td>\n",
       "      <td>74.402654</td>\n",
       "      <td>27.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-02-07 23:00:00</td>\n",
       "      <td>73.091160</td>\n",
       "      <td>32.816667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>854 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     105PU01A_CUR  105FT01A_PDI\n",
       "DATETIME                                       \n",
       "2020-01-01 00:00:00     66.482693     43.533333\n",
       "2020-01-01 01:00:00     66.445520     47.816667\n",
       "2020-01-01 02:00:00     65.698880     50.900000\n",
       "2020-01-01 03:00:00     63.755893     50.183333\n",
       "2020-01-01 04:00:00     27.769613     23.433333\n",
       "...                           ...           ...\n",
       "2020-02-07 19:00:00     72.225293      9.900000\n",
       "2020-02-07 20:00:00     74.062653     15.383333\n",
       "2020-02-07 21:00:00     74.366613     20.550000\n",
       "2020-02-07 22:00:00     74.402654     27.416667\n",
       "2020-02-07 23:00:00     73.091160     32.816667\n",
       "\n",
       "[854 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_lst_xset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT THE MACHINE LEARNING LIBRARIES\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNCTIONS TO GENERATE THE COEFFICIENTS AND INTERCEPTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lm_coefficients(df_column_toPredict, colname_lst, pumpLetter):\n",
    "    X1 = colname_lst.dropna()\n",
    "    y1 = df_column_toPredict.dropna()\n",
    "    X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.20, random_state=0)\n",
    "\n",
    "    lm = LinearRegression()\n",
    "    lm.fit(X1_train,y1_train)\n",
    "\n",
    "    coeff_df_FLOW_PU01 = pd.DataFrame(zip(lm.coef_, X1.columns), columns=['105PU01'+str(pumpLetter)+'_FLOW','PU01'+str(pumpLetter)+'_Param'])\n",
    "    \n",
    "    return coeff_df_FLOW_PU01\n",
    "\n",
    "#--------------------------------------\n",
    "def generate_lm_intercept(df_column_toPredict, colname_lst, pumpLetter):\n",
    "    X1 = colname_lst.dropna()\n",
    "    y1 = df_column_toPredict.dropna()\n",
    "    X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.20, random_state=0)\n",
    "\n",
    "    lm = LinearRegression()\n",
    "    lm.fit(X1_train,y1_train)\n",
    "\n",
    "    coeff_df_FLOW_PU01 = pd.DataFrame(zip(lm.coef_, X1.columns), columns=['105PU01'+str(pumpLetter)+'_FLOW','PU01'+str(pumpLetter)+'_Param'])\n",
    "    intercept_pumpflow = lm.intercept_\n",
    "    \n",
    "    return intercept_pumpflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_coefficients_df = generate_lm_coefficients(col_a, A_lst_xset, 'A')\n",
    "A_intercept = generate_lm_intercept(col_a, A_lst_xset, 'A')\n",
    "\n",
    "B_coefficients_df = generate_lm_coefficients(col_b, B_lst_xset, 'B')\n",
    "B_intercept = generate_lm_intercept(col_b, B_lst_xset, 'B')\n",
    "\n",
    "C_coefficients_df = generate_lm_coefficients(col_c, C_lst_xset, 'C')\n",
    "C_intercept = generate_lm_intercept(col_c, C_lst_xset, 'C')\n",
    "\n",
    "D_coefficients_df = generate_lm_coefficients(col_d, D_lst_xset, 'D')\n",
    "D_intercept = generate_lm_intercept(col_d, D_lst_xset, 'D')\n",
    "\n",
    "E_coefficients_df = generate_lm_coefficients(col_e, E_lst_xset, 'E')\n",
    "E_intercept = generate_lm_intercept(col_e, E_lst_xset, 'E')\n",
    "\n",
    "F_coefficients_df = generate_lm_coefficients(col_f, F_lst_xset, 'F')\n",
    "F_intercept = generate_lm_intercept(col_f, F_lst_xset, 'F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>105PU01C_FLOW</th>\n",
       "      <th>PU01C_Param</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.801696</td>\n",
       "      <td>105PU01C_CUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.580304</td>\n",
       "      <td>105FT01C_PDI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   105PU01C_FLOW   PU01C_Param\n",
       "0       3.801696  105PU01C_CUR\n",
       "1      -0.580304  105FT01C_PDI"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_coefficients_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>105PU01B_FLOW</th>\n",
       "      <th>PU01B_Param</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.922221</td>\n",
       "      <td>105PU01B_CUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.550560</td>\n",
       "      <td>105FT01B_PDI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   105PU01B_FLOW   PU01B_Param\n",
       "0       3.922221  105PU01B_CUR\n",
       "1      -0.550560  105FT01B_PDI"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B_coefficients_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataFrame' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-285e3c161106>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mA_coefficients_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'\\\\THGOBNA002\\thpal\\05 Production\\150 DCS\\00 DCS Monitoring & Records\\00 Active Files\\2020\\Polishing_Filter_Flow_Pred\\A_coeff.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mB_coefficients_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'\\\\THGOBNA002\\thpal\\05 Production\\150 DCS\\00 DCS Monitoring & Records\\00 Active Files\\2020\\Polishing_Filter_Flow_Pred\\B_coeff.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'DataFrame' object is not callable"
     ]
    }
   ],
   "source": [
    "A_coefficients_df.to_excel(r'\\\\THGOBNA002\\thpal\\05 Production\\150 DCS\\00 DCS Monitoring & Records\\00 Active Files\\2020\\Polishing_Filter_Flow_Pred\\A_coeff.xlsx')\n",
    "B_coefficients_df.to_ex(r'\\\\THGOBNA002\\thpal\\05 Production\\150 DCS\\00 DCS Monitoring & Records\\00 Active Files\\2020\\Polishing_Filter_Flow_Pred\\A_coeff.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_coefficients_df.to_excel(r'\\\\THGOBNA002\\thpal\\05 Production\\150 DCS\\00 DCS Monitoring & Records\\00 Active Files\\2020\\Polishing_Filter_Flow_Pred\\A_coeff.xlsx')\n",
    "\n",
    "B_coefficients_df.to_excel(r'\\\\THGOBNA002\\thpal\\05 Production\\150 DCS\\00 DCS Monitoring & Records\\00 Active Files\\2020\\Polishing_Filter_Flow_Pred\\B_coeff.xlsx')\n",
    "\n",
    "C_coefficients_df.to_excel(r'\\\\THGOBNA002\\thpal\\05 Production\\150 DCS\\00 DCS Monitoring & Records\\00 Active Files\\2020\\Polishing_Filter_Flow_Pred\\C_coeff.xlsx')\n",
    "\n",
    "D_coefficients_df.to_excel(r'\\\\THGOBNA002\\thpal\\05 Production\\150 DCS\\00 DCS Monitoring & Records\\00 Active Files\\2020\\Polishing_Filter_Flow_Pred\\D_coeff.xlsx')\n",
    "\n",
    "E_coefficients_df.to_excel(r'\\\\THGOBNA002\\thpal\\05 Production\\150 DCS\\00 DCS Monitoring & Records\\00 Active Files\\2020\\Polishing_Filter_Flow_Pred\\E_coeff.xlsx')\n",
    "\n",
    "F_coefficients_df.to_excel(r'\\\\THGOBNA002\\thpal\\05 Production\\150 DCS\\00 DCS Monitoring & Records\\00 Active Files\\2020\\Polishing_Filter_Flow_Pred\\F_coeff.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.float64' object has no attribute 'to_excel'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-e0a3a4dcee11>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mA_intercept\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'\\\\THGOBNA002\\thpal\\05 Production\\150 DCS\\00 DCS Monitoring & Records\\00 Active Files\\2020\\Polishing_Filter_Flow_Pred\\A_intercept.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mB_intercept\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'\\\\THGOBNA002\\thpal\\05 Production\\150 DCS\\00 DCS Monitoring & Records\\00 Active Files\\2020\\Polishing_Filter_Flow_Pred\\B_intercept.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mC_intercept\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'\\\\THGOBNA002\\thpal\\05 Production\\150 DCS\\00 DCS Monitoring & Records\\00 Active Files\\2020\\Polishing_Filter_Flow_Pred\\C_intercept.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mD_intercept\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'\\\\THGOBNA002\\thpal\\05 Production\\150 DCS\\00 DCS Monitoring & Records\\00 Active Files\\2020\\Polishing_Filter_Flow_Pred\\D_intercept.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mE_intercept\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'\\\\THGOBNA002\\thpal\\05 Production\\150 DCS\\00 DCS Monitoring & Records\\00 Active Files\\2020\\Polishing_Filter_Flow_Pred\\E_intercept.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.float64' object has no attribute 'to_excel'"
     ]
    }
   ],
   "source": [
    "A_intercept.to_excel(r'\\\\THGOBNA002\\thpal\\05 Production\\150 DCS\\00 DCS Monitoring & Records\\00 Active Files\\2020\\Polishing_Filter_Flow_Pred\\A_intercept.xlsx')\n",
    "B_intercept.to_excel(r'\\\\THGOBNA002\\thpal\\05 Production\\150 DCS\\00 DCS Monitoring & Records\\00 Active Files\\2020\\Polishing_Filter_Flow_Pred\\B_intercept.xlsx')\n",
    "C_intercept.to_excel(r'\\\\THGOBNA002\\thpal\\05 Production\\150 DCS\\00 DCS Monitoring & Records\\00 Active Files\\2020\\Polishing_Filter_Flow_Pred\\C_intercept.xlsx')\n",
    "D_intercept.to_excel(r'\\\\THGOBNA002\\thpal\\05 Production\\150 DCS\\00 DCS Monitoring & Records\\00 Active Files\\2020\\Polishing_Filter_Flow_Pred\\D_intercept.xlsx')\n",
    "E_intercept.to_excel(r'\\\\THGOBNA002\\thpal\\05 Production\\150 DCS\\00 DCS Monitoring & Records\\00 Active Files\\2020\\Polishing_Filter_Flow_Pred\\E_intercept.xlsx')\n",
    "F_intercept.to_excel(r'\\\\THGOBNA002\\thpal\\05 Production\\150 DCS\\00 DCS Monitoring & Records\\00 Active Files\\2020\\Polishing_Filter_Flow_Pred\\F_intercept.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "685.8273879919026 -9.212248576009785 -5.421782466672454 -10.387774950324456 -6.4146067805576195 -10.276708430233413\n"
     ]
    }
   ],
   "source": [
    "print(A_intercept,\n",
    "B_intercept,\n",
    "C_intercept,\n",
    "D_intercept,\n",
    "E_intercept,\n",
    "F_intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
