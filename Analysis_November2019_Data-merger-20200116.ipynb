{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exc1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from dateutil.parser import parse\n",
    "from itertools import compress\n",
    "from collections import OrderedDict\n",
    "from datetime import date\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:62: RuntimeWarning: invalid value encountered in sign\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:63: RuntimeWarning: invalid value encountered in sign\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:63: RuntimeWarning: invalid value encountered in greater\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:64: RuntimeWarning: invalid value encountered in sign\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:64: RuntimeWarning: invalid value encountered in less\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:71: RuntimeWarning: invalid value encountered in sign\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:72: RuntimeWarning: invalid value encountered in sign\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:72: RuntimeWarning: invalid value encountered in greater\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:73: RuntimeWarning: invalid value encountered in sign\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:73: RuntimeWarning: invalid value encountered in less\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done\n",
      "Done 2020-01-16 17:06:01.026741\n"
     ]
    }
   ],
   "source": [
    "#exc2\n",
    "#Sheet nov2019_Mg_PS\n",
    "\n",
    "#Step1: Load the Data for the month\n",
    "df_nov2019_Mg_PS =  pd.read_excel(r'C:\\Users\\v.t.flores\\Documents\\Analysis_November2019_MSdataCLEAN.xlsx', sheet_name='NOV19Datetime_Mg_PS', index_col=False)\n",
    "\n",
    "#Step2: Parse the DATETIME column\n",
    "df_nov2019_Mg_PS['DATETIME'] = df_nov2019_Mg_PS['DATETIME'].apply(lambda x: parse(str(x)))\n",
    "\n",
    "#Step3: Set the DATETIME column as the index\n",
    "df_nov2019_Mg_PS.set_index('DATETIME', inplace=True)\n",
    "\n",
    "#exc3\n",
    "#Sheet 106FT02A_spcl\n",
    "\n",
    "#Step1: Load the Data for the month\n",
    "df_106FT02A_spcl =  pd.read_excel(r'C:\\Users\\v.t.flores\\Documents\\Analysis_November2019_MSdataCLEAN.xlsx', sheet_name='106FT02A_spcl', index_col=False)\n",
    "\n",
    "#Step2: Parse the DATETIME column\n",
    "df_106FT02A_spcl['DATETIME'] = df_106FT02A_spcl['DATETIME'].apply(lambda x: parse(x))\n",
    "\n",
    "#Step3: Set the DATETIME column as the index\n",
    "df_106FT02A_spcl.set_index('DATETIME', inplace=True)\n",
    "\n",
    "#exc4\n",
    "#Sheet 106FT02B_spcl\n",
    "\n",
    "#Step1: Load the Data for the month\n",
    "df_106FT02B_spcl = pd.read_excel(r'C:\\Users\\v.t.flores\\Documents\\Analysis_November2019_MSdataCLEAN.xlsx', sheet_name='106FT02B_spcl', index_col=False)\n",
    "\n",
    "#Step2: Parse the DATETIME column\n",
    "df_106FT02B_spcl['DATETIME'] = df_106FT02B_spcl['DATETIME'].apply(lambda x: parse(x))\n",
    "\n",
    "#Step3: Set the DATETIME column as the index\n",
    "df_106FT02B_spcl.set_index('DATETIME', inplace=True)\n",
    "\n",
    "#exc5\n",
    "#Sheet From Pi\n",
    "#Step1: Load the Data for the month\n",
    "df_nov2019Pi = pd.read_excel(r'C:\\Users\\v.t.flores\\Documents\\Analysis_November2019_MSdataCLEAN.xlsx', sheet_name='From Pi', index_col=False)\n",
    "\n",
    "#Drop the row[1]\n",
    "df_nov2019Pi = df_nov2019Pi.drop(df_nov2019Pi.index[0])\n",
    "\n",
    "#Step2: Parse the DATETIME column\n",
    "df_nov2019Pi['DATETIME'] = df_nov2019Pi['DATETIME'].apply(lambda x: parse(str(x)))\n",
    "\n",
    "df_nov2019Pi.set_index('DATETIME', inplace=True)\n",
    "\n",
    "#exc6\n",
    "#This code merges the formatted data from the three sheets to on single dataframe named df_comb\n",
    "\n",
    "df_com_Pi_FT02A = df_nov2019Pi.join(df_106FT02A_spcl, how='outer')\n",
    "df_com_Mg_FT02B = df_nov2019_Mg_PS.join(df_106FT02B_spcl, how='outer')\n",
    "df_comb = df_com_Pi_FT02A.join(df_com_Mg_FT02B, how='outer')\n",
    "\n",
    "\n",
    "#exc7\n",
    "#finding peaks FT for A_filtration time\n",
    "\n",
    "df_comb['A_t_FEED'] = pd.to_numeric(df_comb['A_t_FEED'], errors='coerce')\n",
    "a = np.diff(np.sign(np.diff(df_comb['A_t_FEED']))).nonzero()[0] + 1               # local min & max\n",
    "b = (np.diff(np.sign(np.diff(df_comb['A_t_FEED']))) > 0).nonzero()[0] + 1         # local min\n",
    "c = (np.diff(np.sign(np.diff(df_comb['A_t_FEED']))) < 0).nonzero()[0] + 1         # local max\n",
    "# +1 due to the fact that diff reduces the original index number\n",
    "\n",
    "\n",
    "#finding peaks FT for A_N2 Dry time\n",
    "\n",
    "df_comb['A_t_DRY'] = pd.to_numeric(df_comb['A_t_DRY'], errors='coerce')\n",
    "d = np.diff(np.sign(np.diff(df_comb['A_t_DRY']))).nonzero()[0] + 1               # local min & max\n",
    "e = (np.diff(np.sign(np.diff(df_comb['A_t_DRY']))) > 0).nonzero()[0] + 1         # local min\n",
    "f = (np.diff(np.sign(np.diff(df_comb['A_t_DRY']))) < 0).nonzero()[0] + 1         # local max\n",
    "# +1 due to the fact that diff reduces the original index number\n",
    "\n",
    "#Use b as the starting index and f as the ending index for one full cylcle of Filtration to N2 Drying\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#This code here collects the index range for the each cycle\n",
    "try:\n",
    "    ft_cyc_lim = {}\n",
    "\n",
    "    for i in range(0, len(b)):\n",
    "        for j in range(0, len(f)):\n",
    "            if f[j] > b[i] and f[j] < b[i+1]:\n",
    "                if f[j+1]<b[i+1]:\n",
    "                    cyc_start = b[i]\n",
    "                    cyc_end = f[j+1]\n",
    "                    ft_cyc_lim.setdefault(cyc_start,cyc_end)\n",
    "\n",
    "except IndexError:\n",
    "    print('\\nDone')\n",
    "#------------------------------------------------------------     \n",
    "\n",
    "print('Done', str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 2020-01-16 17:06:36.631162\n"
     ]
    }
   ],
   "source": [
    "#code for getting the CWP for CakeWash1 and CakeWash2\n",
    "##Working as of 1/15/2020\n",
    "A_CWP_1new = list()\n",
    "A_CWP_1new[:] = []\n",
    "\n",
    "A_CWP_1_indexList = list()\n",
    "A_CWP_1_indexList[:] = []\n",
    "\n",
    "A_CWP_2new = list()\n",
    "A_CWP_2new[:] = []\n",
    "\n",
    "A_CWP_2_indexList = list()\n",
    "A_CWP_2_indexList[:] = []\n",
    "\n",
    "A_CWP_1_inner = list()\n",
    "A_CWP_1_inner[:] = []\n",
    "\n",
    "A_CWP_2_inner = list()\n",
    "A_CWP_2_inner[:] = []\n",
    "\n",
    "A_Pair_CWP_1_List = list()\n",
    "A_Pair_CWP_2_List = list()\n",
    "\n",
    "try:\n",
    "    for i in range(0, len(keyslist)):\n",
    "        A_CWPList_i = list()\n",
    "        A_CWPList_i[:] = []\n",
    "        d = list()\n",
    "        d[:] = []\n",
    "        \n",
    "        A_CWPList_i = list(np.arange(keyslist[i],ft_cyc_lim[keyslist[i]]))\n",
    "        d = (np.diff(np.sign(np.diff(df_comb['106FT02A_CWP'].iloc[keyslist[i]:ft_cyc_lim[keyslist[i]]])))< 0).nonzero()[0] + 1\n",
    "        A_CWP_for_sort = list()\n",
    "        A_CWP_for_sort[:] = [] \n",
    "        \n",
    "        A_CWP_1_indexList.append((str(df_comb.index[keyslist[i]])+\" to \"+str(df_comb.index[ft_cyc_lim[keyslist[i]]])))\n",
    "        A_CWP_2_indexList.append((str(df_comb.index[keyslist[i]])+\" to \"+str(df_comb.index[ft_cyc_lim[keyslist[i]]])))\n",
    "        \n",
    "        for i in range(0, len(d)):\n",
    "            CWP_val_shortlist = df_comb['106FT02A_CWP'].iloc[A_CWPList_i[d[i]]]\n",
    "            A_CWP_for_sort.append(CWP_val_shortlist)\n",
    "                    \n",
    "        A_CWP_1 = sorted(A_CWP_for_sort)[len(A_CWP_for_sort)-1]\n",
    "        A_CWP_1_inner.append(A_CWP_1)\n",
    "        \n",
    "        A_CWP_2 = sorted(A_CWP_for_sort)[len(A_CWP_for_sort)-2]\n",
    "        A_CWP_2_inner.append(A_CWP_2)\n",
    "\n",
    "    A_Pair_CWP_1_List = list(zip(A_CWP_1_inner, A_CWP_1_indexList[0:]))\n",
    "    A_Pair_CWP_2_List = list(zip(A_CWP_2_inner, A_CWP_2_indexList[0:]))\n",
    "            \n",
    "    \n",
    "except IndexError:\n",
    "    print('IndexError')\n",
    "\n",
    "df_A_Pair_CWP_1 = pd.DataFrame(A_Pair_CWP_1_List)\n",
    "df_A_Pair_CWP_1.columns = ['A_CWP_1', 'DATETIME']\n",
    "df_A_Pair_CWP_1.set_index('DATETIME', inplace=True)\n",
    "    \n",
    "df_A_Pair_CWP_2 = pd.DataFrame(A_Pair_CWP_2_List)\n",
    "df_A_Pair_CWP_2.columns = ['A_CWP_2', 'DATETIME']\n",
    "df_A_Pair_CWP_2.set_index('DATETIME', inplace=True)\n",
    "    \n",
    "    \n",
    "print('Done', str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 2020-01-16 17:06:39.764742\n"
     ]
    }
   ],
   "source": [
    "# This code will use the index range (or limits) to create a list of values: feedtime range, cake wash time range,\n",
    "# then selects the max value as the parameter value for that range\n",
    "\n",
    "#FILTRATION TIME\n",
    "keyslist = list(ft_cyc_lim.keys()) #creates a list of the ft_cyc_lim keys so that we can iterate later\n",
    "#For loop Dictionary names \n",
    "A_Filt_MaxList= list()\n",
    "A_Filt_MaxList[:] = []\n",
    "A_feedt_Val_List = list()\n",
    "A_feedt_Val_List[:] = []\n",
    "A_feedt_index_List = list()\n",
    "A_feedt_index_List[:] = []\n",
    "A_Pair_Filt_List = list()\n",
    "A_Pair_Filt_List[:] = []\n",
    "try:         \n",
    "    for i in range(0, len(keyslist)):\n",
    "        A_feedt_Val_List = list()\n",
    "        A_feedt_Val_List[:] = []\n",
    "        for j in range(keyslist[i], ft_cyc_lim[keyslist[i]]):\n",
    "            A_feedt = df_comb['A_t_FEED'][j]\n",
    "            A_feedt_Val_List.append(A_feedt)\n",
    "        A_Filt_MaxList.append(sorted(A_feedt_Val_List)[-1])\n",
    "        A_feedt_index_List.append((str(df_comb.index[keyslist[i]])+\" to \"+str(df_comb.index[ft_cyc_lim[keyslist[i]]])))  \n",
    "    A_Pair_Filt_List = list(zip(A_Filt_MaxList, A_feedt_index_List[0:]))      \n",
    "except:\n",
    "    pass\n",
    "\n",
    "df_A_Pair_Filt_t = pd.DataFrame(A_Pair_Filt_List)\n",
    "df_A_Pair_Filt_t.columns = ['A_FILT_T', 'DATETIME']\n",
    "df_A_Pair_Filt_t.set_index('DATETIME', inplace=True)\n",
    "\n",
    "print('Done', str(datetime.datetime.now()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 2020-01-16 17:06:42.817765\n"
     ]
    }
   ],
   "source": [
    "#MANIFOLD PRESSURE\n",
    "keyslist = list(ft_cyc_lim.keys()) #creates a list of the ft_cyc_lim keys so that we can iterate later\n",
    "#For loop Dictionary names \n",
    "A_MANFP_MaxList = list()\n",
    "A_MANFP_MaxList[:] = []\n",
    "A_Pair_MANFP_List =list() \n",
    "A_Pair_MANFP_List[:] = []\n",
    "A_MANFP_index_List=list()      \n",
    "A_MANFP_index_List[:] = []\n",
    "try:         \n",
    "    for i in range(0, len(keyslist)):\n",
    "        A_MANFP_val_List=list() \n",
    "        A_MANFP_val_List[:] = []\n",
    "        for j in range(keyslist[i], ft_cyc_lim[keyslist[i]]):               \n",
    "            #Gets A manifold pressure of the cycle\n",
    "            A_MANFP = df_comb['106FT02A_MANFP'][j]         \n",
    "            A_MANFP_val_List.append(A_MANFP)\n",
    "        A_MANFP_MaxList.append(sorted(A_MANFP_val_List)[-1])\n",
    "        A_MANFP_index_List.append((str(df_comb.index[keyslist[i]])+\" to \"+str(df_comb.index[ft_cyc_lim[keyslist[i]]])))\n",
    "    A_Pair_MANFP_List = list(zip(A_MANFP_MaxList, A_MANFP_index_List[0:]))      \n",
    "                        \n",
    "except:\n",
    "    pass\n",
    "\n",
    "df_A_Pair_MANF_P = pd.DataFrame(A_Pair_MANFP_List)\n",
    "df_A_Pair_MANF_P.columns = ['A_MANF_P', 'DATETIME']\n",
    "df_A_Pair_MANF_P.set_index('DATETIME', inplace=True)\n",
    "\n",
    "print('Done', str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 2020-01-16 17:06:44.683657\n"
     ]
    }
   ],
   "source": [
    "#CWSH1\n",
    "##wORKING as of 2020.01.15\n",
    "\n",
    "keyslist = list(ft_cyc_lim.keys()) #creates a list of the ft_cyc_lim keys so that we can iterate later\n",
    "\n",
    "A_t_CWSH1_Maxlist = list()\n",
    "A_t_CWSH1_Maxlist[:] = []\n",
    "\n",
    "A_CWSH1_index_List=list()      \n",
    "A_CWSH1_index_List[:] = []\n",
    "\n",
    "A_Pair_CWSH1_List =list() \n",
    "A_Pair_CWSH1_List[:] = []\n",
    "try:         \n",
    "    for i in range(0, len(keyslist)):\n",
    "        A_t_CWSH1_val_List=list() \n",
    "        A_t_CWSH1_val_List[:] = []\n",
    "        for j in range(keyslist[i], ft_cyc_lim[keyslist[i]]):               \n",
    "            A_t_CWSH1 = df_comb['A_t_CWSH1'][j]         \n",
    "            A_t_CWSH1_val_List.append(A_t_CWSH1)\n",
    "        A_t_CWSH1_Maxlist.append(sorted(A_t_CWSH1_val_List)[-1])\n",
    "        A_CWSH1_index_List.append((str(df_comb.index[keyslist[i]])+\" to \"+str(df_comb.index[ft_cyc_lim[keyslist[i]]])))\n",
    "    A_Pair_CWSH1_List = list(zip(A_t_CWSH1_Maxlist, A_CWSH1_index_List[0:]))      \n",
    "                        \n",
    "except:\n",
    "    pass\n",
    "df_A_Pair_CWSH1 = pd.DataFrame(A_Pair_CWSH1_List)\n",
    "df_A_Pair_CWSH1.columns = ['A_CWSH1', 'DATETIME']\n",
    "df_A_Pair_CWSH1.set_index('DATETIME', inplace=True)\n",
    "\n",
    "print('Done', str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 2020-01-16 17:06:47.252318\n"
     ]
    }
   ],
   "source": [
    "#CWSH2\n",
    "##wORKING as of 2020.01.15\n",
    "keyslist = list(ft_cyc_lim.keys()) #creates a list of the ft_cyc_lim keys so that we can iterate later\n",
    "\n",
    "A_t_CWSH2_Maxlist = list()\n",
    "A_t_CWSH2_Maxlist[:] = []\n",
    "\n",
    "A_CWSH2_index_List=list()      \n",
    "A_CWSH2_index_List[:] = []\n",
    "\n",
    "A_Pair_CWSH2_List =list() \n",
    "A_Pair_CWSH2_List[:] = []\n",
    "try:         \n",
    "    for i in range(0, len(keyslist)):\n",
    "        A_t_CWSH2_val_List=list() \n",
    "        A_t_CWSH2_val_List[:] = []\n",
    "        for j in range(keyslist[i], ft_cyc_lim[keyslist[i]]):               \n",
    "            A_t_CWSH2 = df_comb['A_t_CWSH2'][j]         \n",
    "            A_t_CWSH2_val_List.append(A_t_CWSH2)\n",
    "        A_t_CWSH2_Maxlist.append(sorted(A_t_CWSH2_val_List)[-1])\n",
    "        A_CWSH2_index_List.append((str(df_comb.index[keyslist[i]])+\" to \"+str(df_comb.index[ft_cyc_lim[keyslist[i]]])))\n",
    "    A_Pair_CWSH2_List = list(zip(A_t_CWSH2_Maxlist, A_CWSH2_index_List[0:]))      \n",
    "                        \n",
    "except:\n",
    "    pass\n",
    "  \n",
    "df_A_Pair_CWSH2 = pd.DataFrame(A_Pair_CWSH2_List)\n",
    "df_A_Pair_CWSH2.columns = ['A_CWSH2', 'DATETIME']\n",
    "df_A_Pair_CWSH2.set_index('DATETIME', inplace=True)\n",
    "print('Done', str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 2020-01-16 17:06:49.001232\n"
     ]
    }
   ],
   "source": [
    "#Pressing_1\n",
    "##wORKING as of 2020.01.15\n",
    "keyslist = list(ft_cyc_lim.keys()) #creates a list of the ft_cyc_lim keys so that we can iterate later\n",
    "\n",
    "A_t_Press1_Maxlist = list()\n",
    "A_t_Press1_Maxlist[:] = []\n",
    "\n",
    "A_t_Press1_index_List=list()      \n",
    "A_t_Press1_index_List[:] = []\n",
    "\n",
    "A_Pair_A_t_Press1_List =list() \n",
    "A_Pair_A_t_Press1_List[:] = []\n",
    "try:         \n",
    "    for i in range(0, len(keyslist)):\n",
    "        A_t_Press1_val_List=list() \n",
    "        A_t_Press1_val_List[:] = []\n",
    "        for j in range(keyslist[i], ft_cyc_lim[keyslist[i]]):               \n",
    "            A_t_Press1 = df_comb['A_t_PRESS1'][j]         \n",
    "            A_t_Press1_val_List.append(A_t_Press1)\n",
    "        A_t_Press1_Maxlist.append(sorted(A_t_Press1_val_List)[-1])\n",
    "        A_t_Press1_index_List.append((str(df_comb.index[keyslist[i]])+\" to \"+str(df_comb.index[ft_cyc_lim[keyslist[i]]])))\n",
    "    A_Pair_Press1_List = list(zip(A_t_Press1_Maxlist, A_t_Press1_index_List[0:]))      \n",
    "                        \n",
    "except:\n",
    "    pass\n",
    "df_A_Pair_PRESS1_t = pd.DataFrame(A_Pair_Press1_List)\n",
    "df_A_Pair_PRESS1_t.columns = ['A_PRESS1_t', 'DATETIME']\n",
    "df_A_Pair_PRESS1_t.set_index('DATETIME', inplace=True)\n",
    "print('Done', str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 2020-01-16 17:06:50.752755\n"
     ]
    }
   ],
   "source": [
    "#Pressing_2\n",
    "##wORKING as of 2020.01.15\n",
    "keyslist = list(ft_cyc_lim.keys()) #creates a list of the ft_cyc_lim keys so that we can iterate later\n",
    "\n",
    "A_t_Press2_Maxlist = list()\n",
    "A_t_Press2_Maxlist[:] = []\n",
    "\n",
    "A_t_Press2_index_List=list()      \n",
    "A_t_Press2_index_List[:] = []\n",
    "\n",
    "A_Pair_Press2_List =list() \n",
    "A_Pair_Press2_List[:] = []\n",
    "try:         \n",
    "    for i in range(0, len(keyslist)):\n",
    "        A_t_Press2_val_List=list() \n",
    "        A_t_Press2_val_List[:] = []\n",
    "        for j in range(keyslist[i], ft_cyc_lim[keyslist[i]]):               \n",
    "            A_t_Press2 = df_comb['A_t_PRESS2'][j]         \n",
    "            A_t_Press2_val_List.append(A_t_Press2)\n",
    "        A_t_Press2_Maxlist.append(sorted(A_t_Press2_val_List)[-1])\n",
    "        A_t_Press2_index_List.append((str(df_comb.index[keyslist[i]])+\" to \"+str(df_comb.index[ft_cyc_lim[keyslist[i]]])))\n",
    "    A_Pair_Press2_List = list(zip(A_t_Press2_Maxlist, A_t_Press2_index_List[0:]))      \n",
    "                        \n",
    "except:\n",
    "    pass\n",
    "  \n",
    "df_A_Pair_PRESS2_t = pd.DataFrame(A_Pair_Press2_List)\n",
    "df_A_Pair_PRESS2_t.columns = ['A_PRESS2_t', 'DATETIME']\n",
    "df_A_Pair_PRESS2_t.set_index('DATETIME', inplace=True)\n",
    "print('Done', str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 2020-01-16 17:06:52.086839\n"
     ]
    }
   ],
   "source": [
    "#A_PU26A_OP\n",
    "##Working as of 2020.01.15\n",
    "A_PU26A_OP_Maxlist = list()\n",
    "A_PU26A_OP_Maxlist[:] = []\n",
    "\n",
    "A_PU26A_OP_index_List=list()      \n",
    "A_PU26A_OP_index_List[:] = []\n",
    "\n",
    "A_Pair_PU26A_OP_List =list() \n",
    "A_Pair_PU26A_OP_List[:] = []\n",
    "try:         \n",
    "    for i in range(0, len(keyslist)):\n",
    "        A_PU26A_OP_val_List=list() \n",
    "        A_PU26A_OP_val_List[:] = []\n",
    "        for j in range(keyslist[i], ft_cyc_lim[keyslist[i]]):               \n",
    "            A_PU26A_OP = df_comb['PU26A_OP'][j]      \n",
    "            A_PU26A_OP_val_List.append(A_PU26A_OP)\n",
    "        A_PU26A_OP_Maxlist.append(sorted(A_PU26A_OP_val_List)[-1])\n",
    "        A_PU26A_OP_index_List.append((str(df_comb.index[keyslist[i]])+\" to \"+str(df_comb.index[ft_cyc_lim[keyslist[i]]])))\n",
    "    A_Pair_PU26A_OP_List = list(zip(A_PU26A_OP_Maxlist, A_PU26A_OP_index_List[0:]))          \n",
    "except:\n",
    "    pass\n",
    "df_A_Pair_PU26A_OP = pd.DataFrame(A_Pair_PU26A_OP_List)\n",
    "df_A_Pair_PU26A_OP.columns = ['A_PU26A_OP', 'DATETIME']\n",
    "df_A_Pair_PU26A_OP.set_index('DATETIME', inplace=True)\n",
    "print('Done', str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 2020-01-16 17:06:53.653581\n"
     ]
    }
   ],
   "source": [
    "#A_PU27A_OP\n",
    "##Working as of 2020.01.15\n",
    "keyslist = list(ft_cyc_lim.keys()) #creates a list of the ft_cyc_lim keys so that we can iterate later\n",
    "\n",
    "A_PU27A_OP_Maxlist = list()\n",
    "A_PU27A_OP_Maxlist[:] = []\n",
    "\n",
    "A_PU27A_OP_index_List=list()      \n",
    "A_PU27A_OP_index_List[:] = []\n",
    "\n",
    "A_Pair_PU27A_OP_List =list() \n",
    "A_Pair_PU27A_OP_List[:] = []\n",
    "try:         \n",
    "    for i in range(0, len(keyslist)):\n",
    "        A_PU27A_OP_val_List=list() \n",
    "        A_PU27A_OP_val_List[:] = []\n",
    "        for j in range(keyslist[i], ft_cyc_lim[keyslist[i]]):               \n",
    "            A_PU27A_OP = df_comb['PU27A_OP'][j]      \n",
    "            A_PU27A_OP_val_List.append(A_PU27A_OP)\n",
    "        A_PU27A_OP_Maxlist.append(sorted(A_PU27A_OP_val_List)[-1])\n",
    "        A_PU27A_OP_index_List.append((str(df_comb.index[keyslist[i]])+\" to \"+str(df_comb.index[ft_cyc_lim[keyslist[i]]])))\n",
    "    A_Pair_PU27A_OP_List = list(zip(A_PU27A_OP_Maxlist, A_PU27A_OP_index_List[0:]))          \n",
    "except:\n",
    "    pass\n",
    "  \n",
    "df_A_Pair_PU27A_OP = pd.DataFrame(A_Pair_PU27A_OP_List)\n",
    "df_A_Pair_PU27A_OP.columns = ['A_PU27A_OP', 'DATETIME']\n",
    "df_A_Pair_PU27A_OP.set_index('DATETIME', inplace=True)\n",
    "print('Done', str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 2020-01-16 17:06:57.551754\n"
     ]
    }
   ],
   "source": [
    "#this code replaces the 'No Good Data' from 106PU26A_CUR column\n",
    "for x in range(0, len(df_comb['106PU26A_CUR'])):\n",
    "    if df_comb['106PU26A_CUR'][x] =='[-11059] No Good Data For Calculation':\n",
    "            df_comb['106PU26A_CUR'][x] = 0\n",
    "#A_PU26A_CUR\n",
    "##Working as of 2020.01.15\n",
    "keyslist = list(ft_cyc_lim.keys()) #creates a list of the ft_cyc_lim keys so that we can iterate later\n",
    "\n",
    "A_PU26A_CUR_Maxlist = list()\n",
    "A_PU26A_CUR_Maxlist[:] = []\n",
    "\n",
    "A_PU26A_CUR_index_List=list()      \n",
    "A_PU26A_CUR_index_List[:] = []\n",
    "\n",
    "A_Pair_PU26A_CUR_List =list() \n",
    "A_Pair_PU26A_CUR_List[:] = []\n",
    "try:         \n",
    "    for i in range(0, len(keyslist)):\n",
    "        A_PU26A_CUR_val=list() \n",
    "        A_PU26A_CUR_val[:] = []\n",
    "        for j in range(keyslist[i], ft_cyc_lim[keyslist[i]]):               \n",
    "            A_PU26A_CUR = df_comb['106PU26A_CUR'][j]      \n",
    "            A_PU26A_CUR_val.append(A_PU26A_CUR)\n",
    "        A_PU26A_CUR_Maxlist.append(sorted(A_PU26A_CUR_val)[-1])\n",
    "        A_PU26A_CUR_index_List.append((str(df_comb.index[keyslist[i]])+\" to \"+str(df_comb.index[ft_cyc_lim[keyslist[i]]])))\n",
    "    A_Pair_PU26A_CUR_List = list(zip(A_PU26A_CUR_Maxlist, A_PU26A_CUR_index_List[0:]))          \n",
    "except:\n",
    "    pass\n",
    "\n",
    "df_A_Pair_PU26A_CUR = pd.DataFrame(A_Pair_PU26A_CUR_List)\n",
    "df_A_Pair_PU26A_CUR.columns = ['A_PU26A_CUR', 'DATETIME']\n",
    "df_A_Pair_PU26A_CUR.set_index('DATETIME', inplace=True)\n",
    "print('Done', str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 2020-01-16 17:07:00.832489\n"
     ]
    }
   ],
   "source": [
    "#this code replaces the 'No Good Data' from 106PU26A_CUR column\n",
    "for x in range(0, len(df_comb['106PU27A_CUR'])):\n",
    "    if df_comb['106PU27A_CUR'][x] =='[-11059] No Good Data For Calculation':\n",
    "            df_comb['106PU27A_CUR'][x] = 0\n",
    "#A_PU27A_CUR\n",
    "##Working as of 2020.01.15 after a million trials!!!!!!!!!! mabuak na akong utok!!!\n",
    "keyslist = list(ft_cyc_lim.keys()) #creates a list of the ft_cyc_lim keys so that we can iterate later\n",
    "\n",
    "A_PU27A_CUR_Maxlist = list()\n",
    "A_PU27A_CUR_Maxlist[:] = []\n",
    "\n",
    "A_PU27A_CUR_index_List=list()      \n",
    "A_PU27A_CUR_index_List[:] = []\n",
    "\n",
    "A_Pair_PU27A_CUR_List =list() \n",
    "A_Pair_PU27A_CUR_List[:] = []\n",
    "try:         \n",
    "    for i in range(0, len(keyslist)):\n",
    "        A_PU27A_CUR_val=list() \n",
    "        A_PU27A_CUR_val[:] = []\n",
    "        for j in range(keyslist[i], ft_cyc_lim[keyslist[i]]):               \n",
    "            A_PU27A_CUR = df_comb['106PU27A_CUR'][j]      \n",
    "            A_PU27A_CUR_val.append(A_PU27A_CUR)\n",
    "        A_PU27A_CUR_Maxlist.append(sorted(A_PU27A_CUR_val)[-1])\n",
    "        A_PU27A_CUR_index_List.append((str(df_comb.index[keyslist[i]])+\" to \"+str(df_comb.index[ft_cyc_lim[keyslist[i]]])))\n",
    "    A_Pair_PU27A_CUR_List = list(zip(A_PU27A_CUR_Maxlist, A_PU27A_CUR_index_List[0:]))          \n",
    "except:\n",
    "    pass\n",
    "  \n",
    "df_A_Pair_PU27A_CUR = pd.DataFrame(A_Pair_PU27A_CUR_List)\n",
    "df_A_Pair_PU27A_CUR.columns = ['A_PU27A_CUR', 'DATETIME']\n",
    "df_A_Pair_PU27A_CUR.set_index('DATETIME', inplace=True)\n",
    "print('Done', str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 2020-01-16 17:07:00.892345\n"
     ]
    }
   ],
   "source": [
    "#A_N2 Dry\n",
    "##Working as of 2020-01-15 17:26:09.736327\n",
    "A_Pair_N2_Dry_List = list()\n",
    "A_Pair_N2_Dry_List[:] = []\n",
    "A_t_N2_Dry_indexList = list()\n",
    "A_t_N2_Dry_indexList[:] = []\n",
    "A_t_N2_Dry_val = list()\n",
    "A_t_N2_Dry_val[:] = []\n",
    "try:         \n",
    "    for i in range(0, len(keyslist)):   \n",
    "        A_t_N2_Dry = df_comb['A_t_DRY'][ft_cyc_lim[keyslist[i]]]\n",
    "        A_t_N2_Dry_val.append(A_t_N2_Dry)\n",
    "        A_t_N2_Dry_indexList.append((str(df_comb.index[keyslist[i]])+\" to \"+str(df_comb.index[ft_cyc_lim[keyslist[i]]])))\n",
    "    \n",
    "    A_Pair_N2_Dry_List = list(zip(A_t_N2_Dry_val, A_t_N2_Dry_indexList[0:]))          \n",
    "except:\n",
    "    pass\n",
    "\n",
    "df_A_Pair_N2DRY = pd.DataFrame(A_Pair_N2_Dry_List)\n",
    "df_A_Pair_N2DRY.columns = ['A_N2DRY', 'DATETIME']\n",
    "df_A_Pair_N2DRY.set_index('DATETIME', inplace=True)\n",
    "print('Done', str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 2020-01-16 17:07:11.659854\n"
     ]
    }
   ],
   "source": [
    "dfn = df_A_Pair_CWP_1.join(df_A_Pair_CWP_2, how='outer')\n",
    "dfn1 = df_A_Pair_Filt_t.join(df_A_Pair_MANF_P, how='outer')\n",
    "dfn2 = df_A_Pair_CWSH1.join(df_A_Pair_CWSH2, how='outer')\n",
    "dfn3 = df_A_Pair_PRESS1_t.join(df_A_Pair_PRESS2_t, how='outer')\n",
    "dfn4 = df_A_Pair_PU26A_OP.join(df_A_Pair_PU27A_OP, how='outer')\n",
    "dfn5 = df_A_Pair_PU26A_CUR.join(df_A_Pair_PU27A_CUR, how='outer')\n",
    "dfn6 = df_A_Pair_N2DRY.join(dfn, how='outer')\n",
    "dfn7 = dfn1.join(dfn2, how='outer')\n",
    "dfn8 = dfn3.join(dfn4, how='outer')\n",
    "dfn9 = dfn5.join(dfn6, how='outer')\n",
    "dfn10 = dfn7.join(dfn8, how='outer')\n",
    "dfn11 = dfn9.join(dfn10, how='outer')\n",
    "print('Done', str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "Done 2020-01-16 18:59:33.627685\n"
     ]
    }
   ],
   "source": [
    "#####This block of code appends the Analysis Results from 106TH01 UF\n",
    "import datetime\n",
    "from dateutil.parser import parse\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import openpyxl\n",
    "wb1 = openpyxl.load_workbook(r'C:\\Users\\v.t.flores\\Documents\\Copy of 11.) November_ 2019.xlsx')\n",
    "TH01_UF_sheet = wb1['106TH01 UF']\n",
    "\n",
    "#This code finds the indexloc of the cells with day number from the sampling date column\n",
    "rows_n = list()\n",
    "try:\n",
    "    for i in range (1, TH01_UF_sheet.max_row+1):\n",
    "        if type(TH01_UF_sheet['B'+ str(i)].value) == int:\n",
    "            #print(str(i)+':'+str(TH01_UF_sheet['B'+ str(i)].value))\n",
    "            rows_n.append(i)\n",
    "except:\n",
    "    pass\n",
    "#--------------------------\n",
    "#This code finds the Pb concentration and the datetime\n",
    "Pb_df_list = list()\n",
    "Pb_df_list[:] = []\n",
    "PbList = list()\n",
    "PbList[:] = []\n",
    "timeList = list()\n",
    "timeList[:] = []\n",
    "\n",
    "for i in range(0, len(rows_n)-1):\n",
    "    for j in range(rows_n[i], rows_n[i+1]):        \n",
    "        if TH01_UF_sheet['S'+str(j)].value != None and type(TH01_UF_sheet['S'+str(j)].value) == float:\n",
    "            if  type(TH01_UF_sheet['C'+str(j)].value) == datetime.datetime:\n",
    "                time_val = TH01_UF_sheet['C'+str(j)].value           \n",
    "                strdate = parse(str(time_val))\n",
    "                newtime = str(strdate).split(\" \")[1]\n",
    "                newdate = \"2019/11/\"+str(TH01_UF_sheet['B'+str(rows_n[i])].value)+' '+newtime\n",
    "            elif type(TH01_UF_sheet['C'+str(j)].value) == datetime.time:\n",
    "                time_val = TH01_UF_sheet['C'+str(j)].value           \n",
    "                strdate = str(time_val)\n",
    "                newdate = \"2019/11/\"+str(TH01_UF_sheet['B'+str(rows_n[i])].value)+' '+strdate               \n",
    "            timeList.append(parse(newdate))\n",
    "            Pb_val = TH01_UF_sheet['S'+str(j)].value\n",
    "            PbList.append(Pb_val)\n",
    "    #print(TH01_UF_sheet['B'+str(rows_n[i])].value)\n",
    "Pb_df_list = list(zip(PbList, timeList[0:]))\n",
    "\n",
    "#converting lists to dataframe\n",
    "Pb_df = pd.DataFrame(Pb_df_list)\n",
    "Pb_df.columns = ['Pb', 'DATETIME']\n",
    "Pb_df.set_index('DATETIME', inplace=True)\n",
    "print('done')\n",
    "#--------------\n",
    "#This code finds the Zn concentration and the datetime\n",
    "\n",
    "Zn_df_list = list()\n",
    "Zn_df_list[:] = []\n",
    "ZnList = list()\n",
    "ZnList[:] = []\n",
    "ZntimeList = list()\n",
    "ZntimeList[:] = []\n",
    "\n",
    "for i in range(0, len(rows_n)-1):\n",
    "    for j in range(rows_n[i], rows_n[i+1]):        \n",
    "        if TH01_UF_sheet['T'+str(j)].value != None and type(TH01_UF_sheet['T'+str(j)].value) == float:\n",
    "            if  type(TH01_UF_sheet['C'+str(j)].value) == datetime.datetime:\n",
    "                time_val = TH01_UF_sheet['C'+str(j)].value           \n",
    "                strdate = parse(str(time_val))\n",
    "                newtime = str(strdate).split(\" \")[1]\n",
    "                newdate = \"2019/11/\"+str(TH01_UF_sheet['B'+str(rows_n[i])].value)+' '+newtime\n",
    "            elif type(TH01_UF_sheet['C'+str(j)].value) == datetime.time:\n",
    "                time_val = TH01_UF_sheet['C'+str(j)].value           \n",
    "                strdate = str(time_val)\n",
    "                newdate = \"2019/11/\"+str(TH01_UF_sheet['B'+str(rows_n[i])].value)+' '+strdate               \n",
    "            timeList.append(parse(newdate))\n",
    "            Zn_val = TH01_UF_sheet['T'+str(j)].value\n",
    "            ZnList.append(Zn_val)\n",
    "    #print(TH01_UF_sheet['B'+str(rows_n[i])].value)\n",
    "Zn_df_list = list(zip(ZnList, timeList[0:]))\n",
    "\n",
    "#converting lists to dataframe\n",
    "Zn_df = pd.DataFrame(Zn_df_list)\n",
    "Zn_df.columns = ['Zn', 'DATETIME']\n",
    "Zn_df.set_index('DATETIME', inplace=True)\n",
    "\n",
    "#--------------\n",
    "#This code finds the Cu concentration and the datetime\n",
    "\n",
    "Cu_df_list = list()\n",
    "Cu_df_list[:] = []\n",
    "CuList = list()\n",
    "CuList[:] = []\n",
    "CutimeList = list()\n",
    "CutimeList[:] = []\n",
    "\n",
    "for i in range(0, len(rows_n)-1):\n",
    "    for j in range(rows_n[i], rows_n[i+1]):        \n",
    "        if TH01_UF_sheet['U'+str(j)].value != None and type(TH01_UF_sheet['U'+str(j)].value) == float: ##check if column is updated\n",
    "            if  type(TH01_UF_sheet['C'+str(j)].value) == datetime.datetime:\n",
    "                time_val = TH01_UF_sheet['C'+str(j)].value           \n",
    "                strdate = parse(str(time_val))\n",
    "                newtime = str(strdate).split(\" \")[1]\n",
    "                newdate = \"2019/11/\"+str(TH01_UF_sheet['B'+str(rows_n[i])].value)+' '+newtime\n",
    "            elif type(TH01_UF_sheet['C'+str(j)].value) == datetime.time:\n",
    "                time_val = TH01_UF_sheet['C'+str(j)].value           \n",
    "                strdate = str(time_val)\n",
    "                newdate = \"2019/11/\"+str(TH01_UF_sheet['B'+str(rows_n[i])].value)+' '+strdate               \n",
    "            timeList.append(parse(newdate))\n",
    "            Cu_val = TH01_UF_sheet['U'+str(j)].value ##check if column and varname is updated\n",
    "            CuList.append(Cu_val) ##check if list title is updated\n",
    "Cu_df_list = list(zip(CuList, timeList[0:]))\n",
    "\n",
    "#converting lists to dataframe\n",
    "Cu_df = pd.DataFrame(Zn_df_list)\n",
    "Cu_df.columns = ['Cu', 'DATETIME'] ##check if list title is updated\n",
    "Cu_df.set_index('DATETIME', inplace=True)\n",
    "\n",
    "#--------------\n",
    "#This code finds the Mg concentration and the datetime\n",
    "Mg_df_list = list()\n",
    "Mg_df_list[:] = []\n",
    "MgList = list()\n",
    "MgList[:] = []\n",
    "MgtimeList = list()\n",
    "MgtimeList[:] = []\n",
    "\n",
    "for i in range(0, len(rows_n)-1):\n",
    "    for j in range(rows_n[i], rows_n[i+1]):        \n",
    "        if TH01_UF_sheet['AD'+str(j)].value != None and type(TH01_UF_sheet['AD'+str(j)].value) == float: ##check if column is updated\n",
    "            if  type(TH01_UF_sheet['C'+str(j)].value) == datetime.datetime:\n",
    "                time_val = TH01_UF_sheet['C'+str(j)].value           \n",
    "                strdate = parse(str(time_val))\n",
    "                newtime = str(strdate).split(\" \")[1]\n",
    "                newdate = \"2019/11/\"+str(TH01_UF_sheet['B'+str(rows_n[i])].value)+' '+newtime\n",
    "            elif type(TH01_UF_sheet['C'+str(j)].value) == datetime.time:\n",
    "                time_val = TH01_UF_sheet['C'+str(j)].value           \n",
    "                strdate = str(time_val)\n",
    "                newdate = \"2019/11/\"+str(TH01_UF_sheet['B'+str(rows_n[i])].value)+' '+strdate               \n",
    "            timeList.append(parse(newdate))\n",
    "            Mg_val = TH01_UF_sheet['AD'+str(j)].value ##check if column and varname are updated\n",
    "            MgList.append(Mg_val) ##check if list title is updated\n",
    "Mg_df_list = list(zip(MgList, timeList[0:])) ##check if the list titles and the df list are updated\n",
    "\n",
    "#converting lists to dataframe\n",
    "Mg_df = pd.DataFrame(Mg_df_list) ##check if the element list title is updated\n",
    "Mg_df.columns = ['Mg', 'DATETIME'] ##check if list title and the column name are updated\n",
    "Mg_df.set_index('DATETIME', inplace=True)\n",
    "#--------------\n",
    "\n",
    "dfEl1 = Pb_df.join(Mg_df, how='outer')\n",
    "dfEl2 = Cu_df.join(Zn_df, how='outer')\n",
    "dfEL3 = dfEl1.join(dfEl2, how='outer')\n",
    "print('Done', str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn12 = dfEL3.join(dfn11, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pb</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Cu</th>\n",
       "      <th>Zn</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATETIME</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2019-11-01 07:00:00</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0266</td>\n",
       "      <td>0.0266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-01 11:00:00</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0372</td>\n",
       "      <td>0.0372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-01 15:00:00</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0409</td>\n",
       "      <td>0.0409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-01 19:00:00</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0209</td>\n",
       "      <td>0.0209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-01 23:00:00</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-30 11:00:00</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.0041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-30 15:00:00</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-30 19:00:00</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-30 23:00:00</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-30 03:00:00</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>0.0066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Pb      Mg      Cu      Zn\n",
       "DATETIME                                          \n",
       "2019-11-01 07:00:00  0.001  0.0058  0.0266  0.0266\n",
       "2019-11-01 11:00:00  0.001  0.0049  0.0372  0.0372\n",
       "2019-11-01 15:00:00  0.001  0.0050  0.0409  0.0409\n",
       "2019-11-01 19:00:00  0.001  0.0055  0.0209  0.0209\n",
       "2019-11-01 23:00:00  0.001  0.0062  0.0191  0.0191\n",
       "...                    ...     ...     ...     ...\n",
       "2019-11-30 11:00:00  0.001  0.0046  0.0041  0.0041\n",
       "2019-11-30 15:00:00  0.001  0.0042  0.0054  0.0054\n",
       "2019-11-30 19:00:00  0.001  0.0047  0.0044  0.0044\n",
       "2019-11-30 23:00:00  0.001  0.0059  0.0045  0.0045\n",
       "2019-11-30 03:00:00  0.001  0.0056  0.0066  0.0066\n",
       "\n",
       "[175 rows x 4 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfEL3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn12.to_excel(r'C:\\Users\\v.t.flores\\Documents\\201911Data_Mg_Inv_20200116.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019-11-01 00:11:00 to 2019-11-01 00:34:00'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(df_comb.index[keyslist[0]])+\" to \"+str(df_comb.index[ft_cyc_lim[keyslist[0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyslist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2019-11-01 00:11:00')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comb.index[keyslist[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2019-11-01 00:34:00')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comb.index[ft_cyc_lim[keyslist[0]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2019-11-01 07:00:00')"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfEL3.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comb.index[keyslist[0]] > dfEL3.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn11['newdt'] = dfn11.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_106FT02B_spcl['DATETIME'] = df_106FT02B_spcl['DATETIME'].apply(lambda x: parse(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2019-11-01 00:11:00 ', ' 2019-11-01 00:34:00']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfn11['newdt'][0].split(\"to\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datesplitter_start(x):\n",
    "    return parse(x.split('to')[0])\n",
    "def datesplitter_end(x):\n",
    "    return parse(x.split('to')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn11['startdate'] = dfn11['newdt'].apply(lambda x: datesplitter_start(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn11['enddate'] = dfn11['newdt'].apply(lambda x: datesplitter_end(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'>\n"
     ]
    }
   ],
   "source": [
    "print(type(dfn11['enddate'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfEL3.index[0] < dfn11['enddate'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2019-11-01 00:34:00')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfn11['enddate'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2019-11-01 07:00:00')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfEL3.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfEL3.index[0] < dfn11['startdate'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019-11-01 00:11:00 to 2019-11-01 00:34:00'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfn11.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "List_analysis = list(zip(, [0:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfEL3['daterange'] = dfEL3.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATETIME\n",
       "2019-11-01 07:00:00   2019-11-01 07:00:00\n",
       "2019-11-01 11:00:00   2019-11-01 11:00:00\n",
       "2019-11-01 15:00:00   2019-11-01 15:00:00\n",
       "2019-11-01 19:00:00   2019-11-01 19:00:00\n",
       "2019-11-01 23:00:00   2019-11-01 23:00:00\n",
       "                              ...        \n",
       "2019-11-30 11:00:00   2019-11-30 11:00:00\n",
       "2019-11-30 15:00:00   2019-11-30 15:00:00\n",
       "2019-11-30 19:00:00   2019-11-30 19:00:00\n",
       "2019-11-30 23:00:00   2019-11-30 23:00:00\n",
       "2019-11-30 03:00:00   2019-11-30 03:00:00\n",
       "Name: daterange, Length: 175, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfEL3['daterange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pb</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Cu</th>\n",
       "      <th>Zn</th>\n",
       "      <th>daterange</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATETIME</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2019-11-01 07:00:00</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0266</td>\n",
       "      <td>0.0266</td>\n",
       "      <td>2019-11-01 07:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-01 11:00:00</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0372</td>\n",
       "      <td>0.0372</td>\n",
       "      <td>2019-11-01 11:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-01 15:00:00</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0409</td>\n",
       "      <td>0.0409</td>\n",
       "      <td>2019-11-01 15:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-01 19:00:00</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0209</td>\n",
       "      <td>0.0209</td>\n",
       "      <td>2019-11-01 19:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-01 23:00:00</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>2019-11-01 23:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-30 11:00:00</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>2019-11-30 11:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-30 15:00:00</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>2019-11-30 15:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-30 19:00:00</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>2019-11-30 19:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-30 23:00:00</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>2019-11-30 23:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-30 03:00:00</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>2019-11-30 03:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Pb      Mg      Cu      Zn           daterange\n",
       "DATETIME                                                              \n",
       "2019-11-01 07:00:00  0.001  0.0058  0.0266  0.0266 2019-11-01 07:00:00\n",
       "2019-11-01 11:00:00  0.001  0.0049  0.0372  0.0372 2019-11-01 11:00:00\n",
       "2019-11-01 15:00:00  0.001  0.0050  0.0409  0.0409 2019-11-01 15:00:00\n",
       "2019-11-01 19:00:00  0.001  0.0055  0.0209  0.0209 2019-11-01 19:00:00\n",
       "2019-11-01 23:00:00  0.001  0.0062  0.0191  0.0191 2019-11-01 23:00:00\n",
       "...                    ...     ...     ...     ...                 ...\n",
       "2019-11-30 11:00:00  0.001  0.0046  0.0041  0.0041 2019-11-30 11:00:00\n",
       "2019-11-30 15:00:00  0.001  0.0042  0.0054  0.0054 2019-11-30 15:00:00\n",
       "2019-11-30 19:00:00  0.001  0.0047  0.0044  0.0044 2019-11-30 19:00:00\n",
       "2019-11-30 23:00:00  0.001  0.0059  0.0045  0.0045 2019-11-30 23:00:00\n",
       "2019-11-30 03:00:00  0.001  0.0056  0.0066  0.0066 2019-11-30 03:00:00\n",
       "\n",
       "[175 rows x 5 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfEL3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019-11-01 00:11:00 to 2019-11-01 00:34:00'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfn11.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1325"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfn11['startdate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-01 11:00:00\n",
      "2019-11-01 15:00:00\n",
      "2019-11-01 19:00:00\n",
      "2019-11-01 23:00:00\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 5):\n",
    "    print(df_ELa['daterange'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anl_indexList = list()\n",
    "df_anl_indexList[:] = []\n",
    "\n",
    "df_n11_indexList = list()\n",
    "df_n11_indexList[:] = []\n",
    "\n",
    "for i in range(0, 175):\n",
    "    for j in range(0, len(dfn11)):\n",
    "        if dfn11['startdate'][j] <= dfEL3['daterange'][i] and dfn11['enddate'][j] >= dfEL3['daterange'][i]:\n",
    "            df_n11_indexList.append(dfn11.index[j])\n",
    "            df_anl_indexList.append(dfEL3.index[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Analys_indexList_Pair = list(zip(df_anl_indexList, df_n11_indexList[0:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_anl_indexList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_n11_indexList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfEL4 = pd.DataFrame(Analys_indexList_Pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfEL3.to_excel(r'C:\\Users\\v.t.flores\\Documents\\20200116PM_datetimerangep2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FT_cycletimerange</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATETIME</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2019-11-01 07:00:00</td>\n",
       "      <td>2019-11-01 06:56:00 to 2019-11-01 07:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-01 19:00:00</td>\n",
       "      <td>2019-11-01 18:57:00 to 2019-11-01 19:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-01 23:00:00</td>\n",
       "      <td>2019-11-01 22:45:00 to 2019-11-01 23:07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-01 03:00:00</td>\n",
       "      <td>2019-11-01 02:44:00 to 2019-11-01 03:06:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-02 11:00:00</td>\n",
       "      <td>2019-11-02 10:42:00 to 2019-11-02 11:05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-02 15:00:00</td>\n",
       "      <td>2019-11-02 14:46:00 to 2019-11-02 15:08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-02 19:00:00</td>\n",
       "      <td>2019-11-02 18:55:00 to 2019-11-02 19:17:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-02 03:00:00</td>\n",
       "      <td>2019-11-02 02:50:00 to 2019-11-02 03:12:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-03 07:00:00</td>\n",
       "      <td>2019-11-03 06:44:00 to 2019-11-03 07:08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-03 11:00:00</td>\n",
       "      <td>2019-11-03 10:56:00 to 2019-11-03 11:18:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-03 15:00:00</td>\n",
       "      <td>2019-11-03 14:39:00 to 2019-11-03 15:02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-03 19:00:00</td>\n",
       "      <td>2019-11-03 18:48:00 to 2019-11-03 19:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-03 23:00:00</td>\n",
       "      <td>2019-11-03 22:36:00 to 2019-11-03 23:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-03 03:00:00</td>\n",
       "      <td>2019-11-03 02:56:00 to 2019-11-03 03:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-04 07:00:00</td>\n",
       "      <td>2019-11-04 06:41:00 to 2019-11-04 07:05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-04 11:00:00</td>\n",
       "      <td>2019-11-04 10:41:00 to 2019-11-04 11:05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-04 15:00:00</td>\n",
       "      <td>2019-11-04 14:51:00 to 2019-11-04 15:16:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-04 23:00:00</td>\n",
       "      <td>2019-11-04 22:49:00 to 2019-11-04 23:14:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-04 03:00:00</td>\n",
       "      <td>2019-11-04 02:51:00 to 2019-11-04 03:14:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-05 11:00:00</td>\n",
       "      <td>2019-11-05 10:41:00 to 2019-11-05 11:04:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-05 15:00:00</td>\n",
       "      <td>2019-11-05 14:55:00 to 2019-11-05 15:19:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-05 23:00:00</td>\n",
       "      <td>2019-11-05 22:39:00 to 2019-11-05 23:03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-05 03:00:00</td>\n",
       "      <td>2019-11-05 02:47:00 to 2019-11-05 03:11:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-06 07:00:00</td>\n",
       "      <td>2019-11-06 06:49:00 to 2019-11-06 07:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-06 19:00:00</td>\n",
       "      <td>2019-11-06 19:00:00 to 2019-11-06 19:27:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-06 23:00:00</td>\n",
       "      <td>2019-11-06 22:53:00 to 2019-11-06 23:19:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-06 03:00:00</td>\n",
       "      <td>2019-11-06 02:51:00 to 2019-11-06 03:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-07 07:00:00</td>\n",
       "      <td>2019-11-07 06:57:00 to 2019-11-07 07:25:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-07 11:00:00</td>\n",
       "      <td>2019-11-07 10:37:00 to 2019-11-07 11:09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-07 19:00:00</td>\n",
       "      <td>2019-11-07 18:40:00 to 2019-11-07 19:01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-07 03:00:00</td>\n",
       "      <td>2019-11-07 02:46:00 to 2019-11-07 03:12:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-08 07:00:00</td>\n",
       "      <td>2019-11-08 06:45:00 to 2019-11-08 07:09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-08 11:00:00</td>\n",
       "      <td>2019-11-08 10:47:00 to 2019-11-08 11:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-08 15:00:00</td>\n",
       "      <td>2019-11-08 14:40:00 to 2019-11-08 15:04:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-08 19:00:00</td>\n",
       "      <td>2019-11-08 18:55:00 to 2019-11-08 19:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-08 03:00:00</td>\n",
       "      <td>2019-11-08 02:45:00 to 2019-11-08 03:11:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-09 07:00:00</td>\n",
       "      <td>2019-11-09 06:40:00 to 2019-11-09 07:03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-09 11:00:00</td>\n",
       "      <td>2019-11-09 10:48:00 to 2019-11-09 11:14:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-09 19:00:00</td>\n",
       "      <td>2019-11-09 18:33:00 to 2019-11-09 19:01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-09 03:00:00</td>\n",
       "      <td>2019-11-09 02:42:00 to 2019-11-09 03:07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-10 11:00:00</td>\n",
       "      <td>2019-11-10 10:54:00 to 2019-11-10 11:22:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-10 19:00:00</td>\n",
       "      <td>2019-11-10 18:59:00 to 2019-11-10 19:18:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-10 23:00:00</td>\n",
       "      <td>2019-11-10 22:52:00 to 2019-11-10 23:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-11 07:00:00</td>\n",
       "      <td>2019-11-11 06:58:00 to 2019-11-11 07:22:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-11 19:00:00</td>\n",
       "      <td>2019-11-11 18:59:00 to 2019-11-11 19:22:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-11 23:00:00</td>\n",
       "      <td>2019-11-11 22:42:00 to 2019-11-11 23:06:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-12 11:00:00</td>\n",
       "      <td>2019-11-12 10:42:00 to 2019-11-12 11:04:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-12 15:00:00</td>\n",
       "      <td>2019-11-12 14:53:00 to 2019-11-12 15:14:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-12 23:00:00</td>\n",
       "      <td>2019-11-12 22:45:00 to 2019-11-12 23:09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-12 03:00:00</td>\n",
       "      <td>2019-11-12 02:56:00 to 2019-11-12 03:19:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              FT_cycletimerange\n",
       "DATETIME                                                       \n",
       "2019-11-01 07:00:00  2019-11-01 06:56:00 to 2019-11-01 07:20:00\n",
       "2019-11-01 19:00:00  2019-11-01 18:57:00 to 2019-11-01 19:20:00\n",
       "2019-11-01 23:00:00  2019-11-01 22:45:00 to 2019-11-01 23:07:00\n",
       "2019-11-01 03:00:00  2019-11-01 02:44:00 to 2019-11-01 03:06:00\n",
       "2019-11-02 11:00:00  2019-11-02 10:42:00 to 2019-11-02 11:05:00\n",
       "2019-11-02 15:00:00  2019-11-02 14:46:00 to 2019-11-02 15:08:00\n",
       "2019-11-02 19:00:00  2019-11-02 18:55:00 to 2019-11-02 19:17:00\n",
       "2019-11-02 03:00:00  2019-11-02 02:50:00 to 2019-11-02 03:12:00\n",
       "2019-11-03 07:00:00  2019-11-03 06:44:00 to 2019-11-03 07:08:00\n",
       "2019-11-03 11:00:00  2019-11-03 10:56:00 to 2019-11-03 11:18:00\n",
       "2019-11-03 15:00:00  2019-11-03 14:39:00 to 2019-11-03 15:02:00\n",
       "2019-11-03 19:00:00  2019-11-03 18:48:00 to 2019-11-03 19:10:00\n",
       "2019-11-03 23:00:00  2019-11-03 22:36:00 to 2019-11-03 23:00:00\n",
       "2019-11-03 03:00:00  2019-11-03 02:56:00 to 2019-11-03 03:20:00\n",
       "2019-11-04 07:00:00  2019-11-04 06:41:00 to 2019-11-04 07:05:00\n",
       "2019-11-04 11:00:00  2019-11-04 10:41:00 to 2019-11-04 11:05:00\n",
       "2019-11-04 15:00:00  2019-11-04 14:51:00 to 2019-11-04 15:16:00\n",
       "2019-11-04 23:00:00  2019-11-04 22:49:00 to 2019-11-04 23:14:00\n",
       "2019-11-04 03:00:00  2019-11-04 02:51:00 to 2019-11-04 03:14:00\n",
       "2019-11-05 11:00:00  2019-11-05 10:41:00 to 2019-11-05 11:04:00\n",
       "2019-11-05 15:00:00  2019-11-05 14:55:00 to 2019-11-05 15:19:00\n",
       "2019-11-05 23:00:00  2019-11-05 22:39:00 to 2019-11-05 23:03:00\n",
       "2019-11-05 03:00:00  2019-11-05 02:47:00 to 2019-11-05 03:11:00\n",
       "2019-11-06 07:00:00  2019-11-06 06:49:00 to 2019-11-06 07:15:00\n",
       "2019-11-06 19:00:00  2019-11-06 19:00:00 to 2019-11-06 19:27:00\n",
       "2019-11-06 23:00:00  2019-11-06 22:53:00 to 2019-11-06 23:19:00\n",
       "2019-11-06 03:00:00  2019-11-06 02:51:00 to 2019-11-06 03:15:00\n",
       "2019-11-07 07:00:00  2019-11-07 06:57:00 to 2019-11-07 07:25:00\n",
       "2019-11-07 11:00:00  2019-11-07 10:37:00 to 2019-11-07 11:09:00\n",
       "2019-11-07 19:00:00  2019-11-07 18:40:00 to 2019-11-07 19:01:00\n",
       "2019-11-07 03:00:00  2019-11-07 02:46:00 to 2019-11-07 03:12:00\n",
       "2019-11-08 07:00:00  2019-11-08 06:45:00 to 2019-11-08 07:09:00\n",
       "2019-11-08 11:00:00  2019-11-08 10:47:00 to 2019-11-08 11:10:00\n",
       "2019-11-08 15:00:00  2019-11-08 14:40:00 to 2019-11-08 15:04:00\n",
       "2019-11-08 19:00:00  2019-11-08 18:55:00 to 2019-11-08 19:20:00\n",
       "2019-11-08 03:00:00  2019-11-08 02:45:00 to 2019-11-08 03:11:00\n",
       "2019-11-09 07:00:00  2019-11-09 06:40:00 to 2019-11-09 07:03:00\n",
       "2019-11-09 11:00:00  2019-11-09 10:48:00 to 2019-11-09 11:14:00\n",
       "2019-11-09 19:00:00  2019-11-09 18:33:00 to 2019-11-09 19:01:00\n",
       "2019-11-09 03:00:00  2019-11-09 02:42:00 to 2019-11-09 03:07:00\n",
       "2019-11-10 11:00:00  2019-11-10 10:54:00 to 2019-11-10 11:22:00\n",
       "2019-11-10 19:00:00  2019-11-10 18:59:00 to 2019-11-10 19:18:00\n",
       "2019-11-10 23:00:00  2019-11-10 22:52:00 to 2019-11-10 23:15:00\n",
       "2019-11-11 07:00:00  2019-11-11 06:58:00 to 2019-11-11 07:22:00\n",
       "2019-11-11 19:00:00  2019-11-11 18:59:00 to 2019-11-11 19:22:00\n",
       "2019-11-11 23:00:00  2019-11-11 22:42:00 to 2019-11-11 23:06:00\n",
       "2019-11-12 11:00:00  2019-11-12 10:42:00 to 2019-11-12 11:04:00\n",
       "2019-11-12 15:00:00  2019-11-12 14:53:00 to 2019-11-12 15:14:00\n",
       "2019-11-12 23:00:00  2019-11-12 22:45:00 to 2019-11-12 23:09:00\n",
       "2019-11-12 03:00:00  2019-11-12 02:56:00 to 2019-11-12 03:19:00"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfEL4.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfEL4.columns = ['DATETIME', 'FT_cycletimerange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfEL4.set_index('DATETIME', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfEL5 = dfEL3.join(dfEL4, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2019-11-01 07:00:00', '2019-11-01 11:00:00',\n",
       "               '2019-11-01 15:00:00', '2019-11-01 19:00:00',\n",
       "               '2019-11-01 23:00:00', '2019-11-01 03:00:00',\n",
       "               '2019-11-02 07:00:00', '2019-11-02 11:00:00',\n",
       "               '2019-11-02 15:00:00', '2019-11-02 19:00:00',\n",
       "               ...\n",
       "               '2019-11-29 15:00:00', '2019-11-29 19:00:00',\n",
       "               '2019-11-29 23:00:00', '2019-11-29 03:00:00',\n",
       "               '2019-11-30 07:00:00', '2019-11-30 11:00:00',\n",
       "               '2019-11-30 15:00:00', '2019-11-30 19:00:00',\n",
       "               '2019-11-30 23:00:00', '2019-11-30 03:00:00'],\n",
       "              dtype='datetime64[ns]', name='DATETIME', length=175, freq=None)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfEL3.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pb</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Cu</th>\n",
       "      <th>Zn</th>\n",
       "      <th>daterange</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATETIME</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2019-11-01 07:00:00</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0266</td>\n",
       "      <td>0.0266</td>\n",
       "      <td>2019-11-01 07:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-01 11:00:00</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0372</td>\n",
       "      <td>0.0372</td>\n",
       "      <td>2019-11-01 11:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-01 15:00:00</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0409</td>\n",
       "      <td>0.0409</td>\n",
       "      <td>2019-11-01 15:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-01 19:00:00</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0209</td>\n",
       "      <td>0.0209</td>\n",
       "      <td>2019-11-01 19:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-01 23:00:00</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>2019-11-01 23:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-30 11:00:00</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>2019-11-30 11:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-30 15:00:00</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>2019-11-30 15:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-30 19:00:00</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>2019-11-30 19:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-30 23:00:00</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>2019-11-30 23:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-30 03:00:00</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>2019-11-30 03:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Pb      Mg      Cu      Zn           daterange\n",
       "DATETIME                                                              \n",
       "2019-11-01 07:00:00  0.001  0.0058  0.0266  0.0266 2019-11-01 07:00:00\n",
       "2019-11-01 11:00:00  0.001  0.0049  0.0372  0.0372 2019-11-01 11:00:00\n",
       "2019-11-01 15:00:00  0.001  0.0050  0.0409  0.0409 2019-11-01 15:00:00\n",
       "2019-11-01 19:00:00  0.001  0.0055  0.0209  0.0209 2019-11-01 19:00:00\n",
       "2019-11-01 23:00:00  0.001  0.0062  0.0191  0.0191 2019-11-01 23:00:00\n",
       "...                    ...     ...     ...     ...                 ...\n",
       "2019-11-30 11:00:00  0.001  0.0046  0.0041  0.0041 2019-11-30 11:00:00\n",
       "2019-11-30 15:00:00  0.001  0.0042  0.0054  0.0054 2019-11-30 15:00:00\n",
       "2019-11-30 19:00:00  0.001  0.0047  0.0044  0.0044 2019-11-30 19:00:00\n",
       "2019-11-30 23:00:00  0.001  0.0059  0.0045  0.0045 2019-11-30 23:00:00\n",
       "2019-11-30 03:00:00  0.001  0.0056  0.0066  0.0066 2019-11-30 03:00:00\n",
       "\n",
       "[175 rows x 5 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfEL3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2019-11-01 07:00:00', '2019-11-01 19:00:00'], dtype='datetime64[ns]', name='DATETIME', freq=None)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfEL4.index[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FT_cycletimerange</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATETIME</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2019-11-01 07:00:00</td>\n",
       "      <td>2019-11-01 06:56:00 to 2019-11-01 07:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-01 19:00:00</td>\n",
       "      <td>2019-11-01 18:57:00 to 2019-11-01 19:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-01 23:00:00</td>\n",
       "      <td>2019-11-01 22:45:00 to 2019-11-01 23:07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-01 03:00:00</td>\n",
       "      <td>2019-11-01 02:44:00 to 2019-11-01 03:06:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-02 11:00:00</td>\n",
       "      <td>2019-11-02 10:42:00 to 2019-11-02 11:05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-29 03:00:00</td>\n",
       "      <td>2019-11-29 02:49:00 to 2019-11-29 03:11:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-30 11:00:00</td>\n",
       "      <td>2019-11-30 10:52:00 to 2019-11-30 11:13:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-30 15:00:00</td>\n",
       "      <td>2019-11-30 14:52:00 to 2019-11-30 15:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-30 23:00:00</td>\n",
       "      <td>2019-11-30 22:59:00 to 2019-11-30 23:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-30 03:00:00</td>\n",
       "      <td>2019-11-30 02:45:00 to 2019-11-30 03:07:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              FT_cycletimerange\n",
       "DATETIME                                                       \n",
       "2019-11-01 07:00:00  2019-11-01 06:56:00 to 2019-11-01 07:20:00\n",
       "2019-11-01 19:00:00  2019-11-01 18:57:00 to 2019-11-01 19:20:00\n",
       "2019-11-01 23:00:00  2019-11-01 22:45:00 to 2019-11-01 23:07:00\n",
       "2019-11-01 03:00:00  2019-11-01 02:44:00 to 2019-11-01 03:06:00\n",
       "2019-11-02 11:00:00  2019-11-02 10:42:00 to 2019-11-02 11:05:00\n",
       "...                                                         ...\n",
       "2019-11-29 03:00:00  2019-11-29 02:49:00 to 2019-11-29 03:11:00\n",
       "2019-11-30 11:00:00  2019-11-30 10:52:00 to 2019-11-30 11:13:00\n",
       "2019-11-30 15:00:00  2019-11-30 14:52:00 to 2019-11-30 15:15:00\n",
       "2019-11-30 23:00:00  2019-11-30 22:59:00 to 2019-11-30 23:20:00\n",
       "2019-11-30 03:00:00  2019-11-30 02:45:00 to 2019-11-30 03:07:00\n",
       "\n",
       "[117 rows x 1 columns]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfEL4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATETIME\n",
       "2019-11-01 03:00:00    2019-11-01 02:44:00 to 2019-11-01 03:06:00\n",
       "2019-11-01 07:00:00    2019-11-01 06:56:00 to 2019-11-01 07:20:00\n",
       "2019-11-01 11:00:00                                           NaN\n",
       "2019-11-01 15:00:00                                           NaN\n",
       "2019-11-01 19:00:00    2019-11-01 18:57:00 to 2019-11-01 19:20:00\n",
       "                                          ...                    \n",
       "2019-11-30 07:00:00                                           NaN\n",
       "2019-11-30 11:00:00    2019-11-30 10:52:00 to 2019-11-30 11:13:00\n",
       "2019-11-30 15:00:00    2019-11-30 14:52:00 to 2019-11-30 15:15:00\n",
       "2019-11-30 19:00:00                                           NaN\n",
       "2019-11-30 23:00:00    2019-11-30 22:59:00 to 2019-11-30 23:20:00\n",
       "Name: FT_cycletimerange, Length: 175, dtype: object"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfEL5['FT_cycletimerange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfEL5.to_excel(r'C:\\Users\\v.t.flores\\Documents\\20200116PM_datetimerangep.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Timestamp('2019-11-01 07:00:00'),\n",
       "  '2019-11-01 06:56:00 to 2019-11-01 07:20:00'),\n",
       " (Timestamp('2019-11-01 19:00:00'),\n",
       "  '2019-11-01 18:57:00 to 2019-11-01 19:20:00'),\n",
       " (Timestamp('2019-11-01 23:00:00'),\n",
       "  '2019-11-01 22:45:00 to 2019-11-01 23:07:00'),\n",
       " (Timestamp('2019-11-01 03:00:00'),\n",
       "  '2019-11-01 02:44:00 to 2019-11-01 03:06:00'),\n",
       " (Timestamp('2019-11-02 11:00:00'),\n",
       "  '2019-11-02 10:42:00 to 2019-11-02 11:05:00'),\n",
       " (Timestamp('2019-11-02 15:00:00'),\n",
       "  '2019-11-02 14:46:00 to 2019-11-02 15:08:00'),\n",
       " (Timestamp('2019-11-02 19:00:00'),\n",
       "  '2019-11-02 18:55:00 to 2019-11-02 19:17:00'),\n",
       " (Timestamp('2019-11-02 03:00:00'),\n",
       "  '2019-11-02 02:50:00 to 2019-11-02 03:12:00'),\n",
       " (Timestamp('2019-11-03 07:00:00'),\n",
       "  '2019-11-03 06:44:00 to 2019-11-03 07:08:00'),\n",
       " (Timestamp('2019-11-03 11:00:00'),\n",
       "  '2019-11-03 10:56:00 to 2019-11-03 11:18:00'),\n",
       " (Timestamp('2019-11-03 15:00:00'),\n",
       "  '2019-11-03 14:39:00 to 2019-11-03 15:02:00'),\n",
       " (Timestamp('2019-11-03 19:00:00'),\n",
       "  '2019-11-03 18:48:00 to 2019-11-03 19:10:00'),\n",
       " (Timestamp('2019-11-03 23:00:00'),\n",
       "  '2019-11-03 22:36:00 to 2019-11-03 23:00:00'),\n",
       " (Timestamp('2019-11-03 03:00:00'),\n",
       "  '2019-11-03 02:56:00 to 2019-11-03 03:20:00'),\n",
       " (Timestamp('2019-11-04 07:00:00'),\n",
       "  '2019-11-04 06:41:00 to 2019-11-04 07:05:00'),\n",
       " (Timestamp('2019-11-04 11:00:00'),\n",
       "  '2019-11-04 10:41:00 to 2019-11-04 11:05:00'),\n",
       " (Timestamp('2019-11-04 15:00:00'),\n",
       "  '2019-11-04 14:51:00 to 2019-11-04 15:16:00'),\n",
       " (Timestamp('2019-11-04 23:00:00'),\n",
       "  '2019-11-04 22:49:00 to 2019-11-04 23:14:00'),\n",
       " (Timestamp('2019-11-04 03:00:00'),\n",
       "  '2019-11-04 02:51:00 to 2019-11-04 03:14:00'),\n",
       " (Timestamp('2019-11-05 11:00:00'),\n",
       "  '2019-11-05 10:41:00 to 2019-11-05 11:04:00'),\n",
       " (Timestamp('2019-11-05 15:00:00'),\n",
       "  '2019-11-05 14:55:00 to 2019-11-05 15:19:00'),\n",
       " (Timestamp('2019-11-05 23:00:00'),\n",
       "  '2019-11-05 22:39:00 to 2019-11-05 23:03:00'),\n",
       " (Timestamp('2019-11-05 03:00:00'),\n",
       "  '2019-11-05 02:47:00 to 2019-11-05 03:11:00'),\n",
       " (Timestamp('2019-11-06 07:00:00'),\n",
       "  '2019-11-06 06:49:00 to 2019-11-06 07:15:00'),\n",
       " (Timestamp('2019-11-06 19:00:00'),\n",
       "  '2019-11-06 19:00:00 to 2019-11-06 19:27:00'),\n",
       " (Timestamp('2019-11-06 23:00:00'),\n",
       "  '2019-11-06 22:53:00 to 2019-11-06 23:19:00'),\n",
       " (Timestamp('2019-11-06 03:00:00'),\n",
       "  '2019-11-06 02:51:00 to 2019-11-06 03:15:00'),\n",
       " (Timestamp('2019-11-07 07:00:00'),\n",
       "  '2019-11-07 06:57:00 to 2019-11-07 07:25:00'),\n",
       " (Timestamp('2019-11-07 11:00:00'),\n",
       "  '2019-11-07 10:37:00 to 2019-11-07 11:09:00'),\n",
       " (Timestamp('2019-11-07 19:00:00'),\n",
       "  '2019-11-07 18:40:00 to 2019-11-07 19:01:00'),\n",
       " (Timestamp('2019-11-07 03:00:00'),\n",
       "  '2019-11-07 02:46:00 to 2019-11-07 03:12:00'),\n",
       " (Timestamp('2019-11-08 07:00:00'),\n",
       "  '2019-11-08 06:45:00 to 2019-11-08 07:09:00'),\n",
       " (Timestamp('2019-11-08 11:00:00'),\n",
       "  '2019-11-08 10:47:00 to 2019-11-08 11:10:00'),\n",
       " (Timestamp('2019-11-08 15:00:00'),\n",
       "  '2019-11-08 14:40:00 to 2019-11-08 15:04:00'),\n",
       " (Timestamp('2019-11-08 19:00:00'),\n",
       "  '2019-11-08 18:55:00 to 2019-11-08 19:20:00'),\n",
       " (Timestamp('2019-11-08 03:00:00'),\n",
       "  '2019-11-08 02:45:00 to 2019-11-08 03:11:00'),\n",
       " (Timestamp('2019-11-09 07:00:00'),\n",
       "  '2019-11-09 06:40:00 to 2019-11-09 07:03:00'),\n",
       " (Timestamp('2019-11-09 11:00:00'),\n",
       "  '2019-11-09 10:48:00 to 2019-11-09 11:14:00'),\n",
       " (Timestamp('2019-11-09 19:00:00'),\n",
       "  '2019-11-09 18:33:00 to 2019-11-09 19:01:00'),\n",
       " (Timestamp('2019-11-09 03:00:00'),\n",
       "  '2019-11-09 02:42:00 to 2019-11-09 03:07:00'),\n",
       " (Timestamp('2019-11-10 11:00:00'),\n",
       "  '2019-11-10 10:54:00 to 2019-11-10 11:22:00'),\n",
       " (Timestamp('2019-11-10 19:00:00'),\n",
       "  '2019-11-10 18:59:00 to 2019-11-10 19:18:00'),\n",
       " (Timestamp('2019-11-10 23:00:00'),\n",
       "  '2019-11-10 22:52:00 to 2019-11-10 23:15:00'),\n",
       " (Timestamp('2019-11-11 07:00:00'),\n",
       "  '2019-11-11 06:58:00 to 2019-11-11 07:22:00'),\n",
       " (Timestamp('2019-11-11 19:00:00'),\n",
       "  '2019-11-11 18:59:00 to 2019-11-11 19:22:00'),\n",
       " (Timestamp('2019-11-11 23:00:00'),\n",
       "  '2019-11-11 22:42:00 to 2019-11-11 23:06:00'),\n",
       " (Timestamp('2019-11-12 11:00:00'),\n",
       "  '2019-11-12 10:42:00 to 2019-11-12 11:04:00'),\n",
       " (Timestamp('2019-11-12 15:00:00'),\n",
       "  '2019-11-12 14:53:00 to 2019-11-12 15:14:00'),\n",
       " (Timestamp('2019-11-12 23:00:00'),\n",
       "  '2019-11-12 22:45:00 to 2019-11-12 23:09:00'),\n",
       " (Timestamp('2019-11-12 03:00:00'),\n",
       "  '2019-11-12 02:56:00 to 2019-11-12 03:19:00'),\n",
       " (Timestamp('2019-11-13 07:00:00'),\n",
       "  '2019-11-13 06:39:00 to 2019-11-13 07:03:00'),\n",
       " (Timestamp('2019-11-13 11:00:00'),\n",
       "  '2019-11-13 10:39:00 to 2019-11-13 11:02:00'),\n",
       " (Timestamp('2019-11-13 15:00:00'),\n",
       "  '2019-11-13 14:57:00 to 2019-11-13 15:16:00'),\n",
       " (Timestamp('2019-11-13 19:00:00'),\n",
       "  '2019-11-13 18:50:00 to 2019-11-13 19:13:00'),\n",
       " (Timestamp('2019-11-13 23:00:00'),\n",
       "  '2019-11-13 22:50:00 to 2019-11-13 23:14:00'),\n",
       " (Timestamp('2019-11-13 03:00:00'),\n",
       "  '2019-11-13 03:00:00 to 2019-11-13 03:23:00'),\n",
       " (Timestamp('2019-11-14 15:00:00'),\n",
       "  '2019-11-14 14:37:00 to 2019-11-14 15:00:00'),\n",
       " (Timestamp('2019-11-14 19:00:00'),\n",
       "  '2019-11-14 18:57:00 to 2019-11-14 19:20:00'),\n",
       " (Timestamp('2019-11-14 23:00:00'),\n",
       "  '2019-11-14 22:56:00 to 2019-11-14 23:17:00'),\n",
       " (Timestamp('2019-11-15 11:00:00'),\n",
       "  '2019-11-15 10:43:00 to 2019-11-15 11:07:00'),\n",
       " (Timestamp('2019-11-15 19:00:00'),\n",
       "  '2019-11-15 18:48:00 to 2019-11-15 19:10:00'),\n",
       " (Timestamp('2019-11-15 23:00:00'),\n",
       "  '2019-11-15 23:00:00 to 2019-11-15 23:23:00'),\n",
       " (Timestamp('2019-11-16 07:00:00'),\n",
       "  '2019-11-16 06:48:00 to 2019-11-16 07:10:00'),\n",
       " (Timestamp('2019-11-16 15:00:00'),\n",
       "  '2019-11-16 15:00:00 to 2019-11-16 15:22:00'),\n",
       " (Timestamp('2019-11-16 19:00:00'),\n",
       "  '2019-11-16 18:41:00 to 2019-11-16 19:02:00'),\n",
       " (Timestamp('2019-11-16 23:00:00'),\n",
       "  '2019-11-16 22:44:00 to 2019-11-16 23:06:00'),\n",
       " (Timestamp('2019-11-16 03:00:00'),\n",
       "  '2019-11-16 02:52:00 to 2019-11-16 03:14:00'),\n",
       " (Timestamp('2019-11-17 07:00:00'),\n",
       "  '2019-11-17 06:49:00 to 2019-11-17 07:12:00'),\n",
       " (Timestamp('2019-11-17 11:00:00'),\n",
       "  '2019-11-17 10:55:00 to 2019-11-17 11:17:00'),\n",
       " (Timestamp('2019-11-17 19:00:00'),\n",
       "  '2019-11-17 18:38:00 to 2019-11-17 19:00:00'),\n",
       " (Timestamp('2019-11-18 19:00:00'),\n",
       "  '2019-11-18 18:50:00 to 2019-11-18 19:10:00'),\n",
       " (Timestamp('2019-11-18 23:00:00'),\n",
       "  '2019-11-18 22:49:00 to 2019-11-18 23:10:00'),\n",
       " (Timestamp('2019-11-19 07:00:00'),\n",
       "  '2019-11-19 07:00:00 to 2019-11-19 07:21:00'),\n",
       " (Timestamp('2019-11-19 11:00:00'),\n",
       "  '2019-11-19 11:00:00 to 2019-11-19 11:16:00'),\n",
       " (Timestamp('2019-11-19 15:00:00'),\n",
       "  '2019-11-19 14:34:00 to 2019-11-19 15:00:00'),\n",
       " (Timestamp('2019-11-19 23:00:00'),\n",
       "  '2019-11-19 22:43:00 to 2019-11-19 23:04:00'),\n",
       " (Timestamp('2019-11-19 03:00:00'),\n",
       "  '2019-11-19 03:00:00 to 2019-11-19 03:18:00'),\n",
       " (Timestamp('2019-11-20 11:00:00'),\n",
       "  '2019-11-20 10:55:00 to 2019-11-20 11:17:00'),\n",
       " (Timestamp('2019-11-20 19:00:00'),\n",
       "  '2019-11-20 18:39:00 to 2019-11-20 19:00:00'),\n",
       " (Timestamp('2019-11-20 23:00:00'),\n",
       "  '2019-11-20 22:45:00 to 2019-11-20 23:06:00'),\n",
       " (Timestamp('2019-11-20 03:00:00'),\n",
       "  '2019-11-20 02:45:00 to 2019-11-20 03:07:00'),\n",
       " (Timestamp('2019-11-21 07:00:00'),\n",
       "  '2019-11-21 06:44:00 to 2019-11-21 07:06:00'),\n",
       " (Timestamp('2019-11-21 11:00:00'),\n",
       "  '2019-11-21 10:57:00 to 2019-11-21 11:19:00'),\n",
       " (Timestamp('2019-11-21 19:00:00'),\n",
       "  '2019-11-21 18:40:00 to 2019-11-21 19:00:00'),\n",
       " (Timestamp('2019-11-21 03:00:00'),\n",
       "  '2019-11-21 02:49:00 to 2019-11-21 03:10:00'),\n",
       " (Timestamp('2019-11-22 07:00:00'),\n",
       "  '2019-11-22 06:40:00 to 2019-11-22 07:02:00'),\n",
       " (Timestamp('2019-11-22 15:00:00'),\n",
       "  '2019-11-22 14:49:00 to 2019-11-22 15:11:00'),\n",
       " (Timestamp('2019-11-22 19:00:00'),\n",
       "  '2019-11-22 18:54:00 to 2019-11-22 19:17:00'),\n",
       " (Timestamp('2019-11-22 23:00:00'),\n",
       "  '2019-11-22 22:55:00 to 2019-11-22 23:16:00'),\n",
       " (Timestamp('2019-11-23 11:00:00'),\n",
       "  '2019-11-23 10:44:00 to 2019-11-23 11:05:00'),\n",
       " (Timestamp('2019-11-23 15:00:00'),\n",
       "  '2019-11-23 14:41:00 to 2019-11-23 15:02:00'),\n",
       " (Timestamp('2019-11-23 19:00:00'),\n",
       "  '2019-11-23 18:42:00 to 2019-11-23 19:04:00'),\n",
       " (Timestamp('2019-11-23 23:00:00'),\n",
       "  '2019-11-23 22:40:00 to 2019-11-23 23:03:00'),\n",
       " (Timestamp('2019-11-23 03:00:00'),\n",
       "  '2019-11-23 02:59:00 to 2019-11-23 03:24:00'),\n",
       " (Timestamp('2019-11-24 15:00:00'),\n",
       "  '2019-11-24 14:42:00 to 2019-11-24 15:03:00'),\n",
       " (Timestamp('2019-11-24 19:00:00'),\n",
       "  '2019-11-24 18:39:00 to 2019-11-24 19:00:00'),\n",
       " (Timestamp('2019-11-24 03:00:00'),\n",
       "  '2019-11-24 02:48:00 to 2019-11-24 03:11:00'),\n",
       " (Timestamp('2019-11-25 11:00:00'),\n",
       "  '2019-11-25 10:39:00 to 2019-11-25 11:01:00'),\n",
       " (Timestamp('2019-11-25 19:00:00'),\n",
       "  '2019-11-25 18:41:00 to 2019-11-25 19:02:00'),\n",
       " (Timestamp('2019-11-25 23:00:00'),\n",
       "  '2019-11-25 22:41:00 to 2019-11-25 23:02:00'),\n",
       " (Timestamp('2019-11-25 03:00:00'),\n",
       "  '2019-11-25 02:45:00 to 2019-11-25 03:09:00'),\n",
       " (Timestamp('2019-11-26 19:00:00'),\n",
       "  '2019-11-26 18:43:00 to 2019-11-26 19:02:00'),\n",
       " (Timestamp('2019-11-27 07:00:00'),\n",
       "  '2019-11-27 06:39:00 to 2019-11-27 07:00:00'),\n",
       " (Timestamp('2019-11-27 11:00:00'),\n",
       "  '2019-11-27 10:46:00 to 2019-11-27 11:08:00'),\n",
       " (Timestamp('2019-11-27 15:00:00'),\n",
       "  '2019-11-27 14:54:00 to 2019-11-27 15:18:00'),\n",
       " (Timestamp('2019-11-27 19:00:00'),\n",
       "  '2019-11-27 18:49:00 to 2019-11-27 19:13:00'),\n",
       " (Timestamp('2019-11-28 07:00:00'),\n",
       "  '2019-11-28 06:43:00 to 2019-11-28 07:08:00'),\n",
       " (Timestamp('2019-11-28 15:00:00'),\n",
       "  '2019-11-28 14:50:00 to 2019-11-28 15:15:00'),\n",
       " (Timestamp('2019-11-28 19:00:00'),\n",
       "  '2019-11-28 18:37:00 to 2019-11-28 19:03:00'),\n",
       " (Timestamp('2019-11-28 23:00:00'),\n",
       "  '2019-11-28 22:51:00 to 2019-11-28 23:15:00'),\n",
       " (Timestamp('2019-11-29 07:00:00'),\n",
       "  '2019-11-29 06:54:00 to 2019-11-29 07:16:00'),\n",
       " (Timestamp('2019-11-29 23:00:00'),\n",
       "  '2019-11-29 22:39:00 to 2019-11-29 23:01:00'),\n",
       " (Timestamp('2019-11-29 03:00:00'),\n",
       "  '2019-11-29 02:49:00 to 2019-11-29 03:11:00'),\n",
       " (Timestamp('2019-11-30 11:00:00'),\n",
       "  '2019-11-30 10:52:00 to 2019-11-30 11:13:00'),\n",
       " (Timestamp('2019-11-30 15:00:00'),\n",
       "  '2019-11-30 14:52:00 to 2019-11-30 15:15:00'),\n",
       " (Timestamp('2019-11-30 23:00:00'),\n",
       "  '2019-11-30 22:59:00 to 2019-11-30 23:20:00'),\n",
       " (Timestamp('2019-11-30 03:00:00'),\n",
       "  '2019-11-30 02:45:00 to 2019-11-30 03:07:00')]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Analys_indexList_Pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pb</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Cu</th>\n",
       "      <th>Zn</th>\n",
       "      <th>daterange</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATETIME</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2019-11-01 07:00:00</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0266</td>\n",
       "      <td>0.0266</td>\n",
       "      <td>2019-11-01 07:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-01 11:00:00</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0372</td>\n",
       "      <td>0.0372</td>\n",
       "      <td>2019-11-01 11:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-01 15:00:00</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0409</td>\n",
       "      <td>0.0409</td>\n",
       "      <td>2019-11-01 15:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-01 19:00:00</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0209</td>\n",
       "      <td>0.0209</td>\n",
       "      <td>2019-11-01 19:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-01 23:00:00</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>2019-11-01 23:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-30 11:00:00</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>2019-11-30 11:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-30 15:00:00</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>2019-11-30 15:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-30 19:00:00</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>2019-11-30 19:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-30 23:00:00</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>2019-11-30 23:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-30 03:00:00</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>2019-11-30 03:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Pb      Mg      Cu      Zn           daterange\n",
       "DATETIME                                                              \n",
       "2019-11-01 07:00:00  0.001  0.0058  0.0266  0.0266 2019-11-01 07:00:00\n",
       "2019-11-01 11:00:00  0.001  0.0049  0.0372  0.0372 2019-11-01 11:00:00\n",
       "2019-11-01 15:00:00  0.001  0.0050  0.0409  0.0409 2019-11-01 15:00:00\n",
       "2019-11-01 19:00:00  0.001  0.0055  0.0209  0.0209 2019-11-01 19:00:00\n",
       "2019-11-01 23:00:00  0.001  0.0062  0.0191  0.0191 2019-11-01 23:00:00\n",
       "...                    ...     ...     ...     ...                 ...\n",
       "2019-11-30 11:00:00  0.001  0.0046  0.0041  0.0041 2019-11-30 11:00:00\n",
       "2019-11-30 15:00:00  0.001  0.0042  0.0054  0.0054 2019-11-30 15:00:00\n",
       "2019-11-30 19:00:00  0.001  0.0047  0.0044  0.0044 2019-11-30 19:00:00\n",
       "2019-11-30 23:00:00  0.001  0.0059  0.0045  0.0045 2019-11-30 23:00:00\n",
       "2019-11-30 03:00:00  0.001  0.0056  0.0066  0.0066 2019-11-30 03:00:00\n",
       "\n",
       "[175 rows x 5 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfEL3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2019-11-01 00:11:00')"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfn11['startdate'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(0, len(rows_n)-1):\n",
    "    for j in range(rows_n[i], rows_n[i+1]):        \n",
    "        if TH01_UF_sheet['AD'+str(j)].value != None and type(TH01_UF_sheet['AD'+str(j)].value) == float: ##check if column is updated\n",
    "            if  type(TH01_UF_sheet['C'+str(j)].value) == datetime.datetime:\n",
    "                time_val = TH01_UF_sheet['C'+str(j)].value           \n",
    "                strdate = parse(str(time_val))\n",
    "                newtime = str(strdate).split(\" \")[1]\n",
    "                newdate = \"2019/11/\"+str(TH01_UF_sheet['B'+str(rows_n[i])].value)+' '+newtime\n",
    "            elif type(TH01_UF_sheet['C'+str(j)].value) == datetime.time:\n",
    "                time_val = TH01_UF_sheet['C'+str(j)].value           \n",
    "                strdate = str(time_val)\n",
    "                newdate = \"2019/11/\"+str(TH01_UF_sheet['B'+str(rows_n[i])].value)+' '+strdate               \n",
    "            timeList.append(parse(newdate))\n",
    "            Mg_val = TH01_UF_sheet['AD'+str(j)].value ##check if column and varname are updated\n",
    "            MgList.append(Mg_val) ##check if list title is updated\n",
    "Mg_df_list = list(zip(MgList, timeList[0:])) ##check if the list titles and the df list are updated"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
