{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an InterActive Graph of NTRL Lab Analysis Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from dateutil.parser import parse\n",
    "from itertools import compress\n",
    "from collections import OrderedDict\n",
    "from datetime import date\n",
    "import datetime\n",
    "import re\n",
    "from datetime import timedelta\n",
    "import openpyxl\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#used in the analysis results data. cleans up the sampling time entry\n",
    "def time_cleaner(x):\n",
    "    time_regex = re.compile(r'[0-8a-zA-Z:]', re.IGNORECASE| re.VERBOSE|re.DOTALL)\n",
    "    timeact = time_regex.findall(x)\n",
    "    newtime = ''.join(timeact)\n",
    "    t = parse(x)\n",
    "    new_str_time = str(t.hour)+':'+str(t.minute)+':'+str(t.second)\n",
    "    return new_str_time\n",
    "def ave_filler(dfname, colname):\n",
    "    dfcn = dfname[colname]\n",
    "    try:        \n",
    "        dfcn = pd.to_numeric(dfcn, errors='coerce')\n",
    "    except:\n",
    "        print('error found in' + str(colname))\n",
    "        pass\n",
    "    try:\n",
    "        dfname[colname] = dfcn.where(dfcn.notnull(), other=(dfcn.fillna(method='ffill') + dfcn.fillna(method='bfill'))/2)\n",
    "    except:\n",
    "        print('nan not fixed' + str(colname))   \n",
    "    return dfname\n",
    "def generate_df_from_analysis(workbookTab, col_sampleDate, col_sampleTime, col_analysis, col_title):\n",
    "    #get the start and end sample dates\n",
    "    Smpl_day_index = list()\n",
    "    Chem_Element_datelist = list()\n",
    "    Chem_Element_list = list()\n",
    "    Smpl_day_index = list()\n",
    "    Chem_Element_datelist = list()\n",
    "    Chem_Element_list = list()\n",
    "    plus_oneday_list = ['0:0:0', '1:0:0', '2:0:0', '3:0:0', '4:0:0', '5:0:0']\n",
    "    #gets the date day from the B column of the analysis file if there is value in the cell\n",
    "    for i in range(1, workbookTab.max_row):\n",
    "        if type(workbookTab[str(col_sampleDate) + str(i)].value) == int or type(workbookTab[str(col_sampleDate) + str(i)].value) == float:\n",
    "            Smpl_day_index.append(i)\n",
    "    #get the ending row that has date day\n",
    "    for j in range(1, workbookTab.max_row):\n",
    "        if type(workbookTab[str(col_sampleTime) + str(j)].value) == datetime.datetime:\n",
    "            smpl_end_index = j\n",
    "    for y in range(0, len(Smpl_day_index)):\n",
    "        if Smpl_day_index[y] != Smpl_day_index[-1]:      \n",
    "            for x in range(Smpl_day_index[y], Smpl_day_index[y+1]):\n",
    "                if workbookTab[str(col_analysis)+str(x)].value is None: \n",
    "                    pass\n",
    "                else:\n",
    "                    if time_cleaner(str(workbookTab[str(col_sampleTime)+str(x)].value)) in plus_oneday_list:\n",
    "                        date = str((currentmonthyr)+datetime.timedelta(workbookTab[str(col_sampleDate)+str(Smpl_day_index[y])].value))\\\n",
    "                        +' '+time_cleaner(str(workbookTab[str(col_sampleTime)+str(x)].value))\n",
    "                        Chem_Element_datelist.append(parse(date))  \n",
    "                        chem_element = workbookTab[str(col_analysis)+str(x)].value\n",
    "                        Chem_Element_list.append(chem_element)\n",
    "                    else:\n",
    "                        date = str((currentmonthyr)-datetime.timedelta(1)+datetime.timedelta(workbookTab[str(col_sampleDate)+str(Smpl_day_index[y])].value))\\\n",
    "                        +' '+time_cleaner(str(workbookTab[str(col_sampleTime)+str(x)].value))\n",
    "                        Chem_Element_datelist.append(parse(date))  \n",
    "                        chem_element = workbookTab[str(col_analysis)+str(x)].value\n",
    "                        Chem_Element_list.append(chem_element)\n",
    "\n",
    "        if Smpl_day_index[y] == Smpl_day_index[-1]:\n",
    "            for x in range(Smpl_day_index[y], smpl_end_index+1):\n",
    "                if workbookTab[str(col_analysis)+str(x)].value is None:   \n",
    "                    pass\n",
    "                else:\n",
    "                    if time_cleaner(str(workbookTab[str(col_sampleTime)+str(x)].value)) in plus_oneday_list:\n",
    "                        date = str((currentmonthyr)+datetime.timedelta(workbookTab[str(col_sampleDate)+str(Smpl_day_index[y])].value))\\\n",
    "                        +' '+time_cleaner(str(workbookTab[str(col_sampleTime)+str(x)].value))\n",
    "                        Chem_Element_datelist.append(parse(date))\n",
    "                        chem_element = workbookTab[str(col_analysis)+str(x)].value\n",
    "                        Chem_Element_list.append(chem_element)\n",
    "                    else:\n",
    "                        date = str((currentmonthyr)-datetime.timedelta(1)+datetime.timedelta(workbookTab[str(col_sampleDate)+str(Smpl_day_index[y])].value))\\\n",
    "                        +' '+time_cleaner(str(workbookTab[str(col_sampleTime)+str(x)].value))\n",
    "                        Chem_Element_datelist.append(parse(date))\n",
    "                        chem_element = workbookTab[str(col_analysis)+str(x)].value\n",
    "                        Chem_Element_list.append(chem_element)\n",
    "\n",
    "    Chem_Element_list_pair = list(zip(Chem_Element_list, Chem_Element_datelist[0:]))\n",
    "    Chem_Element_df = pd.DataFrame(Chem_Element_list_pair)\n",
    "    Chem_Element_df.columns = [col_title, 'DATETIME'] ##check if list title is updated\n",
    "    Chem_Element_df.set_index('DATETIME', inplace=True)\n",
    "\n",
    "    return Chem_Element_df\n",
    "\n",
    "def generate_add_trace(figname, df_elemental, axis_bool):\n",
    "    colname = df_elemental.columns[0]\n",
    "    figname.add_trace(go.Scatter(x=df_elemental.index, y=df_elemental[colname], name=colname), secondary_y=axis_bool,)\n",
    "#---------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabResults():\n",
    "    def __init__(self, monthyear, filePath):\n",
    "        #____monthyear format examle is datetime.date(2020,7,1)\n",
    "        #____filepath example is '\\\\thgobna001\\userdata\\THPAL\\...\\ANALYSIS RESULTS 2020\\7) July _2020.xlsx'\n",
    "        #____add r' at the start of the filepath to apply the regex that allows the use of the filepath as raw\n",
    "        #____sef.workbook is the uploaded excel workbook of the entire analysis files so it takes time to load\n",
    "        #____Create an instance of the workbook by giving it a varible name with the sample format: Jan_2020\n",
    "        \n",
    "        import openpyxl\n",
    "        import io\n",
    "        with open(filePath, \"rb\") as f:\n",
    "            in_mem_file = io.BytesIO(f.read())\n",
    "        \n",
    "        self.workbook = openpyxl.load_workbook(in_mem_file, data_only=True)\n",
    "        self.monthyear = monthyear   \n",
    "        \n",
    "    def generate_df_from_analysis(self, tabname, list_lab_index):\n",
    "        #____tabname is a string type name of the tab in the laboratory analysis excel file.\n",
    "        #____-------Example tabnames: '104PU01', '105TK03', '106TK01'\n",
    "        #____-------Inside these tabs are the specific analysis results done on the sample taken from the 'tabname' area .\n",
    "        #____list_lab_index is a list with the sample format is: ['B', 'C', 'E', '104_Pb']\n",
    "        #____-------the first letter 'B' is the column letter where the day of the month is written as integers 1,2,3..30\n",
    "        #____-------the second letter 'C' is the column letter where the sampling time is written; e.g. '7:00:00 AM'\n",
    "        #____-------the third letter 'E' is the column where the results of the specific analysis are listed\n",
    "        #____-------the last item in the list is the string you'll use as the new title; e.g. '104_Pb'\n",
    "        \n",
    "        workbookTab = self.workbook[tabname]\n",
    "        self.list_lab_index = list_lab_index\n",
    "        col_sampleDate = self.list_lab_index[0]\n",
    "        col_sampleTime = self.list_lab_index[1]\n",
    "        col_analysis = self.list_lab_index[2]\n",
    "        col_title = self.list_lab_index[3]\n",
    "        currentmonthyr = self.monthyear\n",
    "        \n",
    "        #get the start and end sample dates\n",
    "        Smpl_day_index = list()\n",
    "        Chem_Element_datelist = list()\n",
    "        Chem_Element_list = list()\n",
    "        Smpl_day_index = list()\n",
    "        Chem_Element_datelist = list()\n",
    "        Chem_Element_list = list()\n",
    "        plus_oneday_list = ['0:0:0', '1:0:0', '2:0:0', '3:0:0', '4:0:0', '5:0:0']\n",
    "        #gets the date day from the B column of the analysis file if there is value in the cell\n",
    "        for i in range(1, workbookTab.max_row):\n",
    "            if type(workbookTab[str(col_sampleDate) + str(i)].value) == int or type(workbookTab[str(col_sampleDate) + str(i)].value) == float:\n",
    "                Smpl_day_index.append(i)\n",
    "        #get the ending row that has date day\n",
    "        for j in range(1, workbookTab.max_row):\n",
    "            if type(workbookTab[str(col_sampleTime) + str(j)].value) == datetime.datetime:\n",
    "                smpl_end_index = j\n",
    "        for y in range(0, len(Smpl_day_index)):\n",
    "            if Smpl_day_index[y] != Smpl_day_index[-1]:      \n",
    "                for x in range(Smpl_day_index[y], Smpl_day_index[y+1]):\n",
    "                    if workbookTab[str(col_analysis)+str(x)].value is None: \n",
    "                        pass\n",
    "                    else:\n",
    "                        if time_cleaner(str(workbookTab[str(col_sampleTime)+str(x)].value)) in plus_oneday_list:\n",
    "                            date = str((currentmonthyr)+datetime.timedelta(workbookTab[str(col_sampleDate)+str(Smpl_day_index[y])].value))\\\n",
    "                            +' '+time_cleaner(str(workbookTab[str(col_sampleTime)+str(x)].value))\n",
    "                            Chem_Element_datelist.append(parse(date))  \n",
    "                            chem_element = workbookTab[str(col_analysis)+str(x)].value\n",
    "                            Chem_Element_list.append(chem_element)\n",
    "                        else:\n",
    "                            date = str((currentmonthyr)-datetime.timedelta(1)+datetime.timedelta(workbookTab[str(col_sampleDate)+str(Smpl_day_index[y])].value))\\\n",
    "                            +' '+time_cleaner(str(workbookTab[str(col_sampleTime)+str(x)].value))\n",
    "                            Chem_Element_datelist.append(parse(date))  \n",
    "                            chem_element = workbookTab[str(col_analysis)+str(x)].value\n",
    "                            Chem_Element_list.append(chem_element)\n",
    "\n",
    "            if Smpl_day_index[y] == Smpl_day_index[-1]:\n",
    "                for x in range(Smpl_day_index[y], smpl_end_index+1):\n",
    "                    if workbookTab[str(col_analysis)+str(x)].value is None:   \n",
    "                        pass\n",
    "                    else:\n",
    "                        if time_cleaner(str(workbookTab[str(col_sampleTime)+str(x)].value)) in plus_oneday_list:\n",
    "                            date = str((currentmonthyr)+datetime.timedelta(workbookTab[str(col_sampleDate)+str(Smpl_day_index[y])].value))\\\n",
    "                            +' '+time_cleaner(str(workbookTab[str(col_sampleTime)+str(x)].value))\n",
    "                            Chem_Element_datelist.append(parse(date))\n",
    "                            chem_element = workbookTab[str(col_analysis)+str(x)].value\n",
    "                            Chem_Element_list.append(chem_element)\n",
    "                        else:\n",
    "                            date = str((currentmonthyr)-datetime.timedelta(1)+datetime.timedelta(workbookTab[str(col_sampleDate)+str(Smpl_day_index[y])].value))\\\n",
    "                            +' '+time_cleaner(str(workbookTab[str(col_sampleTime)+str(x)].value))\n",
    "                            Chem_Element_datelist.append(parse(date))\n",
    "                            chem_element = workbookTab[str(col_analysis)+str(x)].value\n",
    "                            Chem_Element_list.append(chem_element)\n",
    "\n",
    "        Chem_Element_list_pair = list(zip(Chem_Element_list, Chem_Element_datelist[0:]))\n",
    "        Chem_Element_df = pd.DataFrame(Chem_Element_list_pair)\n",
    "        Chem_Element_df.columns = [col_title, 'DATETIME'] ##check if list title is updated\n",
    "        Chem_Element_df.set_index('DATETIME', inplace=True)\n",
    "\n",
    "        return Chem_Element_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#monthyear\n",
    "currentmonthyr_01 = datetime.date(2020,1,1)\n",
    "currentmonthyr_02 = datetime.date(2020,2,1)\n",
    "currentmonthyr_03 = datetime.date(2020,3,1)\n",
    "currentmonthyr_04 = datetime.date(2020,4,1)\n",
    "currentmonthyr_05 = datetime.date(2020,5,1)\n",
    "currentmonthyr_06 = datetime.date(2020,6,1)\n",
    "currentmonthyr_07 = datetime.date(2020,7,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filepath\n",
    "filepath_01 = r'\\\\thgobna001\\userdata\\THPAL\\Department\\TAGANITO\\SHARED\\AnalysisResult\\ANALYSIS RESULTS 2020\\JANUARY 2020\\1) JANUARY_2020.xlsx'\n",
    "filepath_02 = r'\\\\thgobna001\\userdata\\THPAL\\Department\\TAGANITO\\SHARED\\AnalysisResult\\ANALYSIS RESULTS 2020\\FEBRUARY 2020\\2) FEBRUARY _2020.xlsx'\n",
    "filepath_03 = r'\\\\thgobna001\\userdata\\THPAL\\Department\\TAGANITO\\SHARED\\AnalysisResult\\ANALYSIS RESULTS 2020\\MARCH 2020\\3) March _2020.xlsx'\n",
    "filepath_04 = r'\\\\thgobna001\\userdata\\THPAL\\Department\\TAGANITO\\SHARED\\AnalysisResult\\ANALYSIS RESULTS 2020\\APRIL 2020\\4) April _2020.xlsx'\n",
    "filepath_05 = r'\\\\thgobna001\\userdata\\THPAL\\Department\\TAGANITO\\SHARED\\AnalysisResult\\ANALYSIS RESULTS 2020\\MAY 2020\\5) MAY_2020.xlsx'\n",
    "filepath_06 = r'\\\\thgobna001\\userdata\\THPAL\\Department\\TAGANITO\\SHARED\\AnalysisResult\\ANALYSIS RESULTS 2020\\JUNE 2020\\6) June _2020.xlsx'\n",
    "filepath_07 = r'\\\\thgobna001\\userdata\\THPAL\\Department\\TAGANITO\\SHARED\\AnalysisResult\\ANALYSIS RESULTS 2020\\7) July _2020.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_lab_index for ntrl\n",
    "ntrl_Pb = ['B', 'C', 'E', '104_Pb']\n",
    "ntr_Zn =  ['B', 'C', 'F', '104_Zn']\n",
    "ntrl_Cu = ['B', 'C', 'G', '104_Cu']\n",
    "ntrl_Ni = ['B', 'C', 'H', '104_Ni']\n",
    "ntrl_Co = ['B', 'C', 'I', '104_Co']\n",
    "ntrl_Mn = ['B', 'C', 'K', '104_Mn']\n",
    "ntrl_Cr = ['B', 'C', 'L', '104_Cr']\n",
    "ntrl_Ca = ['B', 'C', 'M', '104_Ca']\n",
    "ntrl_Si = ['B', 'C', 'N', '104_Si']\n",
    "ntrl_Al = ['B', 'C', 'O', '104_Al']\n",
    "ntrl_Mg = ['B', 'C', 'P', '104_Mg']\n",
    "ntrl_Fe2 = ['B', 'C', 'R', '104_Fe2']\n",
    "ntrl_pH = ['B', 'C', 'BB', '104_pH60']\n",
    "ntrl_ORP = ['B', 'C', 'AJ', '104_ORP']\n",
    "ntrl_NTU = ['B', 'C', 'AN', '104_NTU']\n",
    "ntrl_FT = ['B', 'C', 'AW', '104_FT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one down\n"
     ]
    }
   ],
   "source": [
    "Jan_2020 = LabResults(currentmonthyr_01, filepath_01)\n",
    "print('one down')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NTRL January 2020\n",
    "Jan2020_ntrl_Pb_df = Jan_2020.generate_df_from_analysis('104PU01', ntrl_Pb)\n",
    "Jan2020_ntrl_Zn_df = Jan_2020.generate_df_from_analysis('104PU01', ntr_Zn)\n",
    "Jan2020_ntrl_Cu_df = Jan_2020.generate_df_from_analysis('104PU01', ntrl_Cu)\n",
    "Jan2020_ntrl_Ni_df = Jan_2020.generate_df_from_analysis('104PU01', ntrl_Ni)\n",
    "Jan2020_ntrl_Co_df = Jan_2020.generate_df_from_analysis('104PU01', ntrl_Co)\n",
    "Jan2020_ntrl_Mn_df = Jan_2020.generate_df_from_analysis('104PU01', ntrl_Mn)\n",
    "Jan2020_ntrl_Cr_df = Jan_2020.generate_df_from_analysis('104PU01', ntrl_Cr)\n",
    "Jan2020_ntrl_Ca_df = Jan_2020.generate_df_from_analysis('104PU01', ntrl_Ca)\n",
    "Jan2020_ntrl_Si_df = Jan_2020.generate_df_from_analysis('104PU01', ntrl_Si)\n",
    "Jan2020_ntrl_Al_df = Jan_2020.generate_df_from_analysis('104PU01', ntrl_Al)\n",
    "Jan2020_ntrl_Mg_df = Jan_2020.generate_df_from_analysis('104PU01', ntrl_Mg)\n",
    "Jan2020_ntrl_Fe2_df = Jan_2020.generate_df_from_analysis('104PU01', ntrl_Fe2)\n",
    "Jan2020_ntrl_pH_df = Jan_2020.generate_df_from_analysis('104PU01', ntrl_pH)\n",
    "Jan2020_ntrl_ORP_df = Jan_2020.generate_df_from_analysis('104PU01', ntrl_ORP)\n",
    "Jan2020_ntrl_NTU_df = Jan_2020.generate_df_from_analysis('104PU01', ntrl_NTU)\n",
    "Jan2020_ntrl_FT_df = Jan_2020.generate_df_from_analysis('104PU01', ntrl_FT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jan2020_ntrl_FT_df = January_2020.generate_df_from_analysis('105TK05', ntrl_FT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_lab_index for 105TK05\n",
    "deznTK05_Pb = ['B', 'C', 'E', '105TK05_Pb']\n",
    "deznTK05_Zn =  ['B', 'C', 'F', '105TK05_Zn']\n",
    "deznTK05_Cu = ['B', 'C', 'G', '105TK05_Cu']\n",
    "deznTK05_Ni = ['B', 'C', 'H', '105TK05_Ni']\n",
    "deznTK05_Co = ['B', 'C', 'I', '105TK05_Co']\n",
    "deznTK05_Fe2 = ['B', 'C', 'J', '105TK05_Fe']\n",
    "deznTK05_Mn = ['B', 'C', 'K', '105TK05_Mn']\n",
    "deznTK05_Cr = ['B', 'C', 'L', '105TK05_Cr']\n",
    "deznTK05_Ca = ['B', 'C', 'M', '105TK05_Ca']\n",
    "deznTK05_Si = ['B', 'C', 'N', '105TK05_Si']\n",
    "deznTK05_Al = ['B', 'C', 'O', '105TK05_Al']\n",
    "deznTK05_Mg = ['B', 'C', 'P', '105TK05_Mg']\n",
    "deznTK05_pH = ['B', 'C', 'AF', '105TK05_pH']\n",
    "deznTK05_ORP = ['B', 'C', 'AG', '105TK05_ORP']\n",
    "deznTK05_PS90 = ['B', 'C', 'AP', '105TK05_PS90']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#105TK05 January 2020\n",
    "Jan2020_df_deznTK05_Pb = January_2020.generate_df_from_analysis('105TK05', deznTK05_Pb)\n",
    "Jan2020_df_deznTK05_Zn = January_2020.generate_df_from_analysis('105TK05', deznTK05_Zn)\n",
    "Jan2020_df_deznTK05_Cu = January_2020.generate_df_from_analysis('105TK05', deznTK05_Cu)\n",
    "Jan2020_df_deznTK05_Ni = January_2020.generate_df_from_analysis('105TK05', deznTK05_Ni)\n",
    "Jan2020_df_deznTK05_Co = January_2020.generate_df_from_analysis('105TK05', deznTK05_Co)\n",
    "Jan2020_df_deznTK05_Fe2 = January_2020.generate_df_from_analysis('105TK05', deznTK05_Fe2)\n",
    "Jan2020_df_deznTK05_Mn = January_2020.generate_df_from_analysis('105TK05', deznTK05_Mn)\n",
    "Jan2020_df_deznTK05_Cr = January_2020.generate_df_from_analysis('105TK05', deznTK05_Cr)\n",
    "Jan2020_df_deznTK05_Ca = January_2020.generate_df_from_analysis('105TK05', deznTK05_Ca)\n",
    "Jan2020_df_deznTK05_Si = January_2020.generate_df_from_analysis('105TK05', deznTK05_Si)\n",
    "Jan2020_df_deznTK05_Al = January_2020.generate_df_from_analysis('105TK05', deznTK05_Al)\n",
    "Jan2020_df_deznTK05_Mg = January_2020.generate_df_from_analysis('105TK05', deznTK05_Mg)\n",
    "Jan2020_df_deznTK05_pH = January_2020.generate_df_from_analysis('105TK05', deznTK05_pH)\n",
    "Jan2020_df_deznTK05_ORP = January_2020.generate_df_from_analysis('105TK05', deznTK05_ORP)\n",
    "Jan2020_df_deznTK05_PS90 = January_2020.generate_df_from_analysis('105TK05', deznTK05_PS90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_lab_index for 105TK03\n",
    "deznTK03_Zn = ['B', 'C', 'D', '105TK03_Zn']\n",
    "deznTK03_Zn_change =  ['B', 'C', 'BB', '105TK03_Zn_Change_Ratio']\n",
    "deznTK03_TK05_Zn = ['B', 'C', 'BD', '105TK05_Zn']\n",
    "deznTK03_TK01_Zn = ['B', 'C', 'BE', '106TK01_Zn']\n",
    "deznTK03_Zn_Ni = ['B', 'C', 'BF', '106TK01_Zn/Ni']\n",
    "deznTK03_Zn_Droprate = ['B', 'C', 'BG', '106TK01_Zn_DropRate']\n",
    "deznTK03_VE04Zn_prcnt = ['B', 'C', 'BH', '106VE04_%Zn']\n",
    "deznTK03_TH01Zn_prcnt = ['B', 'C', 'BI', '106TH01_%Zn']\n",
    "deznTK03_NTRL_Ni = ['B', 'C', 'BJ', '104PU01_Ni'] #not true for january 2020 resulst\n",
    "deznTK03_TK05_Ni = ['B', 'C', 'BK', '105TK05_Ni'] #not true for january 2020 results\n",
    "deznTK03_Ni_Loss_TK05 = ['B', 'C', 'BL', 'Ni_Loss_TK05'] #not true for january 2020 results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#105TK03 January 2020\n",
    "Jan2020_df_deznTK03_Zn = January_2020.generate_df_from_analysis('105TK03', deznTK03_Zn)\n",
    "Jan2020_df_deznTK03_Zn_change = January_2020.generate_df_from_analysis('105TK03', deznTK03_Zn_change)\n",
    "Jan2020_df_deznTK03_TK05_Zn = January_2020.generate_df_from_analysis('105TK03', deznTK03_TK05_Zn)\n",
    "Jan2020_df_deznTK03_TK01_Zn = January_2020.generate_df_from_analysis('105TK03', deznTK03_TK01_Zn)\n",
    "Jan2020_df_deznTK03_Zn_Ni = January_2020.generate_df_from_analysis('105TK03', deznTK03_Zn_Ni)\n",
    "Jan2020_df_deznTK03_Zn_Droprate = January_2020.generate_df_from_analysis('105TK03', deznTK03_Zn_Droprate)\n",
    "Jan2020_df_deznTK03_VE04Zn_prcnt = January_2020.generate_df_from_analysis('105TK03', deznTK03_VE04Zn_prcnt)\n",
    "Jan2020_df_deznTK03_TH01Zn_prcnt = January_2020.generate_df_from_analysis('105TK03', deznTK03_TH01Zn_prcnt)\n",
    "\n",
    "#Jan2020_df_deznTK03_NTRL_Ni = January_2020.generate_df_from_analysis('105TK03', deznTK03_NTRL_Ni)\n",
    "#Jan2020_df_deznTK03_TK05_Ni = January_2020.generate_df_from_analysis('105TK03', deznTK03_TK05_Ni)\n",
    "#Jan2020_df_deznTK03_Ni_Loss_TK05 = January_2020.generate_df_from_analysis('105TK03', deznTK03_Ni_Loss_TK05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------\n",
    "#105TK03\n",
    "DeZn_TK03 = wb1['105TK03']\n",
    "DeZn_TK03_105TK03_Zn_df = generate_df_from_analysis(DeZn_TK03, 'B', 'C', 'D', '105TK03_Zn')\n",
    "DeZn_TK03_105TK03_Zn_Change_Ratio_df = generate_df_from_analysis(DeZn_TK03, 'B', 'C', 'BB', '105TK03_Zn_Change_Ratio')\n",
    "DeZn_TK03_105TK05_Zn_df = generate_df_from_analysis(DeZn_TK03, 'B', 'C', 'BD', '105TK05_Zn')\n",
    "DeZn_TK03_106TK01_Zn_df = generate_df_from_analysis(DeZn_TK03, 'B', 'C', 'BE', '106TK01_Zn')\n",
    "DeZn_TK03_106TK01_ZnNi_df = generate_df_from_analysis(DeZn_TK03, 'B', 'C', 'BF', '106TK01_Zn/Ni')\n",
    "DeZn_TK03_106TK01_Zn_DropRate_df = generate_df_from_analysis(DeZn_TK03, 'B', 'C', 'BG', '106TK01_Zn_DropRate')\n",
    "DeZn_TK03_106VE04_Znprcnt_df = generate_df_from_analysis(DeZn_TK03, 'B', 'C', 'BH', '106VE04_%Zn')\n",
    "DeZn_TK03_106TH01_Znprcnt_df = generate_df_from_analysis(DeZn_TK03, 'B', 'C', 'BI', '106TH01_%Zn')\n",
    "DeZn_TK03_104PU01_Ni_df = generate_df_from_analysis(DeZn_TK03, 'B', 'C', 'BJ', '104PU01_Ni')\n",
    "DeZn_TK03_105TK05_Ni_df = generate_df_from_analysis(DeZn_TK03, 'B', 'C', 'BK', '105TK05_Ni')\n",
    "DeZn_TK03_Ni_Loss_TK05_df = generate_df_from_analysis(DeZn_TK03, 'B', 'C', 'BL', 'Ni_Loss_TK05')\n",
    "\n",
    "for i in range(0,len(DeZn_TK03_104PU01_Ni_df)):\n",
    "    if DeZn_TK03_104PU01_Ni_df['104PU01_Ni'][i] == 0:\n",
    "        DeZn_TK03_104PU01_Ni_df['104PU01_Ni'][i] = np.nan\n",
    "        \n",
    "#105TK05 Ni\n",
    "for i in range(0,len(DeZn_TK03_105TK05_Ni_df)):\n",
    "    if DeZn_TK03_105TK05_Ni_df['105TK05_Ni'][i] == 0:\n",
    "        DeZn_TK03_105TK05_Ni_df['105TK05_Ni'][i] = np.nan\n",
    "\n",
    "#105TK05 Ni Loss\n",
    "for i in range(0,len(DeZn_TK03_Ni_Loss_TK05_df)):\n",
    "    if DeZn_TK03_Ni_Loss_TK05_df['Ni_Loss_TK05'][i] == 0:\n",
    "        DeZn_TK03_Ni_Loss_TK05_df['Ni_Loss_TK05'][i] = np.nan         \n",
    "        \n",
    "#105TK05 Zn\n",
    "for i in range(0,len(DeZn_TK03_105TK05_Zn_df)):\n",
    "    if DeZn_TK03_105TK05_Zn_df['105TK05_Zn'][i] == 0:\n",
    "        DeZn_TK03_105TK05_Zn_df['105TK05_Zn'][i] = np.nan    \n",
    "        \n",
    "#106TK01 Zn\n",
    "for i in range(0,len(DeZn_TK03_106TK01_Zn_df)):\n",
    "    if DeZn_TK03_106TK01_Zn_df['106TK01_Zn'][i] == 0:\n",
    "        DeZn_TK03_106TK01_Zn_df['106TK01_Zn'][i] = np.nan      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------\n",
    "DeZn_FT01 = wb1['105FT01']\n",
    "FT01A_Zn_df = generate_df_from_analysis(DeZn_FT01, 'B', 'C', 'D', 'Zn')\n",
    "FT01B_Zn_df = generate_df_from_analysis(DeZn_FT01, 'B', 'C', 'E', 'Zn')\n",
    "FT01C_Zn_df = generate_df_from_analysis(DeZn_FT01, 'B', 'C', 'F', 'Zn')\n",
    "FT01D_Zn_df = generate_df_from_analysis(DeZn_FT01, 'B', 'C', 'G', 'Zn')\n",
    "FT01E_Zn_df = generate_df_from_analysis(DeZn_FT01, 'B', 'C', 'H', 'Zn')\n",
    "FT01F_Zn_df = generate_df_from_analysis(DeZn_FT01, 'B', 'C', 'I', 'Zn')\n",
    "\n",
    "FT01A_ntu_df = generate_df_from_analysis(DeZn_FT01, 'B', 'C', 'J', 'ntu')\n",
    "FT01B_ntu_df = generate_df_from_analysis(DeZn_FT01, 'B', 'C', 'K', 'ntu')\n",
    "FT01C_ntu_df = generate_df_from_analysis(DeZn_FT01, 'B', 'C', 'L', 'ntu')\n",
    "FT01D_ntu_df = generate_df_from_analysis(DeZn_FT01, 'B', 'C', 'M', 'ntu')\n",
    "FT01E_ntu_df = generate_df_from_analysis(DeZn_FT01, 'B', 'C', 'N', 'ntu')\n",
    "FT01F_ntu_df = generate_df_from_analysis(DeZn_FT01, 'B', 'C', 'O', 'ntu')\n",
    "\n",
    "FT01A_ZDR_df = generate_df_from_analysis(DeZn_FT01, 'B', 'C', 'J', 'Zn_dr')\n",
    "FT01B_ZDR_df = generate_df_from_analysis(DeZn_FT01, 'B', 'C', 'K', 'Zn_dr')\n",
    "FT01C_ZDR_df = generate_df_from_analysis(DeZn_FT01, 'B', 'C', 'L', 'Zn_dr')\n",
    "FT01D_ZDR_df = generate_df_from_analysis(DeZn_FT01, 'B', 'C', 'M', 'Zn_dr')\n",
    "FT01E_ZDR_df = generate_df_from_analysis(DeZn_FT01, 'B', 'C', 'N', 'Zn_dr')\n",
    "FT01F_ZDR_df = generate_df_from_analysis(DeZn_FT01, 'B', 'C', 'O', 'Zn_dr')\n",
    "\n",
    "A = FT01A_Zn_df.join(FT01A_ntu_df, how='outer').join(FT01A_ZDR_df, how='outer')\n",
    "A['Filter'] = 'FT01A'\n",
    "A.reset_index(inplace=True)\n",
    "\n",
    "B = FT01B_Zn_df.join(FT01B_ntu_df, how='outer').join(FT01B_ZDR_df, how='outer')\n",
    "B['Filter'] = 'FT01B'\n",
    "B.reset_index(inplace=True)\n",
    "\n",
    "C = FT01C_Zn_df.join(FT01C_ntu_df, how='outer').join(FT01C_ZDR_df, how='outer')\n",
    "C['Filter'] = 'FT01C'\n",
    "C.reset_index(inplace=True)\n",
    "\n",
    "D = FT01A_Zn_df.join(FT01D_ntu_df, how='outer').join(FT01D_ZDR_df, how='outer')\n",
    "D['Filter'] = 'FT01D'\n",
    "D.reset_index(inplace=True)\n",
    "\n",
    "E = FT01E_Zn_df.join(FT01E_ntu_df, how='outer').join(FT01E_ZDR_df, how='outer')\n",
    "E['Filter'] = 'FT01E'\n",
    "E.reset_index(inplace=True)\n",
    "\n",
    "F = FT01F_Zn_df.join(FT01F_ntu_df, how='outer').join(FT01F_ZDR_df, how='outer')\n",
    "F['Filter'] = 'FT01F'\n",
    "F.reset_index(inplace=True)\n",
    "AtoF = A.append(B, ignore_index =True).append(C, ignore_index = True).append(D, ignore_index=True).append(E, ignore_index=True).append(F, ignore_index=True)\n",
    "AtoF.interpolate(method='linear', limit_direction='forward', axis=0)\n",
    "AtoF.dropna(inplace=True)\n",
    "\n",
    "#-----------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 2020-08-01 10:03:01.322545\n",
      "Done  2020-08-01 10:03:07.511968\n",
      "VE04 PRED part Done 2020-08-01 10:03:30.436649\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#fill the nan values with the average of surrounding values\n",
    "for i in range(0, len(df_main.columns)):\n",
    "    #print(i, df_main.columns[i])\n",
    "    ave_filler(df_main, df_main.columns[i])\n",
    "df_main = df_main.fillna(method='bfill')\n",
    "\n",
    "df_main2 = df_main[['104_Pb', '104_Zn', '104_Cu', '104_Ni', '104_Co', '104_Mn',\n",
    "       '104_Cr', '104_Ca', '104_Si', '104_Al', '104_Mg', '104_Fe2', '104_pH',\n",
    "       '104_ORP',]]\n",
    "df_main2 = df_main2.dropna(how='any')\n",
    "\n",
    "zn_drop_lst = list()\n",
    "datelist = list()\n",
    "for j in range(0, len(df_main2)):\n",
    "    zn_drop = 0\n",
    "    for i in range(0, len(df_main2.iloc[j])):\n",
    "        #print(df_main2.iloc[j][i], \" * \" ,coeff_Zn_drop['Zn_drop'][i])\n",
    "        temp_product = df_main2.iloc[j][i] * coeff_Zn_drop['Zn_drop'][i]\n",
    "        zn_drop = zn_drop + temp_product\n",
    "    zn_drop_new = zn_drop + lm_Zndrop.intercept_\n",
    "    zn_drop_lst.append(zn_drop_new)\n",
    "    datelist.append(df_main2.index[j])\n",
    "zn_drop_and_date_lst = list(zip(datelist, zn_drop_lst))\n",
    "df_zn_drop_and_date = pd.DataFrame(zn_drop_and_date_lst)\n",
    "df_zn_drop_and_date = df_zn_drop_and_date.set_index(0)\n",
    "df_zn_drop_and_date['Zn_drop_Pred'] = df_zn_drop_and_date[1]\n",
    "\n",
    "# generates a dataframe for each column in the excel file\n",
    "MS_106TK01 = generate_df_from_analysis(MS_lab, 'B', 'C', 'BD', 'Zn_drop_ACT')\n",
    "pd.to_numeric(MS_106TK01[\"Zn_drop_ACT\"], errors='coerce')\n",
    "for i in range(1, len(MS_106TK01.Zn_drop_ACT)):\n",
    "    try:\n",
    "        if type(MS_106TK01.Zn_drop_ACT[i]) == str:\n",
    "            print(i, MS_106TK01.Zn_drop_ACT[i])\n",
    "            MS_106TK01.drop(MS_106TK01.index[i], inplace=True)\n",
    "            print(i, MS_106TK01.Zn_drop_ACT[i])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print('Done ', datetime.datetime.now())\n",
    "y = df_zn_drop_and_date['Zn_drop_Pred']\n",
    "MS_y = MS_106TK01[\"Zn_drop_ACT\"]*100\n",
    "\n",
    "y_Pb_ntrl = df_main['104_Pb']\n",
    "y_Zn_ntrl = df_main['104_Zn']\n",
    "y_Cu_ntrl = df_main['104_Cu']\n",
    "y_Ni_ntrl = df_main['104_Ni']\n",
    "y_Co_ntrl = df_main['104_Co']\n",
    "y_Mn_ntrl = df_main['104_Mn']\n",
    "y_Cr_ntrl = df_main['104_Cr']\n",
    "y_Ca_ntrl = df_main['104_Ca']\n",
    "y_Si_ntrl = df_main['104_Si']\n",
    "y_Al_ntrl = df_main['104_Al']\n",
    "y_Mg_ntrl = df_main['104_Mg']\n",
    "y_Fe2_ntrl = df_main['104_Fe2']\n",
    "y_pH_ntrl = df_main['104_pH']\n",
    "y_ORP_ntrl = df_main['104_ORP']\n",
    "\n",
    "\n",
    "zn_drop_predictions = MS_106TK01.join(df_zn_drop_and_date, how ='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####-------------------Space for the 106TK01 and 106VE04 data to plot-----------------------------------------\n",
    "# generates a dataframe for each column in the Analysis excel file 104PU01\n",
    "MS_TK01_Pb_df = generate_df_from_analysis(MS_lab, 'B', 'C', 'E', '106TK01_Pb')\n",
    "MS_TK01_Zn_df = generate_df_from_analysis(MS_lab, 'B', 'C', 'F', '106TK01_Zn')\n",
    "MS_TK01_Cu_df = generate_df_from_analysis(MS_lab, 'B', 'C', 'G', '106TK01_Cu')\n",
    "MS_TK01_Ni_df = generate_df_from_analysis(MS_lab, 'B', 'C', 'H', '106TK01_Ni')\n",
    "MS_TK01_Co_df = generate_df_from_analysis(MS_lab, 'B', 'C', 'I', '106TK01_Co')\n",
    "MS_TK01_Fe_df = generate_df_from_analysis(MS_lab, 'B', 'C', 'J', '106TK01_Fe')\n",
    "MS_TK01_Mn_df = generate_df_from_analysis(MS_lab, 'B', 'C', 'K', '106TK01_Mn')\n",
    "MS_TK01_Cr_df = generate_df_from_analysis(MS_lab, 'B', 'C', 'L', '106TK01_Cr')\n",
    "MS_TK01_Ca_df = generate_df_from_analysis(MS_lab, 'B', 'C', 'M', '106TK01_Ca')\n",
    "MS_TK01_Si_df = generate_df_from_analysis(MS_lab, 'B', 'C', 'N', '106TK01_Si')\n",
    "MS_TK01_Al_df = generate_df_from_analysis(MS_lab, 'B', 'C', 'O', '106TK01_Al')\n",
    "MS_TK01_Mg_df = generate_df_from_analysis(MS_lab, 'B', 'C', 'P', '106TK01_Mg')\n",
    "MS_TK01_pH_df = generate_df_from_analysis(MS_lab, 'B', 'C', 'AH', '106TK01_pH')\n",
    "MS_TK01_ORP_df = generate_df_from_analysis(MS_lab, 'B', 'C', 'AI', '106_ORP')\n",
    "MS_TK01_ZnNi_df = generate_df_from_analysis(MS_lab, 'B', 'C', 'BC', '106_Zn/Ni')\n",
    "\n",
    "MS_TK01_PbZn = MS_TK01_Pb_df.join(MS_TK01_Zn_df, how='outer')\n",
    "MS_TK01_CuNi = MS_TK01_Cu_df.join(MS_TK01_Ni_df, how='outer')\n",
    "MS_TK01_Co = MS_TK01_Co_df\n",
    "MS_TK01_FeMn = MS_TK01_Fe_df.join(MS_TK01_Mn_df, how='outer')\n",
    "MS_TK01_CaCr = MS_TK01_Cr_df.join(MS_TK01_Ca_df, how='outer')\n",
    "MS_TK01_AlSi = MS_TK01_Si_df.join(MS_TK01_Al_df, how='outer')\n",
    "MS_TK01_pHMg = MS_TK01_Mg_df.join(MS_TK01_pH_df, how='outer')\n",
    "MS_TK01_ZnNiORP = MS_TK01_ORP_df.join(MS_TK01_ZnNi_df, how='outer')\n",
    "#--------------\n",
    "MS_TK01_PbZnCuNi = MS_TK01_PbZn.join(MS_TK01_CuNi, how='outer')\n",
    "MS_TK01_CoFeMnCr = MS_TK01_Co.join(MS_TK01_FeMn, how='outer')\n",
    "MS_TK01_CaSiAlMg = MS_TK01_CaCr.join(MS_TK01_AlSi, how='outer')\n",
    "MS_TK01_Fe2pHORP = MS_TK01_pHMg.join(MS_TK01_ZnNiORP, how='outer')\n",
    "\n",
    "MS_TK01_PbZnCuNiCoFeMnCr = MS_TK01_PbZnCuNi.join(MS_TK01_CoFeMnCr, how='outer')\n",
    "MS_TK01_CaSiAlMgFe2Fe3pHORP = MS_TK01_CaSiAlMg.join(MS_TK01_Fe2pHORP, how='outer')\n",
    "\n",
    "MS_TK01_PbZnCuNiCoFeMnCrCaSiAlMgFe2Fe3pHORP = MS_TK01_PbZnCuNiCoFeMnCr.join(MS_TK01_CaSiAlMgFe2Fe3pHORP, how='outer')\n",
    "df_main_106TK01 = MS_TK01_PbZnCuNiCoFeMnCrCaSiAlMgFe2Fe3pHORP\n",
    "#--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generates a dataframe for each column in the Analysis excel file 106VE04\n",
    "MS_VE04_Ni_soln_df = generate_df_from_analysis(MS_VE04_lab, 'B', 'C', 'D', '106VE04_Ni_soln')\n",
    "MS_VE04_Pb_df = generate_df_from_analysis(MS_VE04_lab, 'B', 'C', 'S', '106VE04_Pb')\n",
    "MS_VE04_Zn_df = generate_df_from_analysis(MS_VE04_lab, 'B', 'C', 'T', '106VE04_Zn')\n",
    "MS_VE04_Cu_df = generate_df_from_analysis(MS_VE04_lab, 'B', 'C', 'U', '106VE04_Cu')\n",
    "MS_VE04_Ni_df = generate_df_from_analysis(MS_VE04_lab, 'B', 'C', 'V', '106VE04_Ni')\n",
    "MS_VE04_Co_df = generate_df_from_analysis(MS_VE04_lab, 'B', 'C', 'W', '106VE04_Co')\n",
    "MS_VE04_Fe_df = generate_df_from_analysis(MS_VE04_lab, 'B', 'C', 'X', '106VE04_Fe')\n",
    "MS_VE04_Mn_df = generate_df_from_analysis(MS_VE04_lab, 'B', 'C', 'Y', '106VE04_Mn')\n",
    "MS_VE04_Cr_df = generate_df_from_analysis(MS_VE04_lab, 'B', 'C', 'Z', '106VE04_Cr')\n",
    "MS_VE04_Ca_df = generate_df_from_analysis(MS_VE04_lab, 'B', 'C', 'AA', '106VE04_Ca')\n",
    "MS_VE04_Si_df = generate_df_from_analysis(MS_VE04_lab, 'B', 'C', 'AB', '106VE04_Si')\n",
    "MS_VE04_Al_df = generate_df_from_analysis(MS_VE04_lab, 'B', 'C', 'AC', '106VE04_Al')\n",
    "MS_VE04_Mg_df = generate_df_from_analysis(MS_VE04_lab, 'B', 'C', 'AD', '106VE04_Mg')\n",
    "MS_VE04_S_df = generate_df_from_analysis(MS_VE04_lab, 'B', 'C', 'AE', '106VE04_S')\n",
    "MS_VE04_pH_df = generate_df_from_analysis(MS_VE04_lab, 'B', 'C', 'AG', '106VE04_pH')\n",
    "MS_VE04_ORP_df = generate_df_from_analysis(MS_VE04_lab, 'B', 'C', 'AH', '106VE04_ORP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####-------------------Space for the 106TK01 and 106VE04 data to plot------------------------------------------\n",
    "#####---------------------Pidaat and Ni recovery calc\n",
    "df_Pi = pd.read_excel(r'C:\\Users\\v.t.flores\\Documents\\MS Flow1.xlsx', sheet_name='PiData_MS FLOW', index_col=False)\n",
    "#Drop the row[1]\n",
    "df_Pi = df_Pi.drop(df_Pi.index[0])\n",
    "#Step2: Parse the DATETIME column\n",
    "df_Pi['DATETIME'] = df_Pi['DATETIME'].apply(lambda x: parse(str(x)))\n",
    "df_Pi.set_index('DATETIME', inplace=True)\n",
    "df_comb = df_Pi\n",
    "for i in df_comb.columns:\n",
    "    df_comb[i] = pd.to_numeric(df_comb[i], errors='coerce')\n",
    "df_comb['MS_Flow'] = np.where(df_comb['MS_FLOW_A']>df_comb['MS_FLOW_B'], df_comb['MS_FLOW_A'], df_comb['MS_FLOW_B'])\n",
    "df_comb['Operation_Load'] = df_comb['MS_Flow']*100/1600\n",
    "df_comb = df_comb[['MS_Flow', 'Operation_Load']]\n",
    "dfn = df_comb['Operation_Load']\n",
    "Ni = MS_TK01_Ni_df.join(MS_TK01_Fe_df, how= 'outer')\n",
    "pHNiSoln = MS_TK01_pH_df.join(MS_VE04_Ni_soln_df, how= 'outer')\n",
    "df_3 = Ni.join(pHNiSoln, how='outer')\n",
    "df_4 = df_3.join(dfn, how='outer')\n",
    "df_5 = df_4.interpolate(method='linear', limit_direction='forward', axis=0)\n",
    "df_5 = df_5.dropna(how='any')\n",
    "df_5['Ni_recovery'] = (df_5['106TK01_Ni']-df_5['106VE04_Ni_soln'])*100/df_5['106TK01_Ni']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------------------------------------------------#\n",
    "#---------------------Code for predicting the 106VE04 Ni soln by applying the coefficients  from RidgeRegression----------#\n",
    "\n",
    "#----Importing the Pi data for MS flow, rec gas, feed temp\n",
    "\n",
    "df_MSPi = pd.read_excel(r'C:\\Users\\v.t.flores\\Documents\\MS Flow1.xlsx', sheet_name='PiData_MS FLOW', index_col=False)\n",
    "\n",
    "#------------------Drop the row[0]. This is the title tag use in the pi datalink. We don't need it in pandas df.\n",
    "#------------------What remain are the column title and the rest of the rows of data.\n",
    "\n",
    "df_MSPi = df_MSPi.drop(df_MSPi.index[0])\n",
    "\n",
    "#Step2: Parse the DATETIME column\n",
    "df_MSPi['DATETIME'] = df_MSPi['DATETIME'].apply(lambda x: parse(str(x)))\n",
    "df_MSPi.set_index('DATETIME', inplace=True)\n",
    "df_MSPi = df_MSPi\n",
    "\n",
    "# Step3: Convert each column to numeric to handle nan values and other comments like 'No data...'. Convering to numeric\n",
    "#------ converts them into a NaN value that pandas understands.\n",
    "for i in df_MSPi.columns:\n",
    "    df_MSPi[i] = pd.to_numeric(df_MSPi[i], errors='coerce')\n",
    "\n",
    "# Step4: Select which FT is online based on their flowrates. The one with the greater value is online.\n",
    "\n",
    "df_MSPi['MS_Flow'] = np.where(df_MSPi['MS_FLOW_A']>df_MSPi['MS_FLOW_B'], df_MSPi['MS_FLOW_A'], df_MSPi['MS_FLOW_B'])\n",
    "\n",
    "\n",
    "# Step5: Selec the three rows for MS flow, feed temp, rec gas. Then put them in a single dataframe.\n",
    "df_MSPi_1 = df_MSPi[['MS_Flow', 'MS_FEED_TEMP', 'REC_GAS']]\n",
    "\n",
    "#-------Get the columns for 106TK01 lab resulsts on MG, pH, Ni, Fe\n",
    "df_VE04_Ni_pred = df_main_106TK01[['106TK01_Mg', '106TK01_pH', '106TK01_Ni', '106TK01_Fe']]\n",
    "df_VE04Ni_MSpi = df_MSPi_1.join(df_VE04_Ni_pred, how='outer')\n",
    "df_VE04Ni_MSpi = df_VE04Ni_MSpi.join(MS_VE04_Ni_soln_df, how='outer')\n",
    "\n",
    "# Step6: Create a dictionary for the regression coefficients.\n",
    "VE04_Ni_pred_coef_ = {0: 0.0000564586689, 1: -0.00439535054, 2: -0.0000177104562, \n",
    "                     3: -0.000172540353, 4:-0.00566003668, 5:0.0479078308, 6:-0.00113562602}\n",
    "VE04_Ni_pred_intrcpt_ = 0.167293627122493\n",
    "\n",
    "# Step7: Create columns for each of the coefficients.\n",
    "df_VE04Ni_MSpi['Coef0'] = VE04_Ni_pred_coef_[0]\n",
    "df_VE04Ni_MSpi['Coef1'] = VE04_Ni_pred_coef_[1]\n",
    "df_VE04Ni_MSpi['Coef2'] = VE04_Ni_pred_coef_[2]\n",
    "df_VE04Ni_MSpi['Coef3'] = VE04_Ni_pred_coef_[3]\n",
    "df_VE04Ni_MSpi['Coef4'] = VE04_Ni_pred_coef_[4]\n",
    "df_VE04Ni_MSpi['Coef5'] = VE04_Ni_pred_coef_[5]\n",
    "df_VE04Ni_MSpi['Coef6'] = VE04_Ni_pred_coef_[6]\n",
    "\n",
    "#Step8: Fill the empty cells using interpolate.\n",
    "df_VE04Ni_MSpi = df_VE04Ni_MSpi.interpolate(method='linear', limit_direction='forward', axis=0)\n",
    "\n",
    "# Step9-----Solving for the VE04 Ni concentration prediction using the coefficients from ridgeregression\n",
    "    \n",
    "df_VE04Ni_MSpi['VE04_Ni_soln_pred'] = df_VE04Ni_MSpi['MS_Flow']*df_VE04Ni_MSpi.Coef0 + \\\n",
    "                                      df_VE04Ni_MSpi['MS_FEED_TEMP']*df_VE04Ni_MSpi.Coef1 + \\\n",
    "                                      df_VE04Ni_MSpi['REC_GAS']*df_VE04Ni_MSpi.Coef2 + \\\n",
    "                                      df_VE04Ni_MSpi['106TK01_Mg']*df_VE04Ni_MSpi.Coef3 + \\\n",
    "                                      df_VE04Ni_MSpi['106TK01_pH']*df_VE04Ni_MSpi.Coef4 + \\\n",
    "                                      df_VE04Ni_MSpi['106TK01_Ni']*df_VE04Ni_MSpi.Coef5 + \\\n",
    "                                      df_VE04Ni_MSpi['106TK01_Fe']*df_VE04Ni_MSpi.Coef6 + \\\n",
    "                                      VE04_Ni_pred_intrcpt_\n",
    "# Step10: Adjust the predicted values for retention time by temporarily transfering it to a separate df, \n",
    "#         then adding 2 hrs to it's datetime. Then rejoining it to the df_VE04Ni_MSpi df.\n",
    "df_VE04_Ni_Pred_solo = df_VE04Ni_MSpi['VE04_Ni_soln_pred']\n",
    "\n",
    "df_VE04Ni_MSpi = df_VE04Ni_MSpi.drop('VE04_Ni_soln_pred', axis=1) # Drop the VE04_Ni_soln_pred from the main df. Join it after adding retention time\n",
    "df_VE04_Ni_Pred_solo = df_VE04_Ni_Pred_solo.reset_index()\n",
    "df_VE04_Ni_Pred_solo['DATETIME'] =  df_VE04_Ni_Pred_solo['DATETIME'] + datetime.timedelta(hours=2)\n",
    "df_VE04_Ni_Pred_solo.set_index('DATETIME', inplace=True)\n",
    "\n",
    "# Join the time adjusted VE04_Ni_pred_solo\n",
    "df_VE04Ni_MSpi = df_VE04Ni_MSpi.join(df_VE04_Ni_Pred_solo, how='outer')\n",
    "\n",
    "print('VE04 PRED part Done', datetime.datetime.now())\n",
    "\n",
    "#-------------------------------------------End of VE04 Ni Prediction Code -------------------------------------------####\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
